{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Libs'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Data And Identify Classes'''\n",
    "PathTrain =  os.getcwd() + \"/data/train.csv\"\n",
    "PathTest =  os.getcwd() + \"/data/test.csv\"\n",
    "DFTrain = pd.read_csv(PathTrain, header=None)\n",
    "DFTest = pd.read_csv(PathTest, header=None)\n",
    "totalClasses = len(Counter(DFTrain.iloc[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''One Hot Encoding for Train and Test Labels'''\n",
    "oneHotTrainLables = np.zeros((len(DFTrain), totalClasses))\n",
    "oneHotTestLables = np.zeros((len(DFTest), totalClasses))\n",
    "\n",
    "for i in range(len(DFTrain)):\n",
    "    oneHotTrainLables[i][DFTrain.iloc[i, -1]] = 1\n",
    "    \n",
    "for i in range(len(DFTest)):\n",
    "    oneHotTestLables[i][DFTest.iloc[i, -1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    #Sigmoid Function\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def ReLU(z):\n",
    "    #Rectified Linear Unit\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def delSigmoid(z):\n",
    "    oj = sigmoid(z)\n",
    "    return np.multiply(oj, (1-oj))\n",
    "\n",
    "def delReLU(z):\n",
    "    z = np.matrix(z)\n",
    "    z[z > 0] = 1\n",
    "    z[z <= 0] = 0    \n",
    "    return z\n",
    "    \n",
    "\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self, perceptron_units, perceptron_units_prev, activation_func, layer_type):\n",
    "        self.type = layer_type\n",
    "        self.activation = activation_func\n",
    "        self.perceptron_units = perceptron_units\n",
    "        self.bias = 0.001*np.random.rand(perceptron_units)\n",
    "        self.weights = 0.001*np.random.rand(perceptron_units, perceptron_units_prev)\n",
    "        self.inputs = None\n",
    "        self.output = None\n",
    "        self.grad = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        representation = (self.type, self.perceptron_units, self.weights.shape, self.bias.shape, self.activation)\n",
    "        return \"<%s Layer | Num_Perceptrons_Units = %d, Weights = %s, Bias = %s, Activation = %s>\" % representation\n",
    "\n",
    "        \n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, list_hidden_layers, op_layers_activation, hidden_layers_activation):\n",
    "        np.random.seed(100)\n",
    "        self.total_layers = len(list_hidden_layers) + 1\n",
    "        self.nodes_hidden_layers = list_hidden_layers\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(list_hidden_layers)):\n",
    "            if i == 0:\n",
    "                layer = Layer(list_hidden_layers[i], n, hidden_layers_activation, \"Hidden\")\n",
    "                self.layers.append(layer)\n",
    "            else:\n",
    "                layer = Layer(list_hidden_layers[i], list_hidden_layers[i-1], hidden_layers_activation, \"Hidden\")\n",
    "                self.layers.append(layer)\n",
    "        \n",
    "        layer = Layer(r, list_hidden_layers[-1], op_layers_activation, \"Output\")\n",
    "        self.layers.append(layer) \n",
    "        \n",
    "    def __repr__(self):\n",
    "        layers = self.layers\n",
    "        rep = \"\"\n",
    "        print(\"Neural Network:\")\n",
    "        for i in range(len(layers)):\n",
    "            rep += \"Layer %d: %s\\n\" % (i, layers[i])\n",
    "        return rep\n",
    "            \n",
    "    def forwardFeed(self, ip_data):\n",
    "        layer = self.layers[0]\n",
    "        layer.inputs = np.matrix(ip_data)\n",
    "        layer.netj = np.matmul(layer.inputs, np.matrix(layer.weights).T) + layer.bias\n",
    "        layer.output = self.activation(layer.netj, layer.activation)\n",
    "        \n",
    "        for i in range(1, len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            layer.inputs = self.layers[i-1].output\n",
    "            layer.netj = np.matmul(layer.inputs, np.matrix(layer.weights).T) + layer.bias\n",
    "            layer.output = self.activation(layer.netj, layer.activation)        \n",
    "        \n",
    "    def backPropagation(self, labels):\n",
    "        labels = np.matrix(labels)\n",
    "        op_layer = self.layers[-1]\n",
    "        diff = labels - op_layer.output\n",
    "        deloj = self.delActivation(op_layer.output, op_layer.activation)\n",
    "        op_layer.delnetj = -1*np.multiply(diff, deloj)\n",
    "        #print(op_layer.delnetj.shape, op_layer.inputs.shape)\n",
    "        op_layer.grad = [np.matmul(op_layer.delnetj.T, op_layer.inputs), op_layer.delnetj]#changed this\n",
    "        \n",
    "        for j in range(self.total_layers -2, -1, -1):\n",
    "            layer_j = self.layers[j]\n",
    "            deloj = self.delActivation(layer_j.output, layer_j.activation)#changed this\n",
    "            layer_l = self.layers[j + 1]\n",
    "            #print(layer_l.weights.shape, layer_l.delnetj.shape)\n",
    "            delL_thetaLJ = np.matmul(layer_l.delnetj, layer_l.weights)\n",
    "            layer_j.delnetj = np.multiply(delL_thetaLJ, deloj)\n",
    "            #print(layer_j.delnetj.shape, layer_j.inputs.shape)\n",
    "            layer_j.grad = [np.matmul(layer_j.delnetj.T, layer_j.inputs), layer_j.delnetj]#changed this\n",
    "    \n",
    "    def activation(self, x, activation):\n",
    "        if activation == \"Sigmoid\":\n",
    "            return sigmoid(x)\n",
    "        elif activation == \"ReLU\":\n",
    "            return ReLU(x)\n",
    "    \n",
    "    def delActivation(self, x, activation):\n",
    "        if activation == \"Sigmoid\":            \n",
    "            return delSigmoid(x)\n",
    "        \n",
    "        elif activation == \"ReLU\":\n",
    "            return delReLU(x)\n",
    "        \n",
    "    def updateParams(self, lr, bSize):\n",
    "        layers = self.layers \n",
    "        #print(\"updating\")\n",
    "        for layer in layers:\n",
    "            gradient = layer.grad\n",
    "            \n",
    "            layer.weights = layer.weights - (lr/bSize)*gradient[0]\n",
    "            layer.bias = layer.bias - (lr/bSize)*gradient[1]\n",
    "            \n",
    "    def meanSquaredError(self, Y, avg=True):\n",
    "        div = 1\n",
    "        if avg:\n",
    "            div = len(Y)\n",
    "        \n",
    "        op_layer_labels = self.layers[-1].output\n",
    "        error = Y - op_layer_labels\n",
    "        error = np.square(error)\n",
    "        error = np.sum(error)/(2*div)\n",
    "        return error\n",
    "    \n",
    "    def trainNeuralNetwork(self, X, Labels, eta = 0.1, batch_size=100, max_epoch = 10000, epsilon=1e-10):\n",
    "        lr = eta\n",
    "        data = X\n",
    "        labels = Labels\n",
    "        \n",
    "        epoch = 0\n",
    "        self.forwardFeed(data)\n",
    "        error_prev = self.meanSquaredError(labels)\n",
    "        epoch_error_list = [error_prev]\n",
    "        t0 = time()\n",
    "        while epoch < max_epoch:\n",
    "            t1 = time()\n",
    "            epoch += 1\n",
    "            #print(\"Epoch: \", epoch)\n",
    "            \n",
    "            data, labels = shuffle(data, labels)\n",
    "            \n",
    "            if eta == 0:\n",
    "                lr = 0.5/np.sqrt(epoch)\n",
    "                \n",
    "            for batch_start in range(0, len(data), batch_size):\n",
    "                batch_end = batch_start + batch_size\n",
    "                Xb = data[batch_start : batch_end]\n",
    "                Yb = labels[batch_start : batch_end]\n",
    "                #print(Xb.shape, Yb.shape)\n",
    "                self.forwardFeed(Xb)\n",
    "                self.backPropagation(Yb)\n",
    "                \n",
    "                self.updateParams(lr, batch_size)\n",
    "                error = self.meanSquaredError(Yb)\n",
    "                \n",
    "            t2 = time()   \n",
    "            #self.forwardFeed(data)\n",
    "            #error = self.meanSquaredError(labels)\n",
    "            deltaError = np.abs(error - error_prev)\n",
    "            epoch_error_list.append(error)            \n",
    "            print(\"$$ Epoch: {} | Error = {} | DeltaError = {} | LR = {} | Epoch Train Time = {}Sec\"\n",
    "                  .format(epoch, round(error,6), round(deltaError,6), lr, round(t2-t1,2)))\n",
    "            if deltaError < epsilon:\n",
    "                break\n",
    "            error_prev = error\n",
    "            #epoch += 1\n",
    "        \n",
    "        t4 = time()\n",
    "        print(\"\\n%% Total Epochs ={} | Epsilon = {} | Total Learning Time = {}Min\"\n",
    "              .format(epoch, epsilon, round((t4-t0)/60,2)))\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ Epoch: 1 | Error = 0.481202 | DeltaError = 2.921681 | LR = 0.1 | Epoch Train Time = 0.52Sec\n",
      "$$ Epoch: 2 | Error = 0.480898 | DeltaError = 0.000304 | LR = 0.1 | Epoch Train Time = 0.47Sec\n",
      "$$ Epoch: 3 | Error = 0.481046 | DeltaError = 0.000148 | LR = 0.1 | Epoch Train Time = 0.5Sec\n",
      "$$ Epoch: 4 | Error = 0.481125 | DeltaError = 7.9e-05 | LR = 0.1 | Epoch Train Time = 0.47Sec\n",
      "$$ Epoch: 5 | Error = 0.481019 | DeltaError = 0.000107 | LR = 0.1 | Epoch Train Time = 0.47Sec\n",
      "$$ Epoch: 6 | Error = 0.480933 | DeltaError = 8.6e-05 | LR = 0.1 | Epoch Train Time = 0.46Sec\n",
      "$$ Epoch: 7 | Error = 0.480707 | DeltaError = 0.000226 | LR = 0.1 | Epoch Train Time = 0.51Sec\n",
      "$$ Epoch: 8 | Error = 0.480744 | DeltaError = 3.8e-05 | LR = 0.1 | Epoch Train Time = 0.45Sec\n",
      "$$ Epoch: 9 | Error = 0.480874 | DeltaError = 0.00013 | LR = 0.1 | Epoch Train Time = 0.5Sec\n",
      "$$ Epoch: 10 | Error = 0.480882 | DeltaError = 8e-06 | LR = 0.1 | Epoch Train Time = 0.48Sec\n",
      "$$ Epoch: 11 | Error = 0.480999 | DeltaError = 0.000117 | LR = 0.1 | Epoch Train Time = 0.5Sec\n",
      "$$ Epoch: 12 | Error = 0.481163 | DeltaError = 0.000164 | LR = 0.1 | Epoch Train Time = 0.48Sec\n",
      "$$ Epoch: 13 | Error = 0.481331 | DeltaError = 0.000168 | LR = 0.1 | Epoch Train Time = 0.49Sec\n",
      "$$ Epoch: 14 | Error = 0.481107 | DeltaError = 0.000224 | LR = 0.1 | Epoch Train Time = 0.52Sec\n",
      "$$ Epoch: 15 | Error = 0.480947 | DeltaError = 0.00016 | LR = 0.1 | Epoch Train Time = 0.64Sec\n",
      "$$ Epoch: 16 | Error = 0.481689 | DeltaError = 0.000743 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 17 | Error = 0.480787 | DeltaError = 0.000903 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 18 | Error = 0.480985 | DeltaError = 0.000198 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 19 | Error = 0.481187 | DeltaError = 0.000202 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 20 | Error = 0.481515 | DeltaError = 0.000329 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 21 | Error = 0.480619 | DeltaError = 0.000896 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 22 | Error = 0.48024 | DeltaError = 0.000379 | LR = 0.1 | Epoch Train Time = 0.79Sec\n",
      "$$ Epoch: 23 | Error = 0.481019 | DeltaError = 0.000779 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 24 | Error = 0.482086 | DeltaError = 0.001068 | LR = 0.1 | Epoch Train Time = 0.77Sec\n",
      "$$ Epoch: 25 | Error = 0.480828 | DeltaError = 0.001259 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 26 | Error = 0.481788 | DeltaError = 0.000961 | LR = 0.1 | Epoch Train Time = 0.77Sec\n",
      "$$ Epoch: 27 | Error = 0.480612 | DeltaError = 0.001176 | LR = 0.1 | Epoch Train Time = 0.76Sec\n",
      "$$ Epoch: 28 | Error = 0.479981 | DeltaError = 0.000631 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 29 | Error = 0.479429 | DeltaError = 0.000552 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 30 | Error = 0.476342 | DeltaError = 0.003088 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 31 | Error = 0.47254 | DeltaError = 0.003802 | LR = 0.1 | Epoch Train Time = 0.76Sec\n",
      "$$ Epoch: 32 | Error = 0.465803 | DeltaError = 0.006737 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 33 | Error = 0.465703 | DeltaError = 0.0001 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 34 | Error = 0.44902 | DeltaError = 0.016683 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 35 | Error = 0.447971 | DeltaError = 0.001049 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 36 | Error = 0.444871 | DeltaError = 0.0031 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 37 | Error = 0.428789 | DeltaError = 0.016082 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 38 | Error = 0.425524 | DeltaError = 0.003265 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 39 | Error = 0.426081 | DeltaError = 0.000557 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 40 | Error = 0.420381 | DeltaError = 0.0057 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 41 | Error = 0.411879 | DeltaError = 0.008502 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 42 | Error = 0.398074 | DeltaError = 0.013805 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 43 | Error = 0.398274 | DeltaError = 0.0002 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 44 | Error = 0.385898 | DeltaError = 0.012375 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 45 | Error = 0.367742 | DeltaError = 0.018156 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 46 | Error = 0.36561 | DeltaError = 0.002133 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 47 | Error = 0.369408 | DeltaError = 0.003798 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 48 | Error = 0.348413 | DeltaError = 0.020995 | LR = 0.1 | Epoch Train Time = 0.65Sec\n",
      "$$ Epoch: 49 | Error = 0.339252 | DeltaError = 0.009161 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 50 | Error = 0.347399 | DeltaError = 0.008147 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 51 | Error = 0.33486 | DeltaError = 0.012539 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 52 | Error = 0.312542 | DeltaError = 0.022318 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 53 | Error = 0.336584 | DeltaError = 0.024042 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 54 | Error = 0.333757 | DeltaError = 0.002827 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 55 | Error = 0.321593 | DeltaError = 0.012164 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 56 | Error = 0.347732 | DeltaError = 0.026139 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 57 | Error = 0.324054 | DeltaError = 0.023678 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 58 | Error = 0.322201 | DeltaError = 0.001852 | LR = 0.1 | Epoch Train Time = 0.64Sec\n",
      "$$ Epoch: 59 | Error = 0.313042 | DeltaError = 0.009159 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 60 | Error = 0.29653 | DeltaError = 0.016512 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 61 | Error = 0.304011 | DeltaError = 0.007482 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 62 | Error = 0.305302 | DeltaError = 0.001291 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 63 | Error = 0.283749 | DeltaError = 0.021553 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 64 | Error = 0.294467 | DeltaError = 0.010718 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 65 | Error = 0.319526 | DeltaError = 0.025059 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 66 | Error = 0.292986 | DeltaError = 0.02654 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 67 | Error = 0.282682 | DeltaError = 0.010304 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 68 | Error = 0.279246 | DeltaError = 0.003436 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 69 | Error = 0.268614 | DeltaError = 0.010632 | LR = 0.1 | Epoch Train Time = 0.83Sec\n",
      "$$ Epoch: 70 | Error = 0.25166 | DeltaError = 0.016953 | LR = 0.1 | Epoch Train Time = 0.77Sec\n",
      "$$ Epoch: 71 | Error = 0.26341 | DeltaError = 0.01175 | LR = 0.1 | Epoch Train Time = 0.81Sec\n",
      "$$ Epoch: 72 | Error = 0.293315 | DeltaError = 0.029905 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 73 | Error = 0.280015 | DeltaError = 0.0133 | LR = 0.1 | Epoch Train Time = 0.77Sec\n",
      "$$ Epoch: 74 | Error = 0.256451 | DeltaError = 0.023564 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 75 | Error = 0.251211 | DeltaError = 0.00524 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 76 | Error = 0.268733 | DeltaError = 0.017522 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 77 | Error = 0.266017 | DeltaError = 0.002716 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 78 | Error = 0.268335 | DeltaError = 0.002318 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 79 | Error = 0.253995 | DeltaError = 0.01434 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 80 | Error = 0.266632 | DeltaError = 0.012637 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 81 | Error = 0.251614 | DeltaError = 0.015018 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 82 | Error = 0.25958 | DeltaError = 0.007967 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 83 | Error = 0.250374 | DeltaError = 0.009206 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 84 | Error = 0.243843 | DeltaError = 0.006531 | LR = 0.1 | Epoch Train Time = 0.65Sec\n",
      "$$ Epoch: 85 | Error = 0.252534 | DeltaError = 0.008691 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 86 | Error = 0.247227 | DeltaError = 0.005307 | LR = 0.1 | Epoch Train Time = 0.7Sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ Epoch: 87 | Error = 0.242914 | DeltaError = 0.004313 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 88 | Error = 0.234438 | DeltaError = 0.008476 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 89 | Error = 0.242592 | DeltaError = 0.008154 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 90 | Error = 0.234065 | DeltaError = 0.008527 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 91 | Error = 0.245045 | DeltaError = 0.01098 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 92 | Error = 0.249016 | DeltaError = 0.003971 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 93 | Error = 0.241755 | DeltaError = 0.007261 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 94 | Error = 0.205937 | DeltaError = 0.035818 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 95 | Error = 0.234025 | DeltaError = 0.028089 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 96 | Error = 0.223029 | DeltaError = 0.010996 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 97 | Error = 0.230463 | DeltaError = 0.007434 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 98 | Error = 0.240125 | DeltaError = 0.009662 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 99 | Error = 0.228286 | DeltaError = 0.011839 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 100 | Error = 0.253674 | DeltaError = 0.025388 | LR = 0.1 | Epoch Train Time = 0.78Sec\n",
      "$$ Epoch: 101 | Error = 0.25181 | DeltaError = 0.001864 | LR = 0.1 | Epoch Train Time = 0.76Sec\n",
      "$$ Epoch: 102 | Error = 0.256276 | DeltaError = 0.004466 | LR = 0.1 | Epoch Train Time = 0.73Sec\n",
      "$$ Epoch: 103 | Error = 0.247333 | DeltaError = 0.008943 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 104 | Error = 0.21462 | DeltaError = 0.032713 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 105 | Error = 0.236343 | DeltaError = 0.021723 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 106 | Error = 0.226272 | DeltaError = 0.010071 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 107 | Error = 0.231994 | DeltaError = 0.005722 | LR = 0.1 | Epoch Train Time = 0.82Sec\n",
      "$$ Epoch: 108 | Error = 0.23323 | DeltaError = 0.001236 | LR = 0.1 | Epoch Train Time = 0.78Sec\n",
      "$$ Epoch: 109 | Error = 0.22691 | DeltaError = 0.00632 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 110 | Error = 0.219274 | DeltaError = 0.007635 | LR = 0.1 | Epoch Train Time = 0.73Sec\n",
      "$$ Epoch: 111 | Error = 0.236053 | DeltaError = 0.016779 | LR = 0.1 | Epoch Train Time = 0.76Sec\n",
      "$$ Epoch: 112 | Error = 0.207824 | DeltaError = 0.02823 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 113 | Error = 0.207626 | DeltaError = 0.000198 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 114 | Error = 0.178838 | DeltaError = 0.028788 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 115 | Error = 0.195905 | DeltaError = 0.017067 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 116 | Error = 0.20596 | DeltaError = 0.010055 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 117 | Error = 0.20408 | DeltaError = 0.00188 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 118 | Error = 0.205572 | DeltaError = 0.001492 | LR = 0.1 | Epoch Train Time = 0.8Sec\n",
      "$$ Epoch: 119 | Error = 0.22856 | DeltaError = 0.022988 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 120 | Error = 0.204508 | DeltaError = 0.024052 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 121 | Error = 0.211141 | DeltaError = 0.006634 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 122 | Error = 0.198802 | DeltaError = 0.012339 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 123 | Error = 0.230777 | DeltaError = 0.031975 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 124 | Error = 0.219552 | DeltaError = 0.011225 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 125 | Error = 0.181618 | DeltaError = 0.037933 | LR = 0.1 | Epoch Train Time = 0.73Sec\n",
      "$$ Epoch: 126 | Error = 0.196784 | DeltaError = 0.015166 | LR = 0.1 | Epoch Train Time = 0.78Sec\n",
      "$$ Epoch: 127 | Error = 0.2593 | DeltaError = 0.062515 | LR = 0.1 | Epoch Train Time = 0.82Sec\n",
      "$$ Epoch: 128 | Error = 0.216592 | DeltaError = 0.042708 | LR = 0.1 | Epoch Train Time = 1.31Sec\n",
      "$$ Epoch: 129 | Error = 0.189369 | DeltaError = 0.027223 | LR = 0.1 | Epoch Train Time = 1.36Sec\n",
      "$$ Epoch: 130 | Error = 0.236845 | DeltaError = 0.047477 | LR = 0.1 | Epoch Train Time = 1.06Sec\n",
      "$$ Epoch: 131 | Error = 0.20031 | DeltaError = 0.036535 | LR = 0.1 | Epoch Train Time = 1.02Sec\n",
      "$$ Epoch: 132 | Error = 0.222276 | DeltaError = 0.021965 | LR = 0.1 | Epoch Train Time = 0.95Sec\n",
      "$$ Epoch: 133 | Error = 0.23167 | DeltaError = 0.009394 | LR = 0.1 | Epoch Train Time = 0.86Sec\n",
      "$$ Epoch: 134 | Error = 0.22465 | DeltaError = 0.00702 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 135 | Error = 0.19967 | DeltaError = 0.024979 | LR = 0.1 | Epoch Train Time = 0.98Sec\n",
      "$$ Epoch: 136 | Error = 0.264527 | DeltaError = 0.064857 | LR = 0.1 | Epoch Train Time = 0.97Sec\n",
      "$$ Epoch: 137 | Error = 0.212791 | DeltaError = 0.051736 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 138 | Error = 0.173019 | DeltaError = 0.039772 | LR = 0.1 | Epoch Train Time = 0.95Sec\n",
      "$$ Epoch: 139 | Error = 0.218226 | DeltaError = 0.045207 | LR = 0.1 | Epoch Train Time = 0.97Sec\n",
      "$$ Epoch: 140 | Error = 0.210264 | DeltaError = 0.007962 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 141 | Error = 0.236435 | DeltaError = 0.026172 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 142 | Error = 0.186072 | DeltaError = 0.050363 | LR = 0.1 | Epoch Train Time = 0.99Sec\n",
      "$$ Epoch: 143 | Error = 0.199081 | DeltaError = 0.013009 | LR = 0.1 | Epoch Train Time = 0.99Sec\n",
      "$$ Epoch: 144 | Error = 0.176325 | DeltaError = 0.022756 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 145 | Error = 0.201275 | DeltaError = 0.02495 | LR = 0.1 | Epoch Train Time = 0.94Sec\n",
      "$$ Epoch: 146 | Error = 0.203115 | DeltaError = 0.00184 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 147 | Error = 0.187134 | DeltaError = 0.015981 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 148 | Error = 0.216349 | DeltaError = 0.029215 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 149 | Error = 0.185503 | DeltaError = 0.030846 | LR = 0.1 | Epoch Train Time = 0.94Sec\n",
      "$$ Epoch: 150 | Error = 0.200843 | DeltaError = 0.015339 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 151 | Error = 0.185883 | DeltaError = 0.01496 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 152 | Error = 0.190127 | DeltaError = 0.004244 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 153 | Error = 0.212892 | DeltaError = 0.022765 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 154 | Error = 0.200552 | DeltaError = 0.012339 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 155 | Error = 0.190258 | DeltaError = 0.010295 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 156 | Error = 0.198042 | DeltaError = 0.007785 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 157 | Error = 0.202013 | DeltaError = 0.003971 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 158 | Error = 0.222988 | DeltaError = 0.020975 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 159 | Error = 0.208472 | DeltaError = 0.014517 | LR = 0.1 | Epoch Train Time = 0.86Sec\n",
      "$$ Epoch: 160 | Error = 0.179073 | DeltaError = 0.029398 | LR = 0.1 | Epoch Train Time = 0.98Sec\n",
      "$$ Epoch: 161 | Error = 0.204353 | DeltaError = 0.025279 | LR = 0.1 | Epoch Train Time = 0.99Sec\n",
      "$$ Epoch: 162 | Error = 0.182112 | DeltaError = 0.022241 | LR = 0.1 | Epoch Train Time = 1.01Sec\n",
      "$$ Epoch: 163 | Error = 0.206213 | DeltaError = 0.024101 | LR = 0.1 | Epoch Train Time = 0.98Sec\n",
      "$$ Epoch: 164 | Error = 0.200837 | DeltaError = 0.005375 | LR = 0.1 | Epoch Train Time = 1.02Sec\n",
      "$$ Epoch: 165 | Error = 0.195718 | DeltaError = 0.005119 | LR = 0.1 | Epoch Train Time = 0.98Sec\n",
      "$$ Epoch: 166 | Error = 0.202695 | DeltaError = 0.006977 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 167 | Error = 0.222116 | DeltaError = 0.019422 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 168 | Error = 0.222638 | DeltaError = 0.000522 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 169 | Error = 0.199744 | DeltaError = 0.022894 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 170 | Error = 0.205922 | DeltaError = 0.006178 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 171 | Error = 0.230296 | DeltaError = 0.024374 | LR = 0.1 | Epoch Train Time = 0.92Sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ Epoch: 172 | Error = 0.205973 | DeltaError = 0.024323 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 173 | Error = 0.236905 | DeltaError = 0.030933 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 174 | Error = 0.206907 | DeltaError = 0.029998 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 175 | Error = 0.175692 | DeltaError = 0.031215 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 176 | Error = 0.213025 | DeltaError = 0.037333 | LR = 0.1 | Epoch Train Time = 0.86Sec\n",
      "$$ Epoch: 177 | Error = 0.238488 | DeltaError = 0.025463 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 178 | Error = 0.207544 | DeltaError = 0.030944 | LR = 0.1 | Epoch Train Time = 0.84Sec\n",
      "$$ Epoch: 179 | Error = 0.174216 | DeltaError = 0.033327 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 180 | Error = 0.19748 | DeltaError = 0.023263 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 181 | Error = 0.216903 | DeltaError = 0.019423 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 182 | Error = 0.22272 | DeltaError = 0.005817 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 183 | Error = 0.225054 | DeltaError = 0.002335 | LR = 0.1 | Epoch Train Time = 0.99Sec\n",
      "$$ Epoch: 184 | Error = 0.191641 | DeltaError = 0.033413 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 185 | Error = 0.22218 | DeltaError = 0.030539 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 186 | Error = 0.225161 | DeltaError = 0.002981 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 187 | Error = 0.279965 | DeltaError = 0.054803 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 188 | Error = 0.220693 | DeltaError = 0.059272 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 189 | Error = 0.1979 | DeltaError = 0.022793 | LR = 0.1 | Epoch Train Time = 0.86Sec\n",
      "$$ Epoch: 190 | Error = 0.215167 | DeltaError = 0.017267 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 191 | Error = 0.189284 | DeltaError = 0.025883 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 192 | Error = 0.23754 | DeltaError = 0.048256 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 193 | Error = 0.19514 | DeltaError = 0.0424 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 194 | Error = 0.223824 | DeltaError = 0.028684 | LR = 0.1 | Epoch Train Time = 0.86Sec\n",
      "$$ Epoch: 195 | Error = 0.218872 | DeltaError = 0.004952 | LR = 0.1 | Epoch Train Time = 0.84Sec\n",
      "$$ Epoch: 196 | Error = 0.213218 | DeltaError = 0.005654 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 197 | Error = 0.184743 | DeltaError = 0.028475 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 198 | Error = 0.18989 | DeltaError = 0.005148 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 199 | Error = 0.248715 | DeltaError = 0.058825 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 200 | Error = 0.19976 | DeltaError = 0.048955 | LR = 0.1 | Epoch Train Time = 0.84Sec\n",
      "$$ Epoch: 201 | Error = 0.202937 | DeltaError = 0.003176 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 202 | Error = 0.192848 | DeltaError = 0.010088 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 203 | Error = 0.209372 | DeltaError = 0.016524 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 204 | Error = 0.202215 | DeltaError = 0.007157 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 205 | Error = 0.24149 | DeltaError = 0.039275 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 206 | Error = 0.218326 | DeltaError = 0.023164 | LR = 0.1 | Epoch Train Time = 1.04Sec\n",
      "$$ Epoch: 207 | Error = 0.229843 | DeltaError = 0.011517 | LR = 0.1 | Epoch Train Time = 1.02Sec\n",
      "$$ Epoch: 208 | Error = 0.226142 | DeltaError = 0.0037 | LR = 0.1 | Epoch Train Time = 0.97Sec\n",
      "$$ Epoch: 209 | Error = 0.244878 | DeltaError = 0.018736 | LR = 0.1 | Epoch Train Time = 1.06Sec\n",
      "$$ Epoch: 210 | Error = 0.190288 | DeltaError = 0.054591 | LR = 0.1 | Epoch Train Time = 1.02Sec\n",
      "$$ Epoch: 211 | Error = 0.235809 | DeltaError = 0.045521 | LR = 0.1 | Epoch Train Time = 0.97Sec\n",
      "$$ Epoch: 212 | Error = 0.233216 | DeltaError = 0.002593 | LR = 0.1 | Epoch Train Time = 0.97Sec\n",
      "$$ Epoch: 213 | Error = 0.208481 | DeltaError = 0.024735 | LR = 0.1 | Epoch Train Time = 0.8Sec\n",
      "$$ Epoch: 214 | Error = 0.194679 | DeltaError = 0.013801 | LR = 0.1 | Epoch Train Time = 0.77Sec\n",
      "$$ Epoch: 215 | Error = 0.246611 | DeltaError = 0.051931 | LR = 0.1 | Epoch Train Time = 0.75Sec\n",
      "$$ Epoch: 216 | Error = 0.194002 | DeltaError = 0.052608 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 217 | Error = 0.228917 | DeltaError = 0.034915 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 218 | Error = 0.217606 | DeltaError = 0.011311 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 219 | Error = 0.20536 | DeltaError = 0.012246 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 220 | Error = 0.245839 | DeltaError = 0.040479 | LR = 0.1 | Epoch Train Time = 0.64Sec\n",
      "$$ Epoch: 221 | Error = 0.225631 | DeltaError = 0.020208 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 222 | Error = 0.231469 | DeltaError = 0.005838 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 223 | Error = 0.205054 | DeltaError = 0.026416 | LR = 0.1 | Epoch Train Time = 0.63Sec\n",
      "$$ Epoch: 224 | Error = 0.224881 | DeltaError = 0.019827 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 225 | Error = 0.225643 | DeltaError = 0.000762 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 226 | Error = 0.2109 | DeltaError = 0.014743 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 227 | Error = 0.222068 | DeltaError = 0.011168 | LR = 0.1 | Epoch Train Time = 0.8Sec\n",
      "$$ Epoch: 228 | Error = 0.250964 | DeltaError = 0.028896 | LR = 0.1 | Epoch Train Time = 0.84Sec\n",
      "$$ Epoch: 229 | Error = 0.250955 | DeltaError = 9e-06 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 230 | Error = 0.214562 | DeltaError = 0.036393 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 231 | Error = 0.278633 | DeltaError = 0.064071 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 232 | Error = 0.227202 | DeltaError = 0.051431 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 233 | Error = 0.238552 | DeltaError = 0.01135 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 234 | Error = 0.216089 | DeltaError = 0.022463 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 235 | Error = 0.201004 | DeltaError = 0.015085 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 236 | Error = 0.249144 | DeltaError = 0.04814 | LR = 0.1 | Epoch Train Time = 1.01Sec\n",
      "$$ Epoch: 237 | Error = 0.248109 | DeltaError = 0.001035 | LR = 0.1 | Epoch Train Time = 1.26Sec\n",
      "$$ Epoch: 238 | Error = 0.247389 | DeltaError = 0.000719 | LR = 0.1 | Epoch Train Time = 1.22Sec\n",
      "$$ Epoch: 239 | Error = 0.266649 | DeltaError = 0.019259 | LR = 0.1 | Epoch Train Time = 1.1Sec\n",
      "$$ Epoch: 240 | Error = 0.24917 | DeltaError = 0.017478 | LR = 0.1 | Epoch Train Time = 1.07Sec\n",
      "$$ Epoch: 241 | Error = 0.241798 | DeltaError = 0.007372 | LR = 0.1 | Epoch Train Time = 1.07Sec\n",
      "$$ Epoch: 242 | Error = 0.234158 | DeltaError = 0.00764 | LR = 0.1 | Epoch Train Time = 0.96Sec\n",
      "$$ Epoch: 243 | Error = 0.246547 | DeltaError = 0.012389 | LR = 0.1 | Epoch Train Time = 0.84Sec\n",
      "$$ Epoch: 244 | Error = 0.243623 | DeltaError = 0.002924 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 245 | Error = 0.218652 | DeltaError = 0.02497 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 246 | Error = 0.246332 | DeltaError = 0.02768 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 247 | Error = 0.214565 | DeltaError = 0.031767 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 248 | Error = 0.253751 | DeltaError = 0.039186 | LR = 0.1 | Epoch Train Time = 0.81Sec\n",
      "$$ Epoch: 249 | Error = 0.24725 | DeltaError = 0.006501 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 250 | Error = 0.226847 | DeltaError = 0.020402 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 251 | Error = 0.227411 | DeltaError = 0.000563 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 252 | Error = 0.278269 | DeltaError = 0.050858 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 253 | Error = 0.226849 | DeltaError = 0.051419 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 254 | Error = 0.245242 | DeltaError = 0.018393 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 255 | Error = 0.214785 | DeltaError = 0.030458 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 256 | Error = 0.239412 | DeltaError = 0.024627 | LR = 0.1 | Epoch Train Time = 0.67Sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ Epoch: 257 | Error = 0.224365 | DeltaError = 0.015047 | LR = 0.1 | Epoch Train Time = 0.65Sec\n",
      "$$ Epoch: 258 | Error = 0.237136 | DeltaError = 0.012771 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 259 | Error = 0.219016 | DeltaError = 0.01812 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 260 | Error = 0.218269 | DeltaError = 0.000747 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 261 | Error = 0.235734 | DeltaError = 0.017465 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 262 | Error = 0.246659 | DeltaError = 0.010925 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 263 | Error = 0.238838 | DeltaError = 0.007821 | LR = 0.1 | Epoch Train Time = 0.82Sec\n",
      "$$ Epoch: 264 | Error = 0.185142 | DeltaError = 0.053696 | LR = 0.1 | Epoch Train Time = 0.84Sec\n",
      "$$ Epoch: 265 | Error = 0.252862 | DeltaError = 0.067721 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 266 | Error = 0.234315 | DeltaError = 0.018547 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 267 | Error = 0.191095 | DeltaError = 0.04322 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 268 | Error = 0.239247 | DeltaError = 0.048151 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 269 | Error = 0.230421 | DeltaError = 0.008826 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 270 | Error = 0.216756 | DeltaError = 0.013665 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 271 | Error = 0.243172 | DeltaError = 0.026416 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 272 | Error = 0.222591 | DeltaError = 0.02058 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 273 | Error = 0.22011 | DeltaError = 0.002482 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 274 | Error = 0.254324 | DeltaError = 0.034214 | LR = 0.1 | Epoch Train Time = 0.94Sec\n",
      "$$ Epoch: 275 | Error = 0.200736 | DeltaError = 0.053588 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 276 | Error = 0.210012 | DeltaError = 0.009276 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 277 | Error = 0.188275 | DeltaError = 0.021736 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 278 | Error = 0.21437 | DeltaError = 0.026095 | LR = 0.1 | Epoch Train Time = 0.86Sec\n",
      "$$ Epoch: 279 | Error = 0.200162 | DeltaError = 0.014208 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 280 | Error = 0.266243 | DeltaError = 0.066081 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 281 | Error = 0.206267 | DeltaError = 0.059975 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 282 | Error = 0.204035 | DeltaError = 0.002232 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 283 | Error = 0.178922 | DeltaError = 0.025113 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 284 | Error = 0.213614 | DeltaError = 0.034692 | LR = 0.1 | Epoch Train Time = 1.11Sec\n",
      "$$ Epoch: 285 | Error = 0.219433 | DeltaError = 0.005819 | LR = 0.1 | Epoch Train Time = 1.02Sec\n",
      "$$ Epoch: 286 | Error = 0.208565 | DeltaError = 0.010868 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 287 | Error = 0.220166 | DeltaError = 0.011601 | LR = 0.1 | Epoch Train Time = 1.06Sec\n",
      "$$ Epoch: 288 | Error = 0.175877 | DeltaError = 0.044289 | LR = 0.1 | Epoch Train Time = 1.35Sec\n",
      "$$ Epoch: 289 | Error = 0.182294 | DeltaError = 0.006417 | LR = 0.1 | Epoch Train Time = 1.51Sec\n",
      "$$ Epoch: 290 | Error = 0.239826 | DeltaError = 0.057532 | LR = 0.1 | Epoch Train Time = 1.14Sec\n",
      "$$ Epoch: 291 | Error = 0.232306 | DeltaError = 0.00752 | LR = 0.1 | Epoch Train Time = 1.07Sec\n",
      "$$ Epoch: 292 | Error = 0.225405 | DeltaError = 0.006901 | LR = 0.1 | Epoch Train Time = 1.12Sec\n",
      "$$ Epoch: 293 | Error = 0.196039 | DeltaError = 0.029366 | LR = 0.1 | Epoch Train Time = 1.01Sec\n",
      "$$ Epoch: 294 | Error = 0.213075 | DeltaError = 0.017036 | LR = 0.1 | Epoch Train Time = 0.84Sec\n",
      "$$ Epoch: 295 | Error = 0.241553 | DeltaError = 0.028478 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 296 | Error = 0.184277 | DeltaError = 0.057276 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 297 | Error = 0.247169 | DeltaError = 0.062892 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 298 | Error = 0.210045 | DeltaError = 0.037124 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 299 | Error = 0.211946 | DeltaError = 0.001901 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 300 | Error = 0.199577 | DeltaError = 0.012369 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 301 | Error = 0.222938 | DeltaError = 0.023361 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 302 | Error = 0.244524 | DeltaError = 0.021586 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 303 | Error = 0.248411 | DeltaError = 0.003887 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 304 | Error = 0.221886 | DeltaError = 0.026525 | LR = 0.1 | Epoch Train Time = 0.65Sec\n",
      "$$ Epoch: 305 | Error = 0.216274 | DeltaError = 0.005612 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 306 | Error = 0.209432 | DeltaError = 0.006842 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 307 | Error = 0.230938 | DeltaError = 0.021506 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 308 | Error = 0.218547 | DeltaError = 0.012392 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 309 | Error = 0.22135 | DeltaError = 0.002803 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 310 | Error = 0.198497 | DeltaError = 0.022853 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 311 | Error = 0.209977 | DeltaError = 0.01148 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 312 | Error = 0.198055 | DeltaError = 0.011922 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 313 | Error = 0.223168 | DeltaError = 0.025113 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 314 | Error = 0.240005 | DeltaError = 0.016837 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 315 | Error = 0.186852 | DeltaError = 0.053154 | LR = 0.1 | Epoch Train Time = 1.1Sec\n",
      "$$ Epoch: 316 | Error = 0.190875 | DeltaError = 0.004023 | LR = 0.1 | Epoch Train Time = 1.24Sec\n",
      "$$ Epoch: 317 | Error = 0.254842 | DeltaError = 0.063967 | LR = 0.1 | Epoch Train Time = 1.04Sec\n",
      "$$ Epoch: 318 | Error = 0.19134 | DeltaError = 0.063502 | LR = 0.1 | Epoch Train Time = 0.96Sec\n",
      "$$ Epoch: 319 | Error = 0.191906 | DeltaError = 0.000565 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 320 | Error = 0.263499 | DeltaError = 0.071593 | LR = 0.1 | Epoch Train Time = 0.95Sec\n",
      "$$ Epoch: 321 | Error = 0.26625 | DeltaError = 0.002752 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 322 | Error = 0.215781 | DeltaError = 0.050469 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 323 | Error = 0.215353 | DeltaError = 0.000428 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 324 | Error = 0.230102 | DeltaError = 0.014749 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 325 | Error = 0.254069 | DeltaError = 0.023967 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 326 | Error = 0.222697 | DeltaError = 0.031372 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 327 | Error = 0.221049 | DeltaError = 0.001649 | LR = 0.1 | Epoch Train Time = 0.95Sec\n",
      "$$ Epoch: 328 | Error = 0.231402 | DeltaError = 0.010354 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 329 | Error = 0.214475 | DeltaError = 0.016927 | LR = 0.1 | Epoch Train Time = 0.86Sec\n",
      "$$ Epoch: 330 | Error = 0.248522 | DeltaError = 0.034047 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 331 | Error = 0.233159 | DeltaError = 0.015362 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 332 | Error = 0.218745 | DeltaError = 0.014415 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 333 | Error = 0.200611 | DeltaError = 0.018134 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 334 | Error = 0.214685 | DeltaError = 0.014074 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 335 | Error = 0.235701 | DeltaError = 0.021016 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 336 | Error = 0.255589 | DeltaError = 0.019888 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 337 | Error = 0.220179 | DeltaError = 0.03541 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 338 | Error = 0.234373 | DeltaError = 0.014194 | LR = 0.1 | Epoch Train Time = 0.87Sec\n",
      "$$ Epoch: 339 | Error = 0.213232 | DeltaError = 0.021141 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 340 | Error = 0.22859 | DeltaError = 0.015358 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 341 | Error = 0.230898 | DeltaError = 0.002308 | LR = 0.1 | Epoch Train Time = 0.89Sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ Epoch: 342 | Error = 0.233871 | DeltaError = 0.002973 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 343 | Error = 0.232279 | DeltaError = 0.001591 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 344 | Error = 0.244982 | DeltaError = 0.012702 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 345 | Error = 0.206196 | DeltaError = 0.038786 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 346 | Error = 0.246289 | DeltaError = 0.040094 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 347 | Error = 0.235103 | DeltaError = 0.011186 | LR = 0.1 | Epoch Train Time = 0.65Sec\n",
      "$$ Epoch: 348 | Error = 0.244397 | DeltaError = 0.009294 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 349 | Error = 0.234799 | DeltaError = 0.009599 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 350 | Error = 0.210159 | DeltaError = 0.024639 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 351 | Error = 0.225046 | DeltaError = 0.014887 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 352 | Error = 0.20283 | DeltaError = 0.022217 | LR = 0.1 | Epoch Train Time = 0.7Sec\n",
      "$$ Epoch: 353 | Error = 0.21764 | DeltaError = 0.01481 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 354 | Error = 0.228149 | DeltaError = 0.01051 | LR = 0.1 | Epoch Train Time = 0.72Sec\n",
      "$$ Epoch: 355 | Error = 0.227846 | DeltaError = 0.000303 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 356 | Error = 0.238308 | DeltaError = 0.010462 | LR = 0.1 | Epoch Train Time = 0.74Sec\n",
      "$$ Epoch: 357 | Error = 0.229402 | DeltaError = 0.008906 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 358 | Error = 0.246105 | DeltaError = 0.016703 | LR = 0.1 | Epoch Train Time = 1.14Sec\n",
      "$$ Epoch: 359 | Error = 0.24447 | DeltaError = 0.001634 | LR = 0.1 | Epoch Train Time = 0.99Sec\n",
      "$$ Epoch: 360 | Error = 0.210678 | DeltaError = 0.033793 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 361 | Error = 0.250013 | DeltaError = 0.039335 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 362 | Error = 0.22703 | DeltaError = 0.022983 | LR = 0.1 | Epoch Train Time = 0.94Sec\n",
      "$$ Epoch: 363 | Error = 0.239107 | DeltaError = 0.012077 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 364 | Error = 0.236677 | DeltaError = 0.00243 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 365 | Error = 0.193537 | DeltaError = 0.04314 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 366 | Error = 0.258589 | DeltaError = 0.065052 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 367 | Error = 0.246233 | DeltaError = 0.012356 | LR = 0.1 | Epoch Train Time = 0.97Sec\n",
      "$$ Epoch: 368 | Error = 0.232766 | DeltaError = 0.013467 | LR = 0.1 | Epoch Train Time = 1.13Sec\n",
      "$$ Epoch: 369 | Error = 0.276448 | DeltaError = 0.043682 | LR = 0.1 | Epoch Train Time = 1.02Sec\n",
      "$$ Epoch: 370 | Error = 0.241685 | DeltaError = 0.034763 | LR = 0.1 | Epoch Train Time = 0.98Sec\n",
      "$$ Epoch: 371 | Error = 0.231866 | DeltaError = 0.009818 | LR = 0.1 | Epoch Train Time = 0.96Sec\n",
      "$$ Epoch: 372 | Error = 0.22404 | DeltaError = 0.007827 | LR = 0.1 | Epoch Train Time = 0.94Sec\n",
      "$$ Epoch: 373 | Error = 0.23707 | DeltaError = 0.01303 | LR = 0.1 | Epoch Train Time = 0.95Sec\n",
      "$$ Epoch: 374 | Error = 0.235312 | DeltaError = 0.001758 | LR = 0.1 | Epoch Train Time = 0.94Sec\n",
      "$$ Epoch: 375 | Error = 0.224362 | DeltaError = 0.010949 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 376 | Error = 0.240721 | DeltaError = 0.016358 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 377 | Error = 0.217128 | DeltaError = 0.023593 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 378 | Error = 0.228757 | DeltaError = 0.011629 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 379 | Error = 0.260434 | DeltaError = 0.031678 | LR = 0.1 | Epoch Train Time = 0.93Sec\n",
      "$$ Epoch: 380 | Error = 0.242421 | DeltaError = 0.018013 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 381 | Error = 0.264662 | DeltaError = 0.02224 | LR = 0.1 | Epoch Train Time = 0.9Sec\n",
      "$$ Epoch: 382 | Error = 0.243079 | DeltaError = 0.021583 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 383 | Error = 0.239244 | DeltaError = 0.003834 | LR = 0.1 | Epoch Train Time = 0.92Sec\n",
      "$$ Epoch: 384 | Error = 0.240202 | DeltaError = 0.000957 | LR = 0.1 | Epoch Train Time = 0.94Sec\n",
      "$$ Epoch: 385 | Error = 0.169538 | DeltaError = 0.070663 | LR = 0.1 | Epoch Train Time = 0.83Sec\n",
      "$$ Epoch: 386 | Error = 0.234645 | DeltaError = 0.065107 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 387 | Error = 0.233551 | DeltaError = 0.001094 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 388 | Error = 0.234122 | DeltaError = 0.000571 | LR = 0.1 | Epoch Train Time = 0.66Sec\n",
      "$$ Epoch: 389 | Error = 0.23365 | DeltaError = 0.000473 | LR = 0.1 | Epoch Train Time = 0.71Sec\n",
      "$$ Epoch: 390 | Error = 0.235342 | DeltaError = 0.001693 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 391 | Error = 0.211524 | DeltaError = 0.023818 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 392 | Error = 0.257638 | DeltaError = 0.046114 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 393 | Error = 0.215798 | DeltaError = 0.04184 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 394 | Error = 0.238096 | DeltaError = 0.022298 | LR = 0.1 | Epoch Train Time = 0.65Sec\n",
      "$$ Epoch: 395 | Error = 0.252202 | DeltaError = 0.014106 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 396 | Error = 0.234767 | DeltaError = 0.017435 | LR = 0.1 | Epoch Train Time = 0.69Sec\n",
      "$$ Epoch: 397 | Error = 0.245774 | DeltaError = 0.011007 | LR = 0.1 | Epoch Train Time = 0.67Sec\n",
      "$$ Epoch: 398 | Error = 0.214893 | DeltaError = 0.030881 | LR = 0.1 | Epoch Train Time = 0.68Sec\n",
      "$$ Epoch: 399 | Error = 0.220302 | DeltaError = 0.005409 | LR = 0.1 | Epoch Train Time = 0.85Sec\n",
      "$$ Epoch: 400 | Error = 0.273262 | DeltaError = 0.05296 | LR = 0.1 | Epoch Train Time = 0.96Sec\n",
      "$$ Epoch: 401 | Error = 0.276915 | DeltaError = 0.003653 | LR = 0.1 | Epoch Train Time = 0.99Sec\n",
      "$$ Epoch: 402 | Error = 0.233239 | DeltaError = 0.043677 | LR = 0.1 | Epoch Train Time = 0.89Sec\n",
      "$$ Epoch: 403 | Error = 0.252008 | DeltaError = 0.018769 | LR = 0.1 | Epoch Train Time = 0.88Sec\n",
      "$$ Epoch: 404 | Error = 0.230924 | DeltaError = 0.021084 | LR = 0.1 | Epoch Train Time = 0.91Sec\n",
      "$$ Epoch: 405 | Error = 0.216296 | DeltaError = 0.014628 | LR = 0.1 | Epoch Train Time = 1.08Sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-344f37516048>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mneu_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moneHotTrainLables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-114-479f23892343>\u001b[0m in \u001b[0;36mtrainNeuralNetwork\u001b[1;34m(self, X, Labels, eta, batch_size, max_epoch, epsilon)\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[0mYb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_start\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[1;31m#print(Xb.shape, Yb.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwardFeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-479f23892343>\u001b[0m in \u001b[0;36mforwardFeed\u001b[1;34m(self, ip_data)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(subtype, data, dtype, copy)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdtype2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neu_net.trainNeuralNetwork(DTrain, oneHotTrainLables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralNetwork' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cd2c759d6cce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mneu_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodesInHiddenLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sigmoid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ReLu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mneu_net\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NeuralNetwork' is not defined"
     ]
    }
   ],
   "source": [
    "neu_net = NeuralNetwork(nodesInHiddenLayers, \"Sigmoid\", \"ReLu\")\n",
    "neu_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Global Params'''\n",
    "M = 100 #MiniBatch Size\n",
    "n = len(DFTrain.columns)-1\n",
    "nodesInHiddenLayers = [100]\n",
    "r = totalClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681159186392604\n",
      "0.5827889421705694\n",
      "0.26025569013431415\n",
      "0.38946628022928104\n",
      "0.14262154921532913\n",
      "0.2917815823719552\n",
      "0.5834496501560641\n",
      "0.688159408747932\n",
      "0.984204348025801\n",
      "0.2194184703492886\n",
      "0.5759445116655726\n",
      "0.8907884870356644\n",
      "0.5410640257738095\n",
      "0.4116103498381027\n",
      "0.16230006872594094\n",
      "0.29516341557941056\n",
      "0.2899631887022096\n",
      "0.3191239784258544\n",
      "0.8699641692786523\n",
      "0.45651945609314276\n",
      "0.5069547340918302\n",
      "0.976643090748276\n",
      "0.9866198691646545\n",
      "0.43752611967247274\n",
      "0.8439553414892211\n",
      "0.6210068766678049\n",
      "0.47690509333823516\n",
      "0.3012727427062489\n",
      "0.9752187520848697\n",
      "0.7668832380161009\n",
      "0.8125199991045112\n",
      "0.2745564229449183\n",
      "0.3499172946144694\n",
      "0.3251440549094864\n",
      "0.5241635288158171\n",
      "0.33939220463237607\n",
      "0.32666784492959444\n",
      "0.33321499213119743\n",
      "0.27641797013997177\n",
      "0.8808599949277839\n",
      "0.9854397296350409\n",
      "0.7702989906156735\n",
      "0.3941931772577447\n",
      "0.9043715122923546\n",
      "0.968076892347778\n",
      "0.2198123509643054\n",
      "0.7731018430416955\n",
      "0.37230192177201976\n",
      "0.8530828360220072\n",
      "0.9995908606646203\n",
      "0.26013360014313697\n",
      "0.5942934145253023\n",
      "0.7889344992920858\n",
      "0.6944776052148516\n",
      "0.8387339080553188\n",
      "0.5530947581027789\n",
      "0.9579507377042781\n",
      "0.9439528396533099\n",
      "0.9522817005791402\n",
      "0.769209686344952\n",
      "0.3819785264425849\n",
      "0.18129004898247075\n",
      "0.8011703965742002\n",
      "0.27449221925078926\n",
      "0.9594168567333197\n",
      "0.23075446205649575\n",
      "0.25567657614252687\n",
      "0.13307125819143237\n",
      "0.2730863424768568\n",
      "0.6174357849319951\n",
      "0.6228619621390246\n",
      "0.26308234196217306\n",
      "0.21996894216297158\n",
      "0.6391105319688936\n",
      "0.9987967903369497\n",
      "0.5775034000598968\n",
      "0.6052702317827325\n",
      "0.2620593999774605\n",
      "0.9158720640917657\n",
      "0.16761935416526885\n",
      "0.3407474776259899\n",
      "0.9575666628076296\n",
      "0.20306730292243408\n",
      "0.8559722066913371\n",
      "0.33354463892072317\n",
      "0.5176173081549899\n",
      "0.2909596999087293\n",
      "0.9410109296484198\n",
      "0.9863986512040116\n",
      "0.18339517432266134\n",
      "0.8553043512670776\n",
      "0.37992612875587045\n",
      "0.5609635326728032\n",
      "0.6330370313193553\n",
      "0.4190977693801268\n",
      "0.9218892877811101\n",
      "0.7987115898662396\n",
      "0.06069052077795729\n",
      "0.7889911171711413\n",
      "0.7831300505691324\n"
     ]
    }
   ],
   "source": [
    "#for layer in neu_net.layers:\n",
    "layer = neu_net.layers[-1]\n",
    "for x in layer.output:\n",
    "    print(np.amax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTrain = DFTrain.iloc[:,:-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 0: <Hidden Layer | Num_Perceptrons_Units = 10, Weights = (10, 784), Bias = (10,), Activation = Sigmoid>\n",
       "Layer 1: <Output Layer | Num_Perceptrons_Units = 26, Weights = (26, 10), Bias = (26,), Activation = Sigmoid>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6500 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
       "0       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "6495    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6496    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6497    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6498    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6499    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "      778  779  780  781  782  783  784  \n",
       "0       0    0    0    0    0    0   25  \n",
       "1       0    0    0    0    0    0   13  \n",
       "2       0    0    0    0    0    0    6  \n",
       "3       0    0    0    0    0    0    6  \n",
       "4       0    0    0    0    0    0    7  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "6495    0    0    0    0    0    0   13  \n",
       "6496    0    0    0    0    0    0    4  \n",
       "6497    0    0    0    0    0    0    3  \n",
       "6498    0    0    0    0    0    0    4  \n",
       "6499    0    0    0    0    0    0   12  \n",
       "\n",
       "[6500 rows x 785 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "files = glob(os.getcwd()+ \"\\\\data\\\\*csv\")\n",
    "dataframes = [pd.read_csv(f, header = None) for f in files]\n",
    "dataframes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: This function is deprecated. Please call randint(0, 9 + 1) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8, 8, 3, 7, 7],\n",
       "       [0, 4, 2, 5, 2],\n",
       "       [2, 2, 1, 0, 8],\n",
       "       [4, 0, 9, 6, 2],\n",
       "       [4, 1, 5, 3, 4]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "np.random.random_integers(0,9, (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: This function is deprecated. Please call randint(0, 9 + 1) instead\n",
      "  \n",
      "C:\\Users\\Aman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: This function is deprecated. Please call randint(0, 9 + 1) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "p = np.random.random_integers(0,9, (5,20))\n",
    "q = np.random.random_integers(0,9, (5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8, 8, 3, 7, 7, 0, 4, 2, 5, 2, 2, 2, 1, 0, 8, 4, 0, 9, 6, 2],\n",
       "        [4, 1, 5, 3, 4, 4, 3, 7, 1, 1, 7, 7, 0, 2, 9, 9, 3, 2, 5, 8],\n",
       "        [1, 0, 7, 6, 2, 0, 8, 2, 5, 1, 8, 1, 5, 4, 2, 8, 3, 5, 0, 9],\n",
       "        [3, 6, 3, 4, 7, 6, 3, 9, 0, 4, 4, 5, 7, 6, 6, 2, 4, 2, 7, 1],\n",
       "        [6, 6, 0, 7, 2, 3, 5, 4, 2, 4, 3, 7, 9, 0, 0, 5, 9, 6, 6, 5]]),\n",
       " array([[6, 4, 7, 3, 9, 2],\n",
       "        [3, 8, 7, 1, 5, 9],\n",
       "        [3, 0, 6, 2, 3, 4],\n",
       "        [8, 9, 8, 5, 2, 7],\n",
       "        [5, 9, 0, 9, 8, 6]]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3, 6, 3, 4, 7, 6, 3, 9, 0, 4, 4, 5, 7, 6, 6, 2, 4, 2, 7, 1],\n",
       "        [4, 1, 5, 3, 4, 4, 3, 7, 1, 1, 7, 7, 0, 2, 9, 9, 3, 2, 5, 8],\n",
       "        [8, 8, 3, 7, 7, 0, 4, 2, 5, 2, 2, 2, 1, 0, 8, 4, 0, 9, 6, 2],\n",
       "        [1, 0, 7, 6, 2, 0, 8, 2, 5, 1, 8, 1, 5, 4, 2, 8, 3, 5, 0, 9],\n",
       "        [6, 6, 0, 7, 2, 3, 5, 4, 2, 4, 3, 7, 9, 0, 0, 5, 9, 6, 6, 5]]),\n",
       " array([[8, 9, 8, 5, 2, 7],\n",
       "        [3, 8, 7, 1, 5, 9],\n",
       "        [6, 4, 7, 3, 9, 2],\n",
       "        [3, 0, 6, 2, 3, 4],\n",
       "        [5, 9, 0, 9, 8, 6]]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "pdash, qdash = shuffle(p,q)\n",
    "pdash, qdash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63260414, 0.56914641, 0.60456376, 0.69947017, 0.50117971],\n",
       "       [0.5303549 , 0.66167087, 0.6954773 , 0.53412352, 0.6399376 ],\n",
       "       [0.7091629 , 0.55211061, 0.5461999 , 0.52706773, 0.55470451],\n",
       "       [0.72683506, 0.69246806, 0.54287967, 0.69343437, 0.56809273],\n",
       "       [0.60628054, 0.71910568, 0.69373714, 0.58324576, 0.54374052]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.random.rand(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97862378, 0.81168315, 0.17194101, 0.81622475, 0.27407375],\n",
       "       [0.89132195, 0.20920212, 0.18532822, 0.10837689, 0.21969749],\n",
       "       [0.43170418, 0.94002982, 0.81764938, 0.33611195, 0.17541045],\n",
       "       [0.12156912, 0.67074908, 0.82585276, 0.13670659, 0.57509333],\n",
       "       [0.54340494, 0.27836939, 0.42451759, 0.84477613, 0.00471886]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.random.shuffle(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   1,   1,   1,   2,   2,   5,  23,  45,  60,  72,\n",
       "         89, 136, 200, 223, 201,  74,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   1,   1,   2,   1,   1,   1,   3,  30, 109, 136, 177, 214,\n",
       "        235, 244, 229, 210, 156, 114,  91,  27,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   3,  14,  27,  41,  72, 163, 189, 214, 244, 247,\n",
       "        237, 208, 182, 109,  46,  26,  12,   3,   1,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 112, 159, 214, 243, 250, 253, 240, 225,\n",
       "        177, 138,  81,  21,   3,   1,   1,   2,   2,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 240, 251, 252, 243, 227, 157,\n",
       "         82,  54,  24,   5,   2,   1,   1,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 248, 254, 248, 125,\n",
       "          4,   1,   1,   2,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 254, 255,\n",
       "        241, 120,   1,   1,   1,   0,   0,   0,   0,   0,   0,   1,   1,\n",
       "          1,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        253, 255, 209,  79,   0,   0,   0,   0,   1,   2,   2,   2,   1,\n",
       "          3,   5,   7,   8,   5,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 246, 254, 194,  12,   1,   0,   1,   2,   5,  22,  69,\n",
       "         92,  93, 109, 125, 138, 138, 115,  37,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 237, 252, 192,  10,   1,   4,  33, 117, 168,\n",
       "        189, 228, 243, 243, 245, 231, 206, 130,  73,  21,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 221, 250, 235, 140, 162, 230, 244,\n",
       "        255, 251, 244, 214, 163, 128,  65,  13,   1,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0, 224, 248, 253, 252, 255,\n",
       "        253, 239, 217, 148,  97,  51,   9,   2,   1,   1,   1,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 218, 246, 254,\n",
       "        238, 214, 137,  58,  29,  11,   2,   3,   1,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 196,\n",
       "        243, 249, 141,  16,   1,   1,   2,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 175, 240, 251, 190,  51,   1,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 141, 236, 255, 247,  93,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  99, 234, 255, 253, 134,   7,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  89, 246, 254, 254, 220,  40,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,  68, 229, 251, 253,\n",
       "        242,  68,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15,  71,\n",
       "        150, 180, 110,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   5], dtype=int64),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
