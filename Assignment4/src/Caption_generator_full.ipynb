{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "tPc-Vc0SDhNb",
    "outputId": "763dcdc5-e9e3-4057-c50b-2eedf139774d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0NAkjfkDunx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from collections import Counter\n",
    "from skimage import io, transform\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Ar-pjO6VDvyM",
    "outputId": "a4c2ba3a-1a7e-4e21-8820-83b1245ce8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Let's use 0 GPUs!\n"
     ]
    }
   ],
   "source": [
    "VOCAB = {}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "parallel = True\n",
    "platform = \"local\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuV9OO2AD772"
   },
   "source": [
    "### Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bARgdNI3D4YX"
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        return img\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return image\n",
    "\n",
    "\n",
    "IMAGE_RESIZE = (256, 256)\n",
    "# Sequentially compose the transforms\n",
    "img_transform = transforms.Compose([Rescale(IMAGE_RESIZE), ToTensor()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TILWv_RDEElV"
   },
   "source": [
    "### Captions Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "zR_D_a8UD_-n",
    "outputId": "b16eaf90-cbcc-4bbe-efd3-97aa024cfcfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE = 10700\n"
     ]
    }
   ],
   "source": [
    "class CaptionsPreprocessing:\n",
    "    \"\"\"Preprocess the captions, generate vocabulary and convert words to tensor tokens\n",
    "    Args:\n",
    "        captions_file_path (string): captions tsv file path\n",
    "    \"\"\"\n",
    "    def __init__(self, captions_file_path):\n",
    "        self.captions_file_path = captions_file_path\n",
    "\n",
    "        # Read raw captions\n",
    "        self.raw_captions_dict = self.read_raw_captions()\n",
    "\n",
    "        # Preprocess captions\n",
    "        self.captions_dict = self.process_captions()\n",
    "\n",
    "        # Create vocabulary\n",
    "        self.start = \"<start>\"\n",
    "        self.end = \"<end>\"\n",
    "        self.oov = \"<unk>\"\n",
    "        self.pad = \"<pad>\"\n",
    "        self.vocab = self.generate_vocabulary()\n",
    "        self.word2index = self.convert_word2index()        \n",
    "        self.index2word = self.convert_index2word()\n",
    "        self.max_len_caption = 50\n",
    "\n",
    "    def read_raw_captions(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            Dictionary with raw captions list keyed by image ids (integers)\n",
    "        \"\"\"\n",
    "        captions_dict = {}\n",
    "        with open(self.captions_file_path, 'r', encoding='utf-8') as f:\n",
    "            for img_caption_line in f.readlines():\n",
    "                img_captions = img_caption_line.strip().split('\\t')\n",
    "                captions_dict[int(img_captions[0])] = img_captions[1:]\n",
    "\n",
    "        return captions_dict \n",
    "\n",
    "    def process_captions(self):\n",
    "        \"\"\"\n",
    "        Use this function to generate dictionary and other preprocessing on captions\n",
    "        \"\"\"\n",
    "\n",
    "        raw_captions_dict = self.raw_captions_dict \n",
    "        \n",
    "        # Do the preprocessing here                \n",
    "        captions_dict = raw_captions_dict\n",
    "\n",
    "        return captions_dict\n",
    "\n",
    " \n",
    "\n",
    "    def generate_vocabulary(self):\n",
    "        \"\"\"\n",
    "        Use this function to generate dictionary and other preprocessing on captions\n",
    "        \"\"\"\n",
    "        captions_dict = self.captions_dict\n",
    "\n",
    "        # Generate the vocabulary\n",
    "        \n",
    "        all_captions = \"\"        \n",
    "        for cap_lists in captions_dict.values():\n",
    "            all_captions += \" \".join(cap_lists)\n",
    "        all_captions = all_captions.lower().replace(\".\", \"\").split(\" \")\n",
    "        \n",
    "        vocab = {self.pad :1, self.oov :1, self.start :1, self.end :1}\n",
    "        vocab_update = Counter(all_captions) \n",
    "        vocab_update = {k:v for k,v in vocab_update.items() if v >= freq_threshold}\n",
    "        vocab.update(vocab_update)\n",
    "        vocab_size = len(vocab)   \n",
    "        VOCAB.update(vocab)\n",
    "        print(\"VOCAB SIZE =\", vocab_size)\n",
    "        return vocab\n",
    "    \n",
    "    def convert_word2index(self):\n",
    "        word2index = {}\n",
    "        vocab = self.vocab\n",
    "        idx = 0\n",
    "        for k, v in vocab.items():\n",
    "            word2index[k] = idx\n",
    "            idx +=1\n",
    "        \n",
    "        return word2index\n",
    "    \n",
    "    def convert_index2word(self):\n",
    "        index2word = {}\n",
    "        vocab = self.vocab\n",
    "        idx = 0\n",
    "        \n",
    "        for k, v in vocab.items():\n",
    "            index2word[idx] = k\n",
    "            idx +=1\n",
    "        \n",
    "        return index2word\n",
    "\n",
    " \n",
    "\n",
    "    def captions_transform(self, img_caption_list, max_len):\n",
    "        \"\"\"\n",
    "        Use this function to generate tensor tokens for the text captions\n",
    "        Args:\n",
    "            img_caption_list: List of captions for a particular image\n",
    "        \"\"\"\n",
    "        word2index = self.word2index\n",
    "        vocab = self.vocab\n",
    "        #index2word = self.index2word        \n",
    "        #embed = self.embed\n",
    "        start = self.start\n",
    "        end = self.end\n",
    "        oov = self.oov\n",
    "        #print(\"MX LEN\", max_len)\n",
    "        processed_list = list(map(lambda x: start + \" \"+ x + \" \" + end, img_caption_list))\n",
    "        processed_list = list(map(lambda x: x.lower().replace(\".\", \"\").split(\" \"), processed_list))\n",
    "        processed_list = list(map(lambda x: list(map(lambda y: word2index[y] if y in vocab else word2index[oov],x)),\n",
    "                                  processed_list))\n",
    "        processed_list = list(map(lambda x: x + ( [0] * int(max_len - len(x) + 2) ),processed_list))\n",
    "        \n",
    "        # Generate tensors\n",
    "        #print(np.array(processed_list).shape)\n",
    "        processed_list = torch.LongTensor(processed_list)\n",
    "        #processed_captions = embed(processed_list)   \n",
    "        #print(processed_captions)    \n",
    "        \n",
    "        #return torch.zeros(len(img_caption_list), 10)\n",
    "        return processed_list\n",
    "\n",
    "\n",
    "if platform == \"colab\":\n",
    "    CAPTIONS_FILE_PATH = '/content/drive/My Drive/A4/train_captions.tsv'\n",
    "else:\n",
    "    CAPTIONS_FILE_PATH = \"../data/train_captions.tsv\"\n",
    "    \n",
    "embedding_dim = 256\n",
    "freq_threshold = 4\n",
    "captions_preprocessing_obj = CaptionsPreprocessing(CAPTIONS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cE5iXNPENzj"
   },
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLxKe6XNESUq"
   },
   "outputs": [],
   "source": [
    "class ImageCaptionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, captions_dict, img_transform=None, captions_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Directory with all the images.\n",
    "            captions_dict: Dictionary with captions list keyed by image ids (integers)\n",
    "            img_transform (callable, optional): Optional transform to be applied\n",
    "                on the image sample.\n",
    "\n",
    "            captions_transform: (callable, optional): Optional transform to be applied\n",
    "                on the caption sample (list).\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.captions_dict = captions_dict\n",
    "        self.img_transform = img_transform\n",
    "        self.captions_transform = captions_transform\n",
    "\n",
    "        self.image_ids = list(captions_dict.keys())\n",
    "        self.max_len = max([max(list(map(lambda x: len(x.lower().replace(\".\", \"\").split(\" \")), v))) for k,v in captions_dict.items()])\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, 'image_{}.jpg'.format(self.image_ids[idx]))\n",
    "        image = io.imread(img_name)\n",
    "        captions = self.captions_dict[self.image_ids[idx]]\n",
    "        if self.img_transform:\n",
    "            image = self.img_transform(image)\n",
    "\n",
    "        if self.captions_transform:            \n",
    "            captions = self.captions_transform(captions, self.max_len)\n",
    "\n",
    "        sample = {'image': image, 'captions': captions}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqlKdxa3ESwY"
   },
   "outputs": [],
   "source": [
    "#ENCODER\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, filters, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            channels: Int: Number of Input channels to 1st convolutional layer\n",
    "            kernel_size: integer, Symmetric Conv Window = (kernel_size, kernel_size)\n",
    "            filters: python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "            stride: Tuple: (stride, stride)\n",
    "        \"\"\"\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        #N, in_channels , H, W = shape\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "        padding = (1,1)\n",
    "        stride = (stride, stride)\n",
    "        self.conv1 = nn.Conv2d(in_channels = channels, out_channels = F1, kernel_size=(1,1), stride=stride, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        self.relu = nn.ReLU(inplace=True) \n",
    "        self.conv2 = nn.Conv2d(in_channels = F1, out_channels = F2, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(F2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = F2, out_channels = F3, kernel_size=(1,1), stride=stride, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(F3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_residual = x #backup x for residual connection\n",
    "        \n",
    "        #stage 1 main path\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #print(\"RESI:\", x.shape)\n",
    "        \n",
    "        #stage 2 main path\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        #print(\"RESI:\", x.shape)\n",
    "        \n",
    "        #stage 3 main path\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        #print(\"RESI:\", x.shape)\n",
    "        \n",
    "        x += x_residual #add output with residual connection\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, filters, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            channels: Int: Number of Input channels to 1st convolutional layer\n",
    "            kernel_size: integer, Symmetric Conv Window = (kernel_size, kernel_size)\n",
    "            filters: python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "            stride: Tuple: (stride, stride)\n",
    "        \"\"\"\n",
    "        super(ConvolutionalBlock, self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "        padding = (1,1)\n",
    "        stride = (stride, stride)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = channels, out_channels = F1, kernel_size=(1,1), stride=stride, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        self.relu = nn.ReLU(inplace=True) \n",
    "        self.conv2 = nn.Conv2d(in_channels = F1, out_channels = F2, kernel_size=kernel_size, stride=(1,1), padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(F2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = F2, out_channels = F3, kernel_size=(1,1), stride=(1,1), padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(F3)\n",
    "        self.conv4 = nn.Conv2d(in_channels = channels, out_channels = F3, kernel_size=(1,1), stride=stride, padding=0)\n",
    "        self.bn4 = nn.BatchNorm2d(F3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_residual = x #backup x for residual connection\n",
    "        \n",
    "        #stage 1 main path\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #print(\"CONV:\", x.shape)\n",
    "        \n",
    "        #stage 2 main path\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        #print(\"CONV:\", x.shape)\n",
    "        \n",
    "        #stage 3 main path\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        #print(\"CONV:\", x.shape)\n",
    "        \n",
    "        #residual connection\n",
    "        x_residual = self.conv4(x_residual)\n",
    "        x_residual = self.bn4(x_residual)\n",
    "        x += x_residual #add output with residual connection\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, input_shape = (256, 256, 3), classes = 5):\n",
    "        \"\"\"\n",
    "        It Implements Famous Resnet50 Architecture\n",
    "        Args:\n",
    "            input_shape(tuple):(callable, optional): dimensions of image sample\n",
    "            classes(int):(callable, optional): Final output classes of softmax layer.\n",
    "        \"\"\"\n",
    "        super(ResNet50, self).__init__()\n",
    "        \n",
    "        self.pad = nn.ZeroPad2d((1, 1, 3, 3))        \n",
    "        ###STAGE1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels=64, kernel_size=(7,7), stride = (2,2), padding=1) # convolve each of our 3-channel images with 6 different 5x5 kernels, giving us 6 feature maps\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64) #BatchNorm\n",
    "        self.pool1 = nn.MaxPool2d((3,3), stride=(2,2), padding=1, dilation=1)\n",
    "        \n",
    "        ###STAGE2 channels, kernel_size=3, filters, stride=1, stage\n",
    "        self.conv_block1 = ConvolutionalBlock(channels = 64, kernel_size = 3, filters = [64, 64, 256],stride = 1)\n",
    "        self.residual_block1 = ResidualBlock(channels = 256, kernel_size = 3, filters = [64, 64, 256])\n",
    "        \n",
    "        ###STAGE3 \n",
    "        self.conv_block2 = ConvolutionalBlock(channels = 256, kernel_size = 3, filters = [128, 128, 512],stride = 2)\n",
    "        self.residual_block2 = ResidualBlock(channels = 512, kernel_size = 3, filters = [128, 128, 512],)\n",
    "        \n",
    "        ###STAGE4 \n",
    "        self.conv_block3 = ConvolutionalBlock(channels = 512, kernel_size = 3, filters = [256, 256, 1024], stride = 2)\n",
    "        self.residual_block3 = ResidualBlock(channels = 1024, kernel_size = 3, filters = [256, 256, 1024])\n",
    "        \n",
    "        ###STAGE5 \n",
    "        self.conv_block4 = ConvolutionalBlock(channels = 1024, kernel_size = 3, filters = [512, 512, 2048], stride = 2)\n",
    "        self.residual_block4 = ResidualBlock(channels = 2048, kernel_size = 3, filters = [512, 512, 2048])\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "        self.fc1 = nn.Linear(in_features=2048, out_features=classes, bias = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"IP_SIZE:\", x.shape)\n",
    "        \n",
    "        ###STAGE1        \n",
    "        #print(\"\\n STAGE1\")\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.pool1(x)\n",
    "        #print(\"OP_STAGE1_SIZE:\", x.shape)\n",
    "        \n",
    "        ###STAGE2 \n",
    "        #print(\"\\n STAGE2\")\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.residual_block1(x)\n",
    "        #print(\"OP_STAGE2_SIZE:\", x.shape)\n",
    "        \n",
    "        ###STAGE3 \n",
    "        #print(\"\\n STAGE3\")\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.residual_block2(x)\n",
    "        #print(\"OP_STAGE3_SIZE:\", x.shape)\n",
    "        \n",
    "        ###STAGE4  \n",
    "        #print(\"\\n STAGE4\")\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.residual_block3(x)\n",
    "        #print(\"OP_STAGE4_SIZE:\", x.shape)\n",
    "        \n",
    "        ###STAGE5  \n",
    "        #print(\"\\n STAGE5\")\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.residual_block4(x)\n",
    "        x = self.residual_block4(x)\n",
    "        #print(\"OP_STAGE5_SIZE:\", x.shape)\n",
    "        \n",
    "        x = self.adaptive_pool(x)\n",
    "        #print(\"OP_ADAPTIVEPOOL_SHAPE\", x.shape)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # Flatten Vector\n",
    "        x = self.fc1(x)\n",
    "        #print(\"OP_FC1_SIZE:\", x.shape)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class Encoder(nn.Module):    \n",
    "    def __init__(self, embed_dim):\n",
    "        \"\"\"\n",
    "        CNN ENCODER\n",
    "        Args:\n",
    "            embed_dim(int): embedding dimension ie output dimension of last FC Layer\n",
    "        Returns:\n",
    "            x: Feature vector of size(BatchSize, embed_dim)\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.resnet50 = ResNet50(classes = embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aFX2bueEa6w"
   },
   "outputs": [],
   "source": [
    "#DECODER\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, lstm_hidden_size, lstm_layers = 1):\n",
    "        \"\"\"\n",
    "        It Implements Famous Resnet50 Architecture\n",
    "        Args:\n",
    "            embed_dim(int): embedding dimension ie output dimension of last FC Layer\n",
    "            lstm_hidden_size(int): size of hidden units of LSTM Cell\n",
    "            lstm_layers(int, optional): Number of recurrent layers\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = len(VOCAB)\n",
    "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = lstm_hidden_size,\n",
    "                            num_layers = lstm_layers, batch_first = True)\n",
    "        \n",
    "        self.linear = nn.Linear(lstm_hidden_size, self.vocab_size)        \n",
    "        self.embed = nn.Embedding(self.vocab_size, embed_dim)\n",
    "        \n",
    "    def forward(self, image_features, embedded_captions_list):\n",
    "        embedded_captions_list = self.embed(embedded_captions_list)\n",
    "        \n",
    "        #print(\"Decoder Shape 1\",image_features.shape, embedded_captions_list.shape)\n",
    "        \n",
    "        image_features = torch.Tensor.repeat_interleave(image_features, repeats=5 , dim=0)\n",
    "        image_features = image_features.unsqueeze(1)\n",
    "        #print(\"Decoder Shape Processed\",image_features.shape, embedded_captions_list[:,:-1].shape)\n",
    "        \n",
    "        input_lstm = torch.cat((image_features, embedded_captions_list[:,1:]), dim = 1)\n",
    "        \n",
    "        lstm_outputs, _ = self.lstm(input_lstm)        \n",
    "        #print(\"LSTM OP SHAPE\", lstm_outputs.shape)\n",
    "        lstm_outputs = self.linear(lstm_outputs)\n",
    "        #print(\"LSTM OUTPUT SHAPE\", lstm_outputs.shape)\n",
    "        return lstm_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "79D1QrHWEbyz",
    "outputId": "bc1591c6-0c63-47c7-db50-f5da775aabb9"
   },
   "outputs": [],
   "source": [
    "class ImageCaptionsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageCaptionsNet, self).__init__()\n",
    "\n",
    "        # Define your architecture here\n",
    "        \n",
    "        ##CNN ENCODER RESNET-50\n",
    "        \n",
    "        self.Encoder = Encoder(embed_dim = embedding_dim)\n",
    "        self.Decoder = Decoder(embedding_dim, units, 1)\n",
    "        #self.Decoder = DecoderRNN(256, 512, len(captions_preprocessing_obj.vocab), 1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = image_batch, captions_batch\n",
    "\n",
    "        # Forward Propogation\n",
    "        x = self.Encoder(image_batch)\n",
    "        #print(x.shape)\n",
    "        x = self.Decoder(x, captions_batch)\n",
    "        return x\n",
    "    \n",
    "units = 512\n",
    "net = ImageCaptionsNet()\n",
    "net = net.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_GtiDw-XIDs"
   },
   "outputs": [],
   "source": [
    "def create_checkpoint(path,model, optim_obj, loss_obj,iteration, epoch):\n",
    "    checkpoint = {'epoch': epoch,\n",
    "                  'iteration': iteration,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optim_obj.state_dict(),\n",
    "                  'loss': loss_obj}\n",
    "\n",
    "    if platform == \"colab\":\n",
    "        directory = '/content/drive/My Drive/A4/checkpoint/'\n",
    "    else:\n",
    "        directory = '../checkpoint/'\n",
    "\n",
    "    torch.save(checkpoint, directory + path)\n",
    "    \n",
    "def restore_checkpoint(path):\n",
    "    if platform == \"colab\":\n",
    "        directory = '/content/drive/My Drive/A4/checkpoint/'\n",
    "    else:\n",
    "        directory = '../checkpoint/'\n",
    "        \n",
    "    checkpoint = torch.load(directory + path)\n",
    "    epoch = checkpoint['epoch']\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "    iteration = checkpoint['iteration']\n",
    "    optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
    "    loss_obj = checkpoint['loss']\n",
    "    print(\"Iterations = {}, Epoch = {}, loss = {}\", iteration, epoch, loss.item())\n",
    "    return optimizer_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a6294abd2199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mIMAGE_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/test/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"caption_chkpt_multi.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-e44e364b9954>\u001b[0m in \u001b[0;36mrestore_checkpoint\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../checkpoint/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmodel_state_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    582\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m         \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    135\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "#Test Dir path\n",
    "if platform == \"colab\":\n",
    "    IMAGE_DIR = '/content/drive/My Drive/train_images/'\n",
    "else:\n",
    "    IMAGE_DIR = '../data/test/'\n",
    "    \n",
    "net.load_state_dict(restore_checkpoint(\"caption_chkpt_multi.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3l4HKg15EhS7"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KgajTBg4EeYv",
    "outputId": "c912a1a5-d26d-44ca-b534-3f71c65c8ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$----EPOCH 1----$$$$$$\n",
      "ITERATION:[1/906] | LOSS: 9.264903 | EPOCH = [1/3] | TIME ELAPSED =1.68Mins\n",
      "ITERATION:[2/906] | LOSS: 6.975613 | EPOCH = [1/3] | TIME ELAPSED =2.02Mins\n",
      "ITERATION:[3/906] | LOSS: 3.941076 | EPOCH = [1/3] | TIME ELAPSED =2.37Mins\n",
      "ITERATION:[4/906] | LOSS: 1.786357 | EPOCH = [1/3] | TIME ELAPSED =2.72Mins\n",
      "ITERATION:[5/906] | LOSS: 1.684843 | EPOCH = [1/3] | TIME ELAPSED =3.07Mins\n",
      "ITERATION:[6/906] | LOSS: 1.666744 | EPOCH = [1/3] | TIME ELAPSED =3.43Mins\n",
      "ITERATION:[7/906] | LOSS: 1.807286 | EPOCH = [1/3] | TIME ELAPSED =3.82Mins\n",
      "ITERATION:[8/906] | LOSS: 1.802248 | EPOCH = [1/3] | TIME ELAPSED =4.17Mins\n",
      "ITERATION:[9/906] | LOSS: 1.689982 | EPOCH = [1/3] | TIME ELAPSED =4.52Mins\n",
      "ITERATION:[10/906] | LOSS: 1.795318 | EPOCH = [1/3] | TIME ELAPSED =4.89Mins\n",
      "ITERATION:[11/906] | LOSS: 1.724378 | EPOCH = [1/3] | TIME ELAPSED =5.22Mins\n",
      "ITERATION:[12/906] | LOSS: 1.718204 | EPOCH = [1/3] | TIME ELAPSED =5.57Mins\n",
      "ITERATION:[13/906] | LOSS: 1.656345 | EPOCH = [1/3] | TIME ELAPSED =5.91Mins\n",
      "ITERATION:[14/906] | LOSS: 1.729122 | EPOCH = [1/3] | TIME ELAPSED =6.26Mins\n",
      "ITERATION:[15/906] | LOSS: 1.717565 | EPOCH = [1/3] | TIME ELAPSED =6.62Mins\n",
      "ITERATION:[16/906] | LOSS: 1.740516 | EPOCH = [1/3] | TIME ELAPSED =6.96Mins\n",
      "ITERATION:[17/906] | LOSS: 1.729274 | EPOCH = [1/3] | TIME ELAPSED =7.3Mins\n",
      "ITERATION:[18/906] | LOSS: 1.640774 | EPOCH = [1/3] | TIME ELAPSED =7.66Mins\n",
      "ITERATION:[19/906] | LOSS: 1.639627 | EPOCH = [1/3] | TIME ELAPSED =8.07Mins\n",
      "ITERATION:[20/906] | LOSS: 1.685389 | EPOCH = [1/3] | TIME ELAPSED =8.43Mins\n",
      "ITERATION:[21/906] | LOSS: 1.778314 | EPOCH = [1/3] | TIME ELAPSED =8.82Mins\n",
      "ITERATION:[22/906] | LOSS: 1.756092 | EPOCH = [1/3] | TIME ELAPSED =9.16Mins\n",
      "ITERATION:[23/906] | LOSS: 1.6941 | EPOCH = [1/3] | TIME ELAPSED =9.51Mins\n",
      "ITERATION:[24/906] | LOSS: 1.728382 | EPOCH = [1/3] | TIME ELAPSED =9.86Mins\n",
      "ITERATION:[25/906] | LOSS: 1.665418 | EPOCH = [1/3] | TIME ELAPSED =10.22Mins\n",
      "ITERATION:[26/906] | LOSS: 1.710252 | EPOCH = [1/3] | TIME ELAPSED =10.57Mins\n",
      "ITERATION:[27/906] | LOSS: 1.760285 | EPOCH = [1/3] | TIME ELAPSED =10.94Mins\n",
      "ITERATION:[28/906] | LOSS: 1.618637 | EPOCH = [1/3] | TIME ELAPSED =11.3Mins\n",
      "ITERATION:[29/906] | LOSS: 1.674144 | EPOCH = [1/3] | TIME ELAPSED =11.64Mins\n",
      "ITERATION:[30/906] | LOSS: 1.69047 | EPOCH = [1/3] | TIME ELAPSED =11.99Mins\n",
      "ITERATION:[31/906] | LOSS: 1.709847 | EPOCH = [1/3] | TIME ELAPSED =12.36Mins\n",
      "ITERATION:[32/906] | LOSS: 1.694395 | EPOCH = [1/3] | TIME ELAPSED =12.72Mins\n",
      "ITERATION:[33/906] | LOSS: 1.528873 | EPOCH = [1/3] | TIME ELAPSED =13.07Mins\n",
      "ITERATION:[34/906] | LOSS: 1.612698 | EPOCH = [1/3] | TIME ELAPSED =13.42Mins\n",
      "ITERATION:[35/906] | LOSS: 1.657964 | EPOCH = [1/3] | TIME ELAPSED =13.87Mins\n",
      "ITERATION:[36/906] | LOSS: 1.664332 | EPOCH = [1/3] | TIME ELAPSED =14.23Mins\n",
      "ITERATION:[37/906] | LOSS: 1.69157 | EPOCH = [1/3] | TIME ELAPSED =14.59Mins\n",
      "ITERATION:[38/906] | LOSS: 1.67592 | EPOCH = [1/3] | TIME ELAPSED =14.94Mins\n",
      "ITERATION:[39/906] | LOSS: 1.715586 | EPOCH = [1/3] | TIME ELAPSED =15.29Mins\n",
      "ITERATION:[40/906] | LOSS: 1.730906 | EPOCH = [1/3] | TIME ELAPSED =15.65Mins\n",
      "ITERATION:[41/906] | LOSS: 1.755023 | EPOCH = [1/3] | TIME ELAPSED =16.0Mins\n",
      "ITERATION:[42/906] | LOSS: 1.686358 | EPOCH = [1/3] | TIME ELAPSED =16.34Mins\n",
      "ITERATION:[43/906] | LOSS: 1.57672 | EPOCH = [1/3] | TIME ELAPSED =16.73Mins\n",
      "ITERATION:[44/906] | LOSS: 1.66666 | EPOCH = [1/3] | TIME ELAPSED =17.07Mins\n",
      "ITERATION:[45/906] | LOSS: 1.73527 | EPOCH = [1/3] | TIME ELAPSED =17.43Mins\n",
      "ITERATION:[46/906] | LOSS: 1.722839 | EPOCH = [1/3] | TIME ELAPSED =17.78Mins\n",
      "ITERATION:[47/906] | LOSS: 1.587896 | EPOCH = [1/3] | TIME ELAPSED =18.12Mins\n",
      "ITERATION:[48/906] | LOSS: 1.525258 | EPOCH = [1/3] | TIME ELAPSED =18.47Mins\n",
      "ITERATION:[49/906] | LOSS: 1.653658 | EPOCH = [1/3] | TIME ELAPSED =18.82Mins\n",
      "ITERATION:[50/906] | LOSS: 1.730259 | EPOCH = [1/3] | TIME ELAPSED =19.19Mins\n",
      "ITERATION:[51/906] | LOSS: 1.683678 | EPOCH = [1/3] | TIME ELAPSED =19.54Mins\n",
      "ITERATION:[52/906] | LOSS: 1.712396 | EPOCH = [1/3] | TIME ELAPSED =19.89Mins\n",
      "ITERATION:[53/906] | LOSS: 1.61567 | EPOCH = [1/3] | TIME ELAPSED =20.25Mins\n",
      "ITERATION:[54/906] | LOSS: 1.587472 | EPOCH = [1/3] | TIME ELAPSED =20.59Mins\n",
      "ITERATION:[55/906] | LOSS: 1.732072 | EPOCH = [1/3] | TIME ELAPSED =20.95Mins\n",
      "ITERATION:[56/906] | LOSS: 1.620864 | EPOCH = [1/3] | TIME ELAPSED =21.3Mins\n",
      "ITERATION:[57/906] | LOSS: 1.582183 | EPOCH = [1/3] | TIME ELAPSED =21.64Mins\n",
      "ITERATION:[58/906] | LOSS: 1.62023 | EPOCH = [1/3] | TIME ELAPSED =21.99Mins\n",
      "ITERATION:[59/906] | LOSS: 1.60999 | EPOCH = [1/3] | TIME ELAPSED =22.34Mins\n",
      "ITERATION:[60/906] | LOSS: 1.661707 | EPOCH = [1/3] | TIME ELAPSED =22.69Mins\n",
      "ITERATION:[61/906] | LOSS: 1.576349 | EPOCH = [1/3] | TIME ELAPSED =23.05Mins\n",
      "ITERATION:[62/906] | LOSS: 1.61882 | EPOCH = [1/3] | TIME ELAPSED =23.4Mins\n",
      "ITERATION:[63/906] | LOSS: 1.683008 | EPOCH = [1/3] | TIME ELAPSED =23.73Mins\n",
      "ITERATION:[64/906] | LOSS: 1.710069 | EPOCH = [1/3] | TIME ELAPSED =24.08Mins\n",
      "ITERATION:[65/906] | LOSS: 1.640906 | EPOCH = [1/3] | TIME ELAPSED =24.43Mins\n",
      "ITERATION:[66/906] | LOSS: 1.63042 | EPOCH = [1/3] | TIME ELAPSED =24.77Mins\n",
      "ITERATION:[67/906] | LOSS: 1.550956 | EPOCH = [1/3] | TIME ELAPSED =25.12Mins\n",
      "ITERATION:[68/906] | LOSS: 1.740151 | EPOCH = [1/3] | TIME ELAPSED =25.47Mins\n",
      "ITERATION:[69/906] | LOSS: 1.611457 | EPOCH = [1/3] | TIME ELAPSED =25.81Mins\n",
      "ITERATION:[70/906] | LOSS: 1.515597 | EPOCH = [1/3] | TIME ELAPSED =26.17Mins\n",
      "ITERATION:[71/906] | LOSS: 1.63031 | EPOCH = [1/3] | TIME ELAPSED =26.51Mins\n",
      "ITERATION:[72/906] | LOSS: 1.54052 | EPOCH = [1/3] | TIME ELAPSED =26.87Mins\n",
      "ITERATION:[73/906] | LOSS: 1.530716 | EPOCH = [1/3] | TIME ELAPSED =27.23Mins\n",
      "ITERATION:[74/906] | LOSS: 1.619206 | EPOCH = [1/3] | TIME ELAPSED =27.59Mins\n",
      "ITERATION:[75/906] | LOSS: 1.7185 | EPOCH = [1/3] | TIME ELAPSED =27.96Mins\n",
      "ITERATION:[76/906] | LOSS: 1.647855 | EPOCH = [1/3] | TIME ELAPSED =28.31Mins\n",
      "ITERATION:[77/906] | LOSS: 1.621727 | EPOCH = [1/3] | TIME ELAPSED =28.74Mins\n",
      "ITERATION:[78/906] | LOSS: 1.69082 | EPOCH = [1/3] | TIME ELAPSED =29.09Mins\n",
      "ITERATION:[79/906] | LOSS: 1.592638 | EPOCH = [1/3] | TIME ELAPSED =29.44Mins\n",
      "ITERATION:[80/906] | LOSS: 1.592719 | EPOCH = [1/3] | TIME ELAPSED =29.79Mins\n",
      "ITERATION:[81/906] | LOSS: 1.667198 | EPOCH = [1/3] | TIME ELAPSED =30.14Mins\n",
      "ITERATION:[82/906] | LOSS: 1.539694 | EPOCH = [1/3] | TIME ELAPSED =30.49Mins\n",
      "ITERATION:[83/906] | LOSS: 1.623073 | EPOCH = [1/3] | TIME ELAPSED =30.87Mins\n",
      "ITERATION:[84/906] | LOSS: 1.506565 | EPOCH = [1/3] | TIME ELAPSED =31.22Mins\n",
      "ITERATION:[85/906] | LOSS: 1.660743 | EPOCH = [1/3] | TIME ELAPSED =31.58Mins\n",
      "ITERATION:[86/906] | LOSS: 1.588345 | EPOCH = [1/3] | TIME ELAPSED =31.93Mins\n",
      "ITERATION:[87/906] | LOSS: 1.601484 | EPOCH = [1/3] | TIME ELAPSED =32.28Mins\n",
      "ITERATION:[88/906] | LOSS: 1.598968 | EPOCH = [1/3] | TIME ELAPSED =32.63Mins\n",
      "ITERATION:[89/906] | LOSS: 1.581179 | EPOCH = [1/3] | TIME ELAPSED =32.97Mins\n",
      "ITERATION:[90/906] | LOSS: 1.669142 | EPOCH = [1/3] | TIME ELAPSED =33.34Mins\n",
      "ITERATION:[91/906] | LOSS: 1.608525 | EPOCH = [1/3] | TIME ELAPSED =33.69Mins\n",
      "ITERATION:[92/906] | LOSS: 1.575135 | EPOCH = [1/3] | TIME ELAPSED =34.03Mins\n",
      "ITERATION:[93/906] | LOSS: 1.638671 | EPOCH = [1/3] | TIME ELAPSED =34.38Mins\n",
      "ITERATION:[94/906] | LOSS: 1.644778 | EPOCH = [1/3] | TIME ELAPSED =34.73Mins\n",
      "ITERATION:[95/906] | LOSS: 1.645951 | EPOCH = [1/3] | TIME ELAPSED =35.1Mins\n",
      "ITERATION:[96/906] | LOSS: 1.576373 | EPOCH = [1/3] | TIME ELAPSED =35.48Mins\n",
      "ITERATION:[97/906] | LOSS: 1.581179 | EPOCH = [1/3] | TIME ELAPSED =35.83Mins\n",
      "ITERATION:[98/906] | LOSS: 1.611822 | EPOCH = [1/3] | TIME ELAPSED =36.17Mins\n",
      "ITERATION:[99/906] | LOSS: 1.583491 | EPOCH = [1/3] | TIME ELAPSED =36.51Mins\n",
      "ITERATION:[100/906] | LOSS: 1.601307 | EPOCH = [1/3] | TIME ELAPSED =36.86Mins\n",
      "ITERATION:[101/906] | LOSS: 1.647189 | EPOCH = [1/3] | TIME ELAPSED =37.21Mins\n",
      "ITERATION:[102/906] | LOSS: 1.627681 | EPOCH = [1/3] | TIME ELAPSED =37.57Mins\n",
      "ITERATION:[103/906] | LOSS: 1.637066 | EPOCH = [1/3] | TIME ELAPSED =37.93Mins\n",
      "ITERATION:[104/906] | LOSS: 1.49623 | EPOCH = [1/3] | TIME ELAPSED =38.28Mins\n",
      "ITERATION:[105/906] | LOSS: 1.591379 | EPOCH = [1/3] | TIME ELAPSED =38.64Mins\n",
      "ITERATION:[106/906] | LOSS: 1.642878 | EPOCH = [1/3] | TIME ELAPSED =38.99Mins\n",
      "ITERATION:[107/906] | LOSS: 1.565886 | EPOCH = [1/3] | TIME ELAPSED =39.33Mins\n",
      "ITERATION:[108/906] | LOSS: 1.549328 | EPOCH = [1/3] | TIME ELAPSED =39.71Mins\n",
      "ITERATION:[109/906] | LOSS: 1.587161 | EPOCH = [1/3] | TIME ELAPSED =40.06Mins\n",
      "ITERATION:[110/906] | LOSS: 1.514964 | EPOCH = [1/3] | TIME ELAPSED =40.42Mins\n",
      "ITERATION:[111/906] | LOSS: 1.465889 | EPOCH = [1/3] | TIME ELAPSED =40.78Mins\n",
      "ITERATION:[112/906] | LOSS: 1.601718 | EPOCH = [1/3] | TIME ELAPSED =41.13Mins\n",
      "ITERATION:[113/906] | LOSS: 1.48522 | EPOCH = [1/3] | TIME ELAPSED =41.47Mins\n",
      "ITERATION:[114/906] | LOSS: 1.572851 | EPOCH = [1/3] | TIME ELAPSED =41.81Mins\n",
      "ITERATION:[115/906] | LOSS: 1.555548 | EPOCH = [1/3] | TIME ELAPSED =42.17Mins\n",
      "ITERATION:[116/906] | LOSS: 1.494657 | EPOCH = [1/3] | TIME ELAPSED =42.51Mins\n",
      "ITERATION:[117/906] | LOSS: 1.553713 | EPOCH = [1/3] | TIME ELAPSED =42.86Mins\n",
      "ITERATION:[118/906] | LOSS: 1.65832 | EPOCH = [1/3] | TIME ELAPSED =43.2Mins\n",
      "ITERATION:[119/906] | LOSS: 1.6588 | EPOCH = [1/3] | TIME ELAPSED =43.56Mins\n",
      "ITERATION:[120/906] | LOSS: 1.522088 | EPOCH = [1/3] | TIME ELAPSED =43.92Mins\n",
      "ITERATION:[121/906] | LOSS: 1.606109 | EPOCH = [1/3] | TIME ELAPSED =44.27Mins\n",
      "ITERATION:[122/906] | LOSS: 1.509903 | EPOCH = [1/3] | TIME ELAPSED =44.61Mins\n",
      "ITERATION:[123/906] | LOSS: 1.592333 | EPOCH = [1/3] | TIME ELAPSED =44.97Mins\n",
      "ITERATION:[124/906] | LOSS: 1.497769 | EPOCH = [1/3] | TIME ELAPSED =45.32Mins\n",
      "ITERATION:[125/906] | LOSS: 1.561565 | EPOCH = [1/3] | TIME ELAPSED =45.67Mins\n",
      "ITERATION:[126/906] | LOSS: 1.528995 | EPOCH = [1/3] | TIME ELAPSED =46.01Mins\n",
      "ITERATION:[127/906] | LOSS: 1.554344 | EPOCH = [1/3] | TIME ELAPSED =46.35Mins\n",
      "ITERATION:[128/906] | LOSS: 1.59922 | EPOCH = [1/3] | TIME ELAPSED =46.69Mins\n",
      "ITERATION:[129/906] | LOSS: 1.592141 | EPOCH = [1/3] | TIME ELAPSED =47.04Mins\n",
      "ITERATION:[130/906] | LOSS: 1.478879 | EPOCH = [1/3] | TIME ELAPSED =47.4Mins\n",
      "ITERATION:[131/906] | LOSS: 1.64138 | EPOCH = [1/3] | TIME ELAPSED =47.74Mins\n",
      "ITERATION:[132/906] | LOSS: 1.546616 | EPOCH = [1/3] | TIME ELAPSED =48.11Mins\n",
      "ITERATION:[133/906] | LOSS: 1.532513 | EPOCH = [1/3] | TIME ELAPSED =48.47Mins\n",
      "ITERATION:[134/906] | LOSS: 1.557953 | EPOCH = [1/3] | TIME ELAPSED =48.81Mins\n",
      "ITERATION:[135/906] | LOSS: 1.520021 | EPOCH = [1/3] | TIME ELAPSED =49.18Mins\n",
      "ITERATION:[136/906] | LOSS: 1.527126 | EPOCH = [1/3] | TIME ELAPSED =49.52Mins\n",
      "ITERATION:[137/906] | LOSS: 1.458739 | EPOCH = [1/3] | TIME ELAPSED =49.87Mins\n",
      "ITERATION:[138/906] | LOSS: 1.462092 | EPOCH = [1/3] | TIME ELAPSED =50.22Mins\n",
      "ITERATION:[139/906] | LOSS: 1.428604 | EPOCH = [1/3] | TIME ELAPSED =50.56Mins\n",
      "ITERATION:[140/906] | LOSS: 1.642965 | EPOCH = [1/3] | TIME ELAPSED =50.91Mins\n",
      "ITERATION:[141/906] | LOSS: 1.454472 | EPOCH = [1/3] | TIME ELAPSED =51.25Mins\n",
      "ITERATION:[142/906] | LOSS: 1.451927 | EPOCH = [1/3] | TIME ELAPSED =51.6Mins\n",
      "ITERATION:[143/906] | LOSS: 1.484894 | EPOCH = [1/3] | TIME ELAPSED =51.94Mins\n",
      "ITERATION:[144/906] | LOSS: 1.552676 | EPOCH = [1/3] | TIME ELAPSED =52.29Mins\n",
      "ITERATION:[145/906] | LOSS: 1.487212 | EPOCH = [1/3] | TIME ELAPSED =52.66Mins\n",
      "ITERATION:[146/906] | LOSS: 1.469682 | EPOCH = [1/3] | TIME ELAPSED =53.0Mins\n",
      "ITERATION:[147/906] | LOSS: 1.396325 | EPOCH = [1/3] | TIME ELAPSED =53.35Mins\n",
      "ITERATION:[148/906] | LOSS: 1.438038 | EPOCH = [1/3] | TIME ELAPSED =53.69Mins\n",
      "ITERATION:[149/906] | LOSS: 1.422455 | EPOCH = [1/3] | TIME ELAPSED =54.03Mins\n",
      "ITERATION:[150/906] | LOSS: 1.522211 | EPOCH = [1/3] | TIME ELAPSED =54.38Mins\n",
      "ITERATION:[151/906] | LOSS: 1.512747 | EPOCH = [1/3] | TIME ELAPSED =54.73Mins\n",
      "ITERATION:[152/906] | LOSS: 1.441518 | EPOCH = [1/3] | TIME ELAPSED =55.07Mins\n",
      "ITERATION:[153/906] | LOSS: 1.454687 | EPOCH = [1/3] | TIME ELAPSED =55.42Mins\n",
      "ITERATION:[154/906] | LOSS: 1.527277 | EPOCH = [1/3] | TIME ELAPSED =55.77Mins\n",
      "ITERATION:[155/906] | LOSS: 1.377035 | EPOCH = [1/3] | TIME ELAPSED =56.13Mins\n",
      "ITERATION:[156/906] | LOSS: 1.541993 | EPOCH = [1/3] | TIME ELAPSED =56.47Mins\n",
      "ITERATION:[157/906] | LOSS: 1.453378 | EPOCH = [1/3] | TIME ELAPSED =56.82Mins\n",
      "ITERATION:[158/906] | LOSS: 1.463318 | EPOCH = [1/3] | TIME ELAPSED =57.18Mins\n",
      "ITERATION:[159/906] | LOSS: 1.44186 | EPOCH = [1/3] | TIME ELAPSED =57.54Mins\n",
      "ITERATION:[160/906] | LOSS: 1.415133 | EPOCH = [1/3] | TIME ELAPSED =57.9Mins\n",
      "ITERATION:[161/906] | LOSS: 1.54797 | EPOCH = [1/3] | TIME ELAPSED =58.25Mins\n",
      "ITERATION:[162/906] | LOSS: 1.482418 | EPOCH = [1/3] | TIME ELAPSED =58.6Mins\n",
      "ITERATION:[163/906] | LOSS: 1.472051 | EPOCH = [1/3] | TIME ELAPSED =58.94Mins\n",
      "ITERATION:[164/906] | LOSS: 1.395831 | EPOCH = [1/3] | TIME ELAPSED =59.29Mins\n",
      "ITERATION:[165/906] | LOSS: 1.5764 | EPOCH = [1/3] | TIME ELAPSED =59.65Mins\n",
      "ITERATION:[166/906] | LOSS: 1.382487 | EPOCH = [1/3] | TIME ELAPSED =60.0Mins\n",
      "ITERATION:[167/906] | LOSS: 1.391455 | EPOCH = [1/3] | TIME ELAPSED =60.34Mins\n",
      "ITERATION:[168/906] | LOSS: 1.457319 | EPOCH = [1/3] | TIME ELAPSED =60.68Mins\n",
      "ITERATION:[169/906] | LOSS: 1.471941 | EPOCH = [1/3] | TIME ELAPSED =61.04Mins\n",
      "ITERATION:[170/906] | LOSS: 1.54416 | EPOCH = [1/3] | TIME ELAPSED =61.39Mins\n",
      "ITERATION:[171/906] | LOSS: 1.479054 | EPOCH = [1/3] | TIME ELAPSED =61.76Mins\n",
      "ITERATION:[172/906] | LOSS: 1.419635 | EPOCH = [1/3] | TIME ELAPSED =62.11Mins\n",
      "ITERATION:[173/906] | LOSS: 1.325803 | EPOCH = [1/3] | TIME ELAPSED =62.46Mins\n",
      "ITERATION:[174/906] | LOSS: 1.399287 | EPOCH = [1/3] | TIME ELAPSED =62.8Mins\n",
      "ITERATION:[175/906] | LOSS: 1.518059 | EPOCH = [1/3] | TIME ELAPSED =63.16Mins\n",
      "ITERATION:[176/906] | LOSS: 1.412543 | EPOCH = [1/3] | TIME ELAPSED =63.52Mins\n",
      "ITERATION:[177/906] | LOSS: 1.441358 | EPOCH = [1/3] | TIME ELAPSED =63.89Mins\n",
      "ITERATION:[178/906] | LOSS: 1.400476 | EPOCH = [1/3] | TIME ELAPSED =64.23Mins\n",
      "ITERATION:[179/906] | LOSS: 1.458101 | EPOCH = [1/3] | TIME ELAPSED =64.58Mins\n",
      "ITERATION:[180/906] | LOSS: 1.315656 | EPOCH = [1/3] | TIME ELAPSED =64.93Mins\n",
      "ITERATION:[181/906] | LOSS: 1.415053 | EPOCH = [1/3] | TIME ELAPSED =65.28Mins\n",
      "ITERATION:[182/906] | LOSS: 1.559964 | EPOCH = [1/3] | TIME ELAPSED =65.63Mins\n",
      "ITERATION:[183/906] | LOSS: 1.473315 | EPOCH = [1/3] | TIME ELAPSED =65.98Mins\n",
      "ITERATION:[184/906] | LOSS: 1.459123 | EPOCH = [1/3] | TIME ELAPSED =66.32Mins\n",
      "ITERATION:[185/906] | LOSS: 1.4287 | EPOCH = [1/3] | TIME ELAPSED =66.69Mins\n",
      "ITERATION:[186/906] | LOSS: 1.376951 | EPOCH = [1/3] | TIME ELAPSED =67.14Mins\n",
      "ITERATION:[187/906] | LOSS: 1.396068 | EPOCH = [1/3] | TIME ELAPSED =67.47Mins\n",
      "ITERATION:[188/906] | LOSS: 1.374562 | EPOCH = [1/3] | TIME ELAPSED =67.82Mins\n",
      "ITERATION:[189/906] | LOSS: 1.383594 | EPOCH = [1/3] | TIME ELAPSED =68.16Mins\n",
      "ITERATION:[190/906] | LOSS: 1.450482 | EPOCH = [1/3] | TIME ELAPSED =68.51Mins\n",
      "ITERATION:[191/906] | LOSS: 1.394455 | EPOCH = [1/3] | TIME ELAPSED =68.86Mins\n",
      "ITERATION:[192/906] | LOSS: 1.441639 | EPOCH = [1/3] | TIME ELAPSED =69.21Mins\n",
      "ITERATION:[193/906] | LOSS: 1.461682 | EPOCH = [1/3] | TIME ELAPSED =69.56Mins\n",
      "ITERATION:[194/906] | LOSS: 1.462437 | EPOCH = [1/3] | TIME ELAPSED =69.92Mins\n",
      "ITERATION:[195/906] | LOSS: 1.385907 | EPOCH = [1/3] | TIME ELAPSED =70.29Mins\n",
      "ITERATION:[196/906] | LOSS: 1.355353 | EPOCH = [1/3] | TIME ELAPSED =70.63Mins\n",
      "ITERATION:[197/906] | LOSS: 1.387741 | EPOCH = [1/3] | TIME ELAPSED =71.19Mins\n",
      "ITERATION:[198/906] | LOSS: 1.33266 | EPOCH = [1/3] | TIME ELAPSED =71.55Mins\n",
      "ITERATION:[199/906] | LOSS: 1.349426 | EPOCH = [1/3] | TIME ELAPSED =71.91Mins\n",
      "ITERATION:[200/906] | LOSS: 1.396369 | EPOCH = [1/3] | TIME ELAPSED =72.27Mins\n",
      "ITERATION:[201/906] | LOSS: 1.415456 | EPOCH = [1/3] | TIME ELAPSED =72.61Mins\n",
      "ITERATION:[202/906] | LOSS: 1.330966 | EPOCH = [1/3] | TIME ELAPSED =72.96Mins\n",
      "ITERATION:[203/906] | LOSS: 1.352834 | EPOCH = [1/3] | TIME ELAPSED =73.31Mins\n",
      "ITERATION:[204/906] | LOSS: 1.397815 | EPOCH = [1/3] | TIME ELAPSED =73.65Mins\n",
      "ITERATION:[205/906] | LOSS: 1.416187 | EPOCH = [1/3] | TIME ELAPSED =74.03Mins\n",
      "ITERATION:[206/906] | LOSS: 1.348871 | EPOCH = [1/3] | TIME ELAPSED =74.38Mins\n",
      "ITERATION:[207/906] | LOSS: 1.404388 | EPOCH = [1/3] | TIME ELAPSED =74.72Mins\n",
      "ITERATION:[208/906] | LOSS: 1.333846 | EPOCH = [1/3] | TIME ELAPSED =75.07Mins\n",
      "ITERATION:[209/906] | LOSS: 1.410017 | EPOCH = [1/3] | TIME ELAPSED =75.41Mins\n",
      "ITERATION:[210/906] | LOSS: 1.49098 | EPOCH = [1/3] | TIME ELAPSED =75.77Mins\n",
      "ITERATION:[211/906] | LOSS: 1.421061 | EPOCH = [1/3] | TIME ELAPSED =76.12Mins\n",
      "ITERATION:[212/906] | LOSS: 1.345403 | EPOCH = [1/3] | TIME ELAPSED =76.5Mins\n",
      "ITERATION:[213/906] | LOSS: 1.342615 | EPOCH = [1/3] | TIME ELAPSED =76.84Mins\n",
      "ITERATION:[214/906] | LOSS: 1.396183 | EPOCH = [1/3] | TIME ELAPSED =77.19Mins\n",
      "ITERATION:[215/906] | LOSS: 1.348001 | EPOCH = [1/3] | TIME ELAPSED =77.54Mins\n",
      "ITERATION:[216/906] | LOSS: 1.48659 | EPOCH = [1/3] | TIME ELAPSED =77.88Mins\n",
      "ITERATION:[217/906] | LOSS: 1.403756 | EPOCH = [1/3] | TIME ELAPSED =78.24Mins\n",
      "ITERATION:[218/906] | LOSS: 1.369733 | EPOCH = [1/3] | TIME ELAPSED =78.57Mins\n",
      "ITERATION:[219/906] | LOSS: 1.300861 | EPOCH = [1/3] | TIME ELAPSED =78.92Mins\n",
      "ITERATION:[220/906] | LOSS: 1.295395 | EPOCH = [1/3] | TIME ELAPSED =79.29Mins\n",
      "ITERATION:[221/906] | LOSS: 1.283808 | EPOCH = [1/3] | TIME ELAPSED =79.63Mins\n",
      "ITERATION:[222/906] | LOSS: 1.295208 | EPOCH = [1/3] | TIME ELAPSED =79.98Mins\n",
      "ITERATION:[223/906] | LOSS: 1.285916 | EPOCH = [1/3] | TIME ELAPSED =80.35Mins\n",
      "ITERATION:[224/906] | LOSS: 1.271014 | EPOCH = [1/3] | TIME ELAPSED =80.69Mins\n",
      "ITERATION:[225/906] | LOSS: 1.312207 | EPOCH = [1/3] | TIME ELAPSED =81.04Mins\n",
      "ITERATION:[226/906] | LOSS: 1.418679 | EPOCH = [1/3] | TIME ELAPSED =81.4Mins\n",
      "ITERATION:[227/906] | LOSS: 1.317883 | EPOCH = [1/3] | TIME ELAPSED =81.79Mins\n",
      "ITERATION:[228/906] | LOSS: 1.328874 | EPOCH = [1/3] | TIME ELAPSED =82.14Mins\n",
      "ITERATION:[229/906] | LOSS: 1.402001 | EPOCH = [1/3] | TIME ELAPSED =82.48Mins\n",
      "ITERATION:[230/906] | LOSS: 1.341345 | EPOCH = [1/3] | TIME ELAPSED =82.82Mins\n",
      "ITERATION:[231/906] | LOSS: 1.365458 | EPOCH = [1/3] | TIME ELAPSED =83.17Mins\n",
      "ITERATION:[232/906] | LOSS: 1.396406 | EPOCH = [1/3] | TIME ELAPSED =83.6Mins\n",
      "ITERATION:[233/906] | LOSS: 1.344577 | EPOCH = [1/3] | TIME ELAPSED =84.03Mins\n",
      "ITERATION:[234/906] | LOSS: 1.37364 | EPOCH = [1/3] | TIME ELAPSED =84.37Mins\n",
      "ITERATION:[235/906] | LOSS: 1.335136 | EPOCH = [1/3] | TIME ELAPSED =84.73Mins\n",
      "ITERATION:[236/906] | LOSS: 1.424206 | EPOCH = [1/3] | TIME ELAPSED =85.07Mins\n",
      "ITERATION:[237/906] | LOSS: 1.344082 | EPOCH = [1/3] | TIME ELAPSED =85.41Mins\n",
      "ITERATION:[238/906] | LOSS: 1.42385 | EPOCH = [1/3] | TIME ELAPSED =85.76Mins\n",
      "ITERATION:[239/906] | LOSS: 1.362432 | EPOCH = [1/3] | TIME ELAPSED =86.1Mins\n",
      "ITERATION:[240/906] | LOSS: 1.360646 | EPOCH = [1/3] | TIME ELAPSED =86.46Mins\n",
      "ITERATION:[241/906] | LOSS: 1.204135 | EPOCH = [1/3] | TIME ELAPSED =86.81Mins\n",
      "ITERATION:[242/906] | LOSS: 1.270832 | EPOCH = [1/3] | TIME ELAPSED =87.15Mins\n",
      "ITERATION:[243/906] | LOSS: 1.404347 | EPOCH = [1/3] | TIME ELAPSED =87.52Mins\n",
      "ITERATION:[244/906] | LOSS: 1.298628 | EPOCH = [1/3] | TIME ELAPSED =87.87Mins\n",
      "ITERATION:[245/906] | LOSS: 1.257266 | EPOCH = [1/3] | TIME ELAPSED =88.22Mins\n",
      "ITERATION:[246/906] | LOSS: 1.314439 | EPOCH = [1/3] | TIME ELAPSED =88.58Mins\n",
      "ITERATION:[247/906] | LOSS: 1.43303 | EPOCH = [1/3] | TIME ELAPSED =88.92Mins\n",
      "ITERATION:[248/906] | LOSS: 1.349551 | EPOCH = [1/3] | TIME ELAPSED =89.27Mins\n",
      "ITERATION:[249/906] | LOSS: 1.345053 | EPOCH = [1/3] | TIME ELAPSED =89.63Mins\n",
      "ITERATION:[250/906] | LOSS: 1.265805 | EPOCH = [1/3] | TIME ELAPSED =89.99Mins\n",
      "ITERATION:[251/906] | LOSS: 1.320398 | EPOCH = [1/3] | TIME ELAPSED =90.37Mins\n",
      "ITERATION:[252/906] | LOSS: 1.24981 | EPOCH = [1/3] | TIME ELAPSED =90.72Mins\n",
      "ITERATION:[253/906] | LOSS: 1.342705 | EPOCH = [1/3] | TIME ELAPSED =91.07Mins\n",
      "ITERATION:[254/906] | LOSS: 1.28283 | EPOCH = [1/3] | TIME ELAPSED =91.41Mins\n",
      "ITERATION:[255/906] | LOSS: 1.255766 | EPOCH = [1/3] | TIME ELAPSED =91.78Mins\n",
      "ITERATION:[256/906] | LOSS: 1.269725 | EPOCH = [1/3] | TIME ELAPSED =92.13Mins\n",
      "ITERATION:[257/906] | LOSS: 1.213241 | EPOCH = [1/3] | TIME ELAPSED =92.46Mins\n",
      "ITERATION:[258/906] | LOSS: 1.374099 | EPOCH = [1/3] | TIME ELAPSED =92.8Mins\n",
      "ITERATION:[259/906] | LOSS: 1.244953 | EPOCH = [1/3] | TIME ELAPSED =93.14Mins\n",
      "ITERATION:[260/906] | LOSS: 1.297125 | EPOCH = [1/3] | TIME ELAPSED =93.51Mins\n",
      "ITERATION:[261/906] | LOSS: 1.30079 | EPOCH = [1/3] | TIME ELAPSED =93.86Mins\n",
      "ITERATION:[262/906] | LOSS: 1.226315 | EPOCH = [1/3] | TIME ELAPSED =94.2Mins\n",
      "ITERATION:[263/906] | LOSS: 1.276693 | EPOCH = [1/3] | TIME ELAPSED =94.54Mins\n",
      "ITERATION:[264/906] | LOSS: 1.274707 | EPOCH = [1/3] | TIME ELAPSED =94.89Mins\n",
      "ITERATION:[265/906] | LOSS: 1.307826 | EPOCH = [1/3] | TIME ELAPSED =95.25Mins\n",
      "ITERATION:[266/906] | LOSS: 1.261131 | EPOCH = [1/3] | TIME ELAPSED =95.6Mins\n",
      "ITERATION:[267/906] | LOSS: 1.276963 | EPOCH = [1/3] | TIME ELAPSED =95.93Mins\n",
      "ITERATION:[268/906] | LOSS: 1.240059 | EPOCH = [1/3] | TIME ELAPSED =96.28Mins\n",
      "ITERATION:[269/906] | LOSS: 1.256693 | EPOCH = [1/3] | TIME ELAPSED =96.63Mins\n",
      "ITERATION:[270/906] | LOSS: 1.1991 | EPOCH = [1/3] | TIME ELAPSED =97.0Mins\n",
      "ITERATION:[271/906] | LOSS: 1.256831 | EPOCH = [1/3] | TIME ELAPSED =97.48Mins\n",
      "ITERATION:[272/906] | LOSS: 1.17822 | EPOCH = [1/3] | TIME ELAPSED =97.83Mins\n",
      "ITERATION:[273/906] | LOSS: 1.324441 | EPOCH = [1/3] | TIME ELAPSED =98.21Mins\n",
      "ITERATION:[274/906] | LOSS: 1.29881 | EPOCH = [1/3] | TIME ELAPSED =98.56Mins\n",
      "ITERATION:[275/906] | LOSS: 1.273812 | EPOCH = [1/3] | TIME ELAPSED =98.92Mins\n",
      "ITERATION:[276/906] | LOSS: 1.319377 | EPOCH = [1/3] | TIME ELAPSED =99.28Mins\n",
      "ITERATION:[277/906] | LOSS: 1.258963 | EPOCH = [1/3] | TIME ELAPSED =99.64Mins\n",
      "ITERATION:[278/906] | LOSS: 1.269057 | EPOCH = [1/3] | TIME ELAPSED =99.98Mins\n",
      "ITERATION:[279/906] | LOSS: 1.290608 | EPOCH = [1/3] | TIME ELAPSED =100.32Mins\n",
      "ITERATION:[280/906] | LOSS: 1.232724 | EPOCH = [1/3] | TIME ELAPSED =100.68Mins\n",
      "ITERATION:[281/906] | LOSS: 1.266516 | EPOCH = [1/3] | TIME ELAPSED =101.02Mins\n",
      "ITERATION:[282/906] | LOSS: 1.290395 | EPOCH = [1/3] | TIME ELAPSED =101.45Mins\n",
      "ITERATION:[283/906] | LOSS: 1.269254 | EPOCH = [1/3] | TIME ELAPSED =101.8Mins\n",
      "ITERATION:[284/906] | LOSS: 1.231351 | EPOCH = [1/3] | TIME ELAPSED =102.14Mins\n",
      "ITERATION:[285/906] | LOSS: 1.13717 | EPOCH = [1/3] | TIME ELAPSED =102.49Mins\n",
      "ITERATION:[286/906] | LOSS: 1.284328 | EPOCH = [1/3] | TIME ELAPSED =102.85Mins\n",
      "ITERATION:[287/906] | LOSS: 1.289713 | EPOCH = [1/3] | TIME ELAPSED =103.2Mins\n",
      "ITERATION:[288/906] | LOSS: 1.273571 | EPOCH = [1/3] | TIME ELAPSED =103.54Mins\n",
      "ITERATION:[289/906] | LOSS: 1.188738 | EPOCH = [1/3] | TIME ELAPSED =103.89Mins\n",
      "ITERATION:[290/906] | LOSS: 1.254948 | EPOCH = [1/3] | TIME ELAPSED =104.24Mins\n",
      "ITERATION:[291/906] | LOSS: 1.255234 | EPOCH = [1/3] | TIME ELAPSED =104.59Mins\n",
      "ITERATION:[292/906] | LOSS: 1.203094 | EPOCH = [1/3] | TIME ELAPSED =104.93Mins\n",
      "ITERATION:[293/906] | LOSS: 1.256642 | EPOCH = [1/3] | TIME ELAPSED =105.27Mins\n",
      "ITERATION:[294/906] | LOSS: 1.285661 | EPOCH = [1/3] | TIME ELAPSED =105.72Mins\n",
      "ITERATION:[295/906] | LOSS: 1.289592 | EPOCH = [1/3] | TIME ELAPSED =106.07Mins\n",
      "ITERATION:[296/906] | LOSS: 1.305926 | EPOCH = [1/3] | TIME ELAPSED =106.43Mins\n",
      "ITERATION:[297/906] | LOSS: 1.274559 | EPOCH = [1/3] | TIME ELAPSED =106.81Mins\n",
      "ITERATION:[298/906] | LOSS: 1.274432 | EPOCH = [1/3] | TIME ELAPSED =107.16Mins\n",
      "ITERATION:[299/906] | LOSS: 1.271985 | EPOCH = [1/3] | TIME ELAPSED =107.5Mins\n",
      "ITERATION:[300/906] | LOSS: 1.20332 | EPOCH = [1/3] | TIME ELAPSED =107.87Mins\n",
      "ITERATION:[301/906] | LOSS: 1.21204 | EPOCH = [1/3] | TIME ELAPSED =108.22Mins\n",
      "ITERATION:[302/906] | LOSS: 1.155736 | EPOCH = [1/3] | TIME ELAPSED =108.56Mins\n",
      "ITERATION:[303/906] | LOSS: 1.256644 | EPOCH = [1/3] | TIME ELAPSED =108.9Mins\n",
      "ITERATION:[304/906] | LOSS: 1.179432 | EPOCH = [1/3] | TIME ELAPSED =109.24Mins\n",
      "ITERATION:[305/906] | LOSS: 1.243978 | EPOCH = [1/3] | TIME ELAPSED =109.59Mins\n",
      "ITERATION:[306/906] | LOSS: 1.208957 | EPOCH = [1/3] | TIME ELAPSED =109.94Mins\n",
      "ITERATION:[307/906] | LOSS: 1.242872 | EPOCH = [1/3] | TIME ELAPSED =110.28Mins\n",
      "ITERATION:[308/906] | LOSS: 1.234014 | EPOCH = [1/3] | TIME ELAPSED =110.61Mins\n",
      "ITERATION:[309/906] | LOSS: 1.173499 | EPOCH = [1/3] | TIME ELAPSED =110.95Mins\n",
      "ITERATION:[310/906] | LOSS: 1.221959 | EPOCH = [1/3] | TIME ELAPSED =111.3Mins\n",
      "ITERATION:[311/906] | LOSS: 1.22464 | EPOCH = [1/3] | TIME ELAPSED =111.65Mins\n",
      "ITERATION:[312/906] | LOSS: 1.225987 | EPOCH = [1/3] | TIME ELAPSED =111.99Mins\n",
      "ITERATION:[313/906] | LOSS: 1.290056 | EPOCH = [1/3] | TIME ELAPSED =112.33Mins\n",
      "ITERATION:[314/906] | LOSS: 1.169143 | EPOCH = [1/3] | TIME ELAPSED =112.69Mins\n",
      "ITERATION:[315/906] | LOSS: 1.219431 | EPOCH = [1/3] | TIME ELAPSED =113.04Mins\n",
      "ITERATION:[316/906] | LOSS: 1.200163 | EPOCH = [1/3] | TIME ELAPSED =113.38Mins\n",
      "ITERATION:[317/906] | LOSS: 1.161319 | EPOCH = [1/3] | TIME ELAPSED =113.73Mins\n",
      "ITERATION:[318/906] | LOSS: 1.258496 | EPOCH = [1/3] | TIME ELAPSED =114.07Mins\n",
      "ITERATION:[319/906] | LOSS: 1.213829 | EPOCH = [1/3] | TIME ELAPSED =114.42Mins\n",
      "ITERATION:[320/906] | LOSS: 1.209465 | EPOCH = [1/3] | TIME ELAPSED =114.77Mins\n",
      "ITERATION:[321/906] | LOSS: 1.295563 | EPOCH = [1/3] | TIME ELAPSED =115.11Mins\n",
      "ITERATION:[322/906] | LOSS: 1.193138 | EPOCH = [1/3] | TIME ELAPSED =115.45Mins\n",
      "ITERATION:[323/906] | LOSS: 1.211124 | EPOCH = [1/3] | TIME ELAPSED =115.8Mins\n",
      "ITERATION:[324/906] | LOSS: 1.228977 | EPOCH = [1/3] | TIME ELAPSED =116.15Mins\n",
      "ITERATION:[325/906] | LOSS: 1.157161 | EPOCH = [1/3] | TIME ELAPSED =116.5Mins\n",
      "ITERATION:[326/906] | LOSS: 1.129047 | EPOCH = [1/3] | TIME ELAPSED =116.84Mins\n",
      "ITERATION:[327/906] | LOSS: 1.141584 | EPOCH = [1/3] | TIME ELAPSED =117.18Mins\n",
      "ITERATION:[328/906] | LOSS: 1.142229 | EPOCH = [1/3] | TIME ELAPSED =117.52Mins\n",
      "ITERATION:[329/906] | LOSS: 1.235762 | EPOCH = [1/3] | TIME ELAPSED =117.86Mins\n",
      "ITERATION:[330/906] | LOSS: 1.170558 | EPOCH = [1/3] | TIME ELAPSED =118.22Mins\n",
      "ITERATION:[331/906] | LOSS: 1.205223 | EPOCH = [1/3] | TIME ELAPSED =118.55Mins\n",
      "ITERATION:[332/906] | LOSS: 1.209207 | EPOCH = [1/3] | TIME ELAPSED =118.91Mins\n",
      "ITERATION:[333/906] | LOSS: 1.205731 | EPOCH = [1/3] | TIME ELAPSED =119.26Mins\n",
      "ITERATION:[334/906] | LOSS: 1.254874 | EPOCH = [1/3] | TIME ELAPSED =119.61Mins\n",
      "ITERATION:[335/906] | LOSS: 1.221941 | EPOCH = [1/3] | TIME ELAPSED =119.97Mins\n",
      "ITERATION:[336/906] | LOSS: 1.193945 | EPOCH = [1/3] | TIME ELAPSED =120.31Mins\n",
      "ITERATION:[337/906] | LOSS: 1.119087 | EPOCH = [1/3] | TIME ELAPSED =120.65Mins\n",
      "ITERATION:[338/906] | LOSS: 1.239536 | EPOCH = [1/3] | TIME ELAPSED =121.0Mins\n",
      "ITERATION:[339/906] | LOSS: 1.165783 | EPOCH = [1/3] | TIME ELAPSED =121.35Mins\n",
      "ITERATION:[340/906] | LOSS: 1.208824 | EPOCH = [1/3] | TIME ELAPSED =121.71Mins\n",
      "ITERATION:[341/906] | LOSS: 1.202622 | EPOCH = [1/3] | TIME ELAPSED =122.1Mins\n",
      "ITERATION:[342/906] | LOSS: 1.215146 | EPOCH = [1/3] | TIME ELAPSED =122.45Mins\n",
      "ITERATION:[343/906] | LOSS: 1.17066 | EPOCH = [1/3] | TIME ELAPSED =122.8Mins\n",
      "ITERATION:[344/906] | LOSS: 1.14736 | EPOCH = [1/3] | TIME ELAPSED =123.14Mins\n",
      "ITERATION:[345/906] | LOSS: 1.200222 | EPOCH = [1/3] | TIME ELAPSED =123.5Mins\n",
      "ITERATION:[346/906] | LOSS: 1.202709 | EPOCH = [1/3] | TIME ELAPSED =123.84Mins\n",
      "ITERATION:[347/906] | LOSS: 1.311319 | EPOCH = [1/3] | TIME ELAPSED =124.19Mins\n",
      "ITERATION:[348/906] | LOSS: 1.185635 | EPOCH = [1/3] | TIME ELAPSED =124.53Mins\n",
      "ITERATION:[349/906] | LOSS: 1.173203 | EPOCH = [1/3] | TIME ELAPSED =124.87Mins\n",
      "ITERATION:[350/906] | LOSS: 1.130706 | EPOCH = [1/3] | TIME ELAPSED =125.21Mins\n",
      "ITERATION:[351/906] | LOSS: 1.195962 | EPOCH = [1/3] | TIME ELAPSED =125.56Mins\n",
      "ITERATION:[352/906] | LOSS: 1.188546 | EPOCH = [1/3] | TIME ELAPSED =125.93Mins\n",
      "ITERATION:[353/906] | LOSS: 1.109955 | EPOCH = [1/3] | TIME ELAPSED =126.28Mins\n",
      "ITERATION:[354/906] | LOSS: 1.135946 | EPOCH = [1/3] | TIME ELAPSED =126.62Mins\n",
      "ITERATION:[355/906] | LOSS: 1.132033 | EPOCH = [1/3] | TIME ELAPSED =126.97Mins\n",
      "ITERATION:[356/906] | LOSS: 1.236476 | EPOCH = [1/3] | TIME ELAPSED =127.32Mins\n",
      "ITERATION:[357/906] | LOSS: 1.229483 | EPOCH = [1/3] | TIME ELAPSED =127.66Mins\n",
      "ITERATION:[358/906] | LOSS: 1.12876 | EPOCH = [1/3] | TIME ELAPSED =128.01Mins\n",
      "ITERATION:[359/906] | LOSS: 1.148818 | EPOCH = [1/3] | TIME ELAPSED =128.41Mins\n",
      "ITERATION:[360/906] | LOSS: 1.153445 | EPOCH = [1/3] | TIME ELAPSED =128.77Mins\n",
      "ITERATION:[361/906] | LOSS: 1.184657 | EPOCH = [1/3] | TIME ELAPSED =129.11Mins\n",
      "ITERATION:[362/906] | LOSS: 1.104659 | EPOCH = [1/3] | TIME ELAPSED =129.45Mins\n",
      "ITERATION:[363/906] | LOSS: 1.144037 | EPOCH = [1/3] | TIME ELAPSED =129.78Mins\n",
      "ITERATION:[364/906] | LOSS: 1.162361 | EPOCH = [1/3] | TIME ELAPSED =130.12Mins\n",
      "ITERATION:[365/906] | LOSS: 1.19048 | EPOCH = [1/3] | TIME ELAPSED =130.48Mins\n",
      "ITERATION:[366/906] | LOSS: 1.212146 | EPOCH = [1/3] | TIME ELAPSED =130.82Mins\n",
      "ITERATION:[367/906] | LOSS: 1.088862 | EPOCH = [1/3] | TIME ELAPSED =131.15Mins\n",
      "ITERATION:[368/906] | LOSS: 1.298703 | EPOCH = [1/3] | TIME ELAPSED =131.49Mins\n",
      "ITERATION:[369/906] | LOSS: 1.145442 | EPOCH = [1/3] | TIME ELAPSED =131.84Mins\n",
      "ITERATION:[370/906] | LOSS: 1.11605 | EPOCH = [1/3] | TIME ELAPSED =132.19Mins\n",
      "ITERATION:[371/906] | LOSS: 1.209718 | EPOCH = [1/3] | TIME ELAPSED =132.54Mins\n",
      "ITERATION:[372/906] | LOSS: 1.269081 | EPOCH = [1/3] | TIME ELAPSED =132.9Mins\n",
      "ITERATION:[373/906] | LOSS: 1.196641 | EPOCH = [1/3] | TIME ELAPSED =133.25Mins\n",
      "ITERATION:[374/906] | LOSS: 1.239245 | EPOCH = [1/3] | TIME ELAPSED =133.6Mins\n",
      "ITERATION:[375/906] | LOSS: 1.092116 | EPOCH = [1/3] | TIME ELAPSED =133.97Mins\n",
      "ITERATION:[376/906] | LOSS: 1.148179 | EPOCH = [1/3] | TIME ELAPSED =134.33Mins\n",
      "ITERATION:[377/906] | LOSS: 1.214197 | EPOCH = [1/3] | TIME ELAPSED =134.68Mins\n"
     ]
    }
   ],
   "source": [
    "if platform == \"colab\":\n",
    "    IMAGE_DIR = '/content/drive/My Drive/train_images/'\n",
    "else:\n",
    "    IMAGE_DIR = '../data/train/'\n",
    "\n",
    "# If GPU training is required\n",
    "if parallel == True and device != \"cpu\":\n",
    "    print(\"Parallel Processing enabled\")\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "if device == \"cpu\":\n",
    "    print(\"Device to CPU\")\n",
    "else:\n",
    "    print(\"Device to CUDA\")\n",
    "    net = net.to(torch.device(\"cuda:0\"))    \n",
    "\n",
    "# Creating the Dataset\n",
    "train_dataset = ImageCaptionsDataset(\n",
    "    IMAGE_DIR, captions_preprocessing_obj.captions_dict, img_transform=img_transform,\n",
    "    captions_transform=captions_preprocessing_obj.captions_transform\n",
    ")\n",
    "\n",
    "# Define your hyperparameters\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 1e-1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0 # Parallel threads for dataloading\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "loss_list = []\n",
    "# Creating the DataLoader for batching purposes\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "import os\n",
    "if device != \"cpu\":\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "t0 = time()\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    print(\"$$$$$----EPOCH {}----$$$$$$\".format(epoch+1))\n",
    "    iteration = 0\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        iteration +=1\n",
    "        net.zero_grad()\n",
    "\n",
    "        image_batch, captions_batch = sample['image'], sample['captions']\n",
    "        \n",
    "        #print(\"image_shape\", image_batch.shape)\n",
    "        #print(\"batch_shape\", captions_batch.shape)\n",
    "        \n",
    "        N, I, L = captions_batch.shape\n",
    "        captions_batch = torch.reshape(captions_batch, (N*I,L))\n",
    "\n",
    "        # If GPU training required\n",
    "        if device != \"cpu\":\n",
    "          #print(\"cuda\")\n",
    "          image_batch, captions_batch = image_batch.to(torch.device(\"cuda:0\")), captions_batch.to(torch.device(\"cuda:0\"))\n",
    "        #print(\"Running Caption Gen\")\n",
    "        output_captions = net((image_batch, captions_batch))\n",
    "        #print(\"output Achieved\")\n",
    "\n",
    "        #print(\"size for loss\", output_captions.shape, captions_batch.shape)\n",
    "        loss = loss_function(output_captions.reshape(-1, output_captions.shape[2]), captions_batch.reshape(-1))\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"creating checkpoint\")\n",
    "        if iteration%5 == 0:\n",
    "            create_checkpoint(\"caption_chkpt_multi.pth\", net, optimizer, loss, iteration, epoch+1)\n",
    "        print(\"ITERATION:[{}/{}] | LOSS: {} | EPOCH = [{}/{}] | TIME ELAPSED ={}Mins\".format(iteration, round(29000/BATCH_SIZE),\n",
    "              round(loss.item(), 6), epoch+1, NUMBER_OF_EPOCHS, round((time()-t0)/60,2)))\n",
    "    print(\"\\n$$Loss = {},EPOCH: [{}/{}]\\n\\n\".format(round(loss.item(), 6), epoch+1, NUMBER_OF_EPOCHS))\n",
    "    create_checkpoint(\"epoch{}_chkpt_multi.pth\".format(epoch+1), net, optimizer, loss, iteration, epoch+1)\n",
    "\n",
    "create_checkpoint(\"Final_Model_multi.pth\", net, optimizer, loss, iteration, epoch+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51h4fNzkFzW1"
   },
   "outputs": [],
   "source": [
    "summary(net, (32,3,256,256))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yg9kH1zPzX5r"
   },
   "outputs": [],
   "source": [
    "#abc\n",
    "#comme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SLKQ4V6NZEp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Caption_generator_full.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
