{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "caption_gen_clean_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B6Kz41NHbkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "bed1f843-c5b8-4579-e08a-9aa93503eb90"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30-Jhw4IHbkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Import modules'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from collections import Counter\n",
        "from skimage import io, transform\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "import numpy as np\n",
        "from time import time\n",
        "import collections\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfLe7s5lHbke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b9a920f6-c182-40d4-84ca-33462e849014"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device =\", device)\n",
        "print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "parallel = True #enable nn.DataParallel for GPU\n",
        "platform = \"colab\" #colab/local\n",
        "restore = False #Restore Checkpoint\n",
        "phase = \"Train\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cuda\n",
            "Using 1 GPUs!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb5SYuizHbkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB = {}\n",
        "WORD2IDX = {}\n",
        "IDX2WORD = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ9hS4RuHbkq",
        "colab_type": "text"
      },
      "source": [
        "### Image Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pLzDxmpHbkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, image):\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "        return img\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, image):\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return image\n",
        "\n",
        "\n",
        "IMAGE_RESIZE = (256, 256)\n",
        "# Sequentially compose the transforms\n",
        "img_transform = transforms.Compose([Rescale(IMAGE_RESIZE), ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I54ecVuHbky",
        "colab_type": "text"
      },
      "source": [
        "### Captions Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfLraFnpHbkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "27167d8d-8072-4735-e2c1-721c4f352cd6"
      },
      "source": [
        "class CaptionsPreprocessing:\n",
        "    \"\"\"Preprocess the captions, generate vocabulary and convert words to tensor tokens\n",
        "    Args:\n",
        "        captions_file_path (string): captions tsv file path\n",
        "    \"\"\"\n",
        "    def __init__(self, captions_file_path):\n",
        "        self.captions_file_path = captions_file_path\n",
        "\n",
        "        # Read raw captions\n",
        "        self.raw_captions_dict = self.read_raw_captions()\n",
        "\n",
        "        # Preprocess captions\n",
        "        self.captions_dict = self.process_captions()\n",
        "\n",
        "        # Create vocabulary\n",
        "        self.start = \"<start>\"\n",
        "        self.end = \"<end>\"\n",
        "        self.oov = \"<unk>\"\n",
        "        self.pad = \"<pad>\"\n",
        "        self.vocab = self.generate_vocabulary()\n",
        "        self.word2index = self.convert_word2index()        \n",
        "        self.index2word = self.convert_index2word()\n",
        "        \n",
        "\n",
        "    def read_raw_captions(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            Dictionary with raw captions list keyed by image ids (integers)\n",
        "        \"\"\"\n",
        "        captions_dict = {}\n",
        "        with open(self.captions_file_path, 'r', encoding='utf-8') as f:\n",
        "            for img_caption_line in f.readlines():\n",
        "                img_captions = img_caption_line.strip().split('\\t')\n",
        "                captions_dict[int(img_captions[0])] = img_captions[1:]\n",
        "\n",
        "        return captions_dict \n",
        "\n",
        "    def process_captions(self):\n",
        "        \"\"\"\n",
        "        Use this function to generate dictionary and other preprocessing on captions\n",
        "        \"\"\"\n",
        "\n",
        "        raw_captions_dict = self.raw_captions_dict \n",
        "        \n",
        "        # Do the preprocessing here                \n",
        "        captions_dict = raw_captions_dict\n",
        "\n",
        "        return captions_dict\n",
        "\n",
        " \n",
        "\n",
        "    def generate_vocabulary(self):\n",
        "        \"\"\"\n",
        "        Use this function to generate dictionary and other preprocessing on captions\n",
        "        \"\"\"\n",
        "        captions_dict = self.captions_dict\n",
        "\n",
        "        # Generate the vocabulary\n",
        "        \n",
        "        all_captions = \"\"        \n",
        "        for cap_lists in captions_dict.values():\n",
        "            all_captions += \" \".join(cap_lists)\n",
        "        all_captions = all_captions.lower().replace(\",\",\"\").replace(\".\",\"\").split(\" \")\n",
        "        \n",
        "        vocab = {self.pad :1, self.oov :1, self.start :1, self.end :1}\n",
        "        vocab_update = Counter(all_captions) \n",
        "        vocab_update = {k:v for k,v in vocab_update.items() if v >= freq_threshold}\n",
        "        vocab.update(vocab_update)        \n",
        "        vocab_size = len(vocab)\n",
        "        \n",
        "        if phase == \"Train\":\n",
        "            VOCAB.update(vocab)\n",
        "            fname = '/content/drive/My Drive/A4/dict/VOCAB.pkl'\n",
        "            #if not os.path.isfile(fname):\n",
        "            with open(fname, 'wb') as handle:\n",
        "                pickle.dump(vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "            \n",
        "        print(\"VOCAB SIZE =\", vocab_size)\n",
        "        return vocab\n",
        "    \n",
        "    def convert_word2index(self):\n",
        "        \"\"\"\n",
        "        word to index converter\n",
        "        \"\"\"\n",
        "        word2index = {}\n",
        "        vocab = self.vocab\n",
        "        idx = 0\n",
        "        for k, v in vocab.items():\n",
        "            word2index[k] = idx\n",
        "            idx +=1\n",
        "        if phase == \"Train\":\n",
        "            WORD2IDX.update(word2index)\n",
        "            fname = '/content/drive/My Drive/A4/dict/WORD2IDX.pkl'\n",
        "            #if not os.path.isfile(fname):\n",
        "            with open(fname, 'wb') as handle:\n",
        "                pickle.dump(word2index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        return word2index\n",
        "    \n",
        "    def convert_index2word(self):\n",
        "        \"\"\"\n",
        "        index to word converter\n",
        "        \"\"\"\n",
        "        index2word = {}\n",
        "        vocab = self.vocab\n",
        "        idx = 0\n",
        "        \n",
        "        for k, v in vocab.items():\n",
        "            index2word[idx] = k\n",
        "            idx +=1\n",
        "        if phase == \"Train\":\n",
        "            IDX2WORD.update(index2word)\n",
        "            fname = '/content/drive/My Drive/A4/dict/IDX2WORD.pkl'\n",
        "            #if not os.path.isfile(fname):\n",
        "            with open(fname, 'wb') as handle:\n",
        "                pickle.dump(index2word, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        return index2word\n",
        "\n",
        " \n",
        "\n",
        "    def captions_transform(self, img_caption_list):\n",
        "        \"\"\"\n",
        "        Use this function to generate tensor tokens for the text captions\n",
        "        Args:\n",
        "            img_caption_list: List of captions for a particular image\n",
        "        \"\"\"\n",
        "        if phase == \"Test\":\n",
        "            word2index = WORD2IDX\n",
        "            vocab = VOCAB\n",
        "        else:\n",
        "            word2index = self.word2index\n",
        "            vocab = self.vocab\n",
        "            \n",
        "        start = self.start\n",
        "        end = self.end\n",
        "        oov = self.oov\n",
        "        \n",
        "        processed_list = list(map(lambda x: start + \" \"+ x + \" \" + end, img_caption_list))\n",
        "        processed_list = list(map(lambda x: x.lower().replace(\".\", \"\").replace(\",\", \"\").split(\" \"), processed_list))\n",
        "        processed_list = list(map(lambda x: list(map(lambda y: word2index[y] if y in vocab else word2index[oov],x)),\n",
        "                                  processed_list))\n",
        "        return processed_list\n",
        "\n",
        "\n",
        "if platform == \"colab\":\n",
        "    CAPTIONS_FILE_PATH = '/content/drive/My Drive/A4/train_captions.tsv'\n",
        "else:\n",
        "    CAPTIONS_FILE_PATH = \"../data/train_captions.tsv\"\n",
        "    \n",
        "embedding_dim = 256\n",
        "freq_threshold = 4\n",
        "captions_preprocessing_obj = CaptionsPreprocessing(CAPTIONS_FILE_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VOCAB SIZE = 11981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd7-CWjdHbk5",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrqRAjJpHbk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageCaptionsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_dir, captions_dict, img_transform=None, captions_transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_dir (string): Directory with all the images.\n",
        "            captions_dict: Dictionary with captions list keyed by image ids (integers)\n",
        "            img_transform (callable, optional): Optional transform to be applied\n",
        "                on the image sample.\n",
        "\n",
        "            captions_transform: (callable, optional): Optional transform to be applied\n",
        "                on the caption sample (list).\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir\n",
        "        self.captions_dict = captions_dict\n",
        "        self.img_transform = img_transform\n",
        "        self.captions_transform = captions_transform\n",
        "\n",
        "        self.image_ids = list(captions_dict.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, 'image_{}.jpg'.format(self.image_ids[idx]))\n",
        "        image = io.imread(img_name)\n",
        "        captions = self.captions_dict[self.image_ids[idx]]\n",
        "        if self.img_transform:\n",
        "            image = self.img_transform(image)\n",
        "\n",
        "        if self.captions_transform:            \n",
        "            captions = self.captions_transform(captions)\n",
        "            \n",
        "        sample = {'image': image, 'captions': captions}\n",
        "\n",
        "        return sample\n",
        "    \n",
        "    \n",
        "def custom_batch(batch):\n",
        "    batch_size = len(batch)\n",
        "    captions = []\n",
        "    x = list(map(lambda b: captions.extend(b['captions']),batch))    \n",
        "    x = list(map(lambda b: b['image'],batch))\n",
        "    captions = list(map(lambda c: torch.LongTensor(c),captions))\n",
        "    captions = pad_sequence(captions, batch_first=True)\n",
        "    \n",
        "    sample = {'image': torch.Tensor(x).double(), 'captions': captions}    \n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVONgE-KHbk8",
        "colab_type": "text"
      },
      "source": [
        "### Encoder and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPoXMWZrHbk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ENCODER\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_size, filters, stride=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            channels: Int: Number of Input channels to 1st convolutional layer\n",
        "            kernel_size: integer, Symmetric Conv Window = (kernel_size, kernel_size)\n",
        "            filters: python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "            stride: Tuple: (stride, stride)\n",
        "        \"\"\"\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        F1, F2, F3 = filters\n",
        "        #N, in_channels , H, W = shape\n",
        "        kernel_size = (kernel_size, kernel_size)\n",
        "        padding = (1,1)\n",
        "        stride = (stride, stride)\n",
        "        self.conv1 = nn.Conv2d(in_channels = channels, out_channels = F1, kernel_size=(1,1), stride=stride, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(F1)\n",
        "        self.relu = nn.ReLU(inplace=True) \n",
        "        self.conv2 = nn.Conv2d(in_channels = F1, out_channels = F2, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.bn2 = nn.BatchNorm2d(F2)\n",
        "        self.conv3 = nn.Conv2d(in_channels = F2, out_channels = F3, kernel_size=(1,1), stride=stride, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(F3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x_residual = x #backup x for residual connection\n",
        "        \n",
        "        #stage 1 main path\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        #print(\"RESI:\", x.shape)\n",
        "        \n",
        "        #stage 2 main path\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        #print(\"RESI:\", x.shape)\n",
        "        \n",
        "        #stage 3 main path\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        #print(\"RESI:\", x.shape)\n",
        "        \n",
        "        x += x_residual #add output with residual connection\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "    \n",
        "class ConvolutionalBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_size, filters, stride=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            channels: Int: Number of Input channels to 1st convolutional layer\n",
        "            kernel_size: integer, Symmetric Conv Window = (kernel_size, kernel_size)\n",
        "            filters: python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "            stride: Tuple: (stride, stride)\n",
        "        \"\"\"\n",
        "        super(ConvolutionalBlock, self).__init__()\n",
        "        F1, F2, F3 = filters\n",
        "        kernel_size = (kernel_size, kernel_size)\n",
        "        padding = (1,1)\n",
        "        stride = (stride, stride)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels = channels, out_channels = F1, kernel_size=(1,1), stride=stride, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(F1)\n",
        "        self.relu = nn.ReLU(inplace=True) \n",
        "        self.conv2 = nn.Conv2d(in_channels = F1, out_channels = F2, kernel_size=kernel_size, stride=(1,1), padding=padding)\n",
        "        self.bn2 = nn.BatchNorm2d(F2)\n",
        "        self.conv3 = nn.Conv2d(in_channels = F2, out_channels = F3, kernel_size=(1,1), stride=(1,1), padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(F3)\n",
        "        self.conv4 = nn.Conv2d(in_channels = channels, out_channels = F3, kernel_size=(1,1), stride=stride, padding=0)\n",
        "        self.bn4 = nn.BatchNorm2d(F3)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x_residual = x #backup x for residual connection\n",
        "        \n",
        "        #stage 1 main path\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        #print(\"CONV:\", x.shape)\n",
        "        \n",
        "        #stage 2 main path\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        #print(\"CONV:\", x.shape)\n",
        "        \n",
        "        #stage 3 main path\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        #print(\"CONV:\", x.shape)\n",
        "        \n",
        "        #residual connection\n",
        "        x_residual = self.conv4(x_residual)\n",
        "        x_residual = self.bn4(x_residual)\n",
        "        x += x_residual #add output with residual connection\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "    \n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, input_shape = (256, 256, 3), classes = 5):\n",
        "        \"\"\"\n",
        "        It Implements Famous Resnet50 Architecture\n",
        "        Args:\n",
        "            input_shape(tuple):(callable, optional): dimensions of image sample\n",
        "            classes(int):(callable, optional): Final output classes of softmax layer.\n",
        "        \"\"\"\n",
        "        super(ResNet50, self).__init__()\n",
        "        \n",
        "        self.pad = nn.ZeroPad2d((1, 1, 3, 3))        \n",
        "        ###STAGE1\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels=64, kernel_size=(7,7), stride = (2,2), padding=1) # convolve each of our 3-channel images with 6 different 5x5 kernels, giving us 6 feature maps\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64) #BatchNorm\n",
        "        self.pool1 = nn.MaxPool2d((3,3), stride=(2,2), padding=1, dilation=1)\n",
        "        \n",
        "        ###STAGE2 channels, kernel_size=3, filters, stride=1, stage\n",
        "        self.conv_block1 = ConvolutionalBlock(channels = 64, kernel_size = 3, filters = [64, 64, 256],stride = 1)\n",
        "        self.residual_block1 = ResidualBlock(channels = 256, kernel_size = 3, filters = [64, 64, 256])\n",
        "        \n",
        "        ###STAGE3 \n",
        "        self.conv_block2 = ConvolutionalBlock(channels = 256, kernel_size = 3, filters = [128, 128, 512],stride = 2)\n",
        "        self.residual_block2 = ResidualBlock(channels = 512, kernel_size = 3, filters = [128, 128, 512],)\n",
        "        \n",
        "        ###STAGE4 \n",
        "        self.conv_block3 = ConvolutionalBlock(channels = 512, kernel_size = 3, filters = [256, 256, 1024], stride = 2)\n",
        "        self.residual_block3 = ResidualBlock(channels = 1024, kernel_size = 3, filters = [256, 256, 1024])\n",
        "        \n",
        "        ###STAGE5 \n",
        "        self.conv_block4 = ConvolutionalBlock(channels = 1024, kernel_size = 3, filters = [512, 512, 2048], stride = 2)\n",
        "        self.residual_block4 = ResidualBlock(channels = 2048, kernel_size = 3, filters = [512, 512, 2048])\n",
        "        \n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
        "        self.fc1 = nn.Linear(in_features=2048, out_features=classes, bias = True)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        #print(\"IP_SIZE:\", x.shape)\n",
        "        \n",
        "        ###STAGE1        \n",
        "        #print(\"\\n STAGE1\")\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.pool1(x)\n",
        "        #print(\"OP_STAGE1_SIZE:\", x.shape)\n",
        "        \n",
        "        ###STAGE2 \n",
        "        #print(\"\\n STAGE2\")\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.residual_block1(x)\n",
        "        x = self.residual_block1(x)\n",
        "        #print(\"OP_STAGE2_SIZE:\", x.shape)\n",
        "        \n",
        "        ###STAGE3 \n",
        "        #print(\"\\n STAGE3\")\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.residual_block2(x)\n",
        "        x = self.residual_block2(x)\n",
        "        x = self.residual_block2(x)\n",
        "        #print(\"OP_STAGE3_SIZE:\", x.shape)\n",
        "        \n",
        "        ###STAGE4  \n",
        "        #print(\"\\n STAGE4\")\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.residual_block3(x)\n",
        "        x = self.residual_block3(x)\n",
        "        x = self.residual_block3(x)\n",
        "        x = self.residual_block3(x)\n",
        "        x = self.residual_block3(x)\n",
        "        #print(\"OP_STAGE4_SIZE:\", x.shape)\n",
        "        \n",
        "        ###STAGE5  \n",
        "        #print(\"\\n STAGE5\")\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.residual_block4(x)\n",
        "        x = self.residual_block4(x)\n",
        "        #print(\"OP_STAGE5_SIZE:\", x.shape)\n",
        "        \n",
        "        x = self.adaptive_pool(x)\n",
        "        #print(\"OP_ADAPTIVEPOOL_SHAPE\", x.shape)\n",
        "        \n",
        "        x = x.view(x.size(0), -1) # Flatten Vector\n",
        "        x = self.fc1(x)\n",
        "        #print(\"OP_FC1_SIZE:\", x.shape)\n",
        "        return x\n",
        "        \n",
        "        \n",
        "class Encoder(nn.Module):    \n",
        "    def __init__(self, embed_dim):\n",
        "        \"\"\"\n",
        "        CNN ENCODER\n",
        "        Args:\n",
        "            embed_dim(int): embedding dimension ie output dimension of last FC Layer\n",
        "        Returns:\n",
        "            x: Feature vector of size(BatchSize, embed_dim)\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.resnet50 = ResNet50(classes = embed_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.resnet50(x)\n",
        "    \n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, units, vocab_size):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W1 = nn.Linear(in_features = embed_dim, out_features = units)\n",
        "        self.W2 = nn.Linear(in_features=units, out_features=units)\n",
        "        self.V = nn.Linear(in_features=units, out_features=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, img_features, hidden):\n",
        "        \n",
        "        hidden = hidden.unsqueeze(dim=1)\n",
        "        hidden = hidden.double()\n",
        "        #print(\"feature and hidden shape\",img_features.shape, hidden.shape)\n",
        "        combined_score = self.tanh(self.W1(img_features) + self.W2(hidden))\n",
        "        \n",
        "        attention_weights = self.softmax(self.V(combined_score))\n",
        "        context_vector = attention_weights * img_features\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "        \n",
        "        return context_vector, attention_weights    \n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embed_dim, lstm_hidden_size,lstm_layers=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm_hidden_size = lstm_hidden_size\n",
        "        self.vocab_size = len(VOCAB)\n",
        "        print(\"VOCAB SIZE = \", self.vocab_size)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = lstm_hidden_size,\n",
        "                            num_layers = lstm_layers, batch_first = True)\n",
        "        \n",
        "        self.linear = nn.Linear(lstm_hidden_size, self.vocab_size)        \n",
        "        self.embed = nn.Embedding(self.vocab_size, embed_dim)\n",
        "        \n",
        "        self.attention = AttentionBlock(embed_dim, lstm_hidden_size, self.vocab_size)\n",
        "\n",
        "        \n",
        "    def forward(self, image_features, image_captions):\n",
        "        \n",
        "        if phase == \"Train\":\n",
        "            image_features = torch.Tensor.repeat_interleave(image_features, repeats=5 , dim=0)\n",
        "        image_features = image_features.unsqueeze(1)\n",
        "        \n",
        "        hidden = torch.zeros((image_features.shape[0], self.lstm_hidden_size))\n",
        "        if device == \"cuda\":\n",
        "          hidden = hidden.to(torch.device(\"cuda:0\"))\n",
        "        \n",
        "        context, attention = self.attention(image_features, hidden)\n",
        "        \n",
        "        embedded_captions = self.embed(image_captions)\n",
        "        #print(\"EMBED SHAPE\", embedded_captions.shape)\n",
        "        #print(\"SHAPES BEFORE CONCAT\",context.unsqueeze(dim=1).shape, embedded_captions[:,:-1].shape)\n",
        "        input_lstm = torch.cat((context.unsqueeze(dim=1), embedded_captions[:,:-1]), dim = 1)\n",
        "        \n",
        "        lstm_outputs, _ = self.lstm(input_lstm)        \n",
        "        lstm_outputs = self.linear(lstm_outputs)\n",
        "        #print(\"lstm_outputs.shape\", lstm_outputs.shape)\n",
        "        \n",
        "        \n",
        "        return lstm_outputs\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT0CTF8-HblC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "1295e6c4-7a1d-454a-fdcf-1a8febeecfad"
      },
      "source": [
        "class ImageCaptionsNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageCaptionsNet, self).__init__()        \n",
        "        ##CNN ENCODER RESNET-50        \n",
        "        self.Encoder = Encoder(embed_dim = embedding_dim)\n",
        "        ## RNN DECODER\n",
        "        self.Decoder = Decoder(embedding_dim, units, 1)    \n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = image_batch, captions_batch\n",
        "        x = self.Encoder(image_batch)\n",
        "        x = self.Decoder(x, captions_batch)\n",
        "        return x\n",
        "    \n",
        "units = 512\n",
        "if restore == False:\n",
        "    net = ImageCaptionsNet()\n",
        "    net = net.double()\n",
        "    \n",
        "    if parallel == True and device != \"cpu\":\n",
        "        print(\"Parallel Processing enabled\")\n",
        "        net = nn.DataParallel(net)\n",
        "\n",
        "    if device == \"cpu\":\n",
        "        print(\"Device to CPU\")\n",
        "    else:\n",
        "        print(\"Device to CUDA\")\n",
        "        net = net.to(torch.device(\"cuda:0\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VOCAB SIZE =  11981\n",
            "Parallel Processing enabled\n",
            "Device to CUDA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7HtlOHRHblG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Save and Restore Checkpoints'''\n",
        "def create_checkpoint(path,model, optim_obj, loss_obj,iteration, epoch):\n",
        "    checkpoint = {'epoch': epoch,\n",
        "                  'iteration': iteration,\n",
        "                  'model_state_dict': model.module.state_dict(),\n",
        "                  'optimizer_state_dict': optim_obj.state_dict(),\n",
        "                  'loss': loss_obj}\n",
        "\n",
        "    if platform == \"colab\":\n",
        "        directory = '/content/drive/My Drive/A4/clean_checkpoint/'\n",
        "    else:\n",
        "        directory = '../clean_checkpoint/'\n",
        "\n",
        "    torch.save(checkpoint, directory + path)\n",
        "    \n",
        "def restore_checkpoint(path):\n",
        "    new_state_dict = collections.OrderedDict()\n",
        "    if platform == \"colab\":\n",
        "        directory = '/content/drive/My Drive/A4/clean_checkpoint/'\n",
        "        checkpoint = torch.load(directory + path)\n",
        "    else:\n",
        "        directory = '../clean_checkpoint/'\n",
        "        checkpoint = torch.load(directory + path, map_location=torch.device('cpu'))    \n",
        "    \n",
        "    epoch = checkpoint['epoch']\n",
        "    new_state_dict = checkpoint['model_state_dict']\n",
        "    iteration = checkpoint['iteration']\n",
        "    optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "    loss_obj = checkpoint['loss']\n",
        "    print(\"Iterations = {}, Epoch = {}, loss = {}\".format(iteration, epoch, loss_obj.item()))\n",
        "    return new_state_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRFEGn7vHblL",
        "colab_type": "text"
      },
      "source": [
        "### TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu5-5PJPHblM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ff0f29c-f653-4a1a-e04e-d18cab31f4ff"
      },
      "source": [
        "if platform == \"colab\":\n",
        "    IMAGE_DIR = '/content/drive/My Drive/train_images/'\n",
        "else:\n",
        "    IMAGE_DIR = 'D:/Padhai/IIT Delhi MS(R)/2019-20 Sem II/COL774 Machine Learning/Assignment/Assignment4/train_images/'\n",
        "\n",
        "if restore == True:\n",
        "    net = ImageCaptionsNet()\n",
        "    net = net.double()\n",
        "    #net = net.to(torch.device(\"cuda:0\"))\n",
        "    #net = nn.DataParallel(net)\n",
        "    new_state_dict = collections.OrderedDict()\n",
        "    new_state_dict = restore_checkpoint(\"caption_chkpt_multi.pth\")\n",
        "    \n",
        "    net.load_state_dict(new_state_dict)\n",
        "    print(\"State Dictionary Loaded Successfully.\")\n",
        "    net = nn.DataParallel(net)\n",
        "    net = net.to(torch.device(\"cuda:0\"))\n",
        "\n",
        "# Creating the Dataset\n",
        "train_dataset = ImageCaptionsDataset(\n",
        "    IMAGE_DIR, captions_preprocessing_obj.captions_dict, img_transform=img_transform,\n",
        "    captions_transform=captions_preprocessing_obj.captions_transform\n",
        ")\n",
        "\n",
        "# Define your hyperparameters\n",
        "NUMBER_OF_EPOCHS = 3\n",
        "LEARNING_RATE = 1e-2\n",
        "BATCH_SIZE = 24\n",
        "NUM_WORKERS = 0 # Parallel threads for dataloading\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=WORD2IDX[\"<pad>\"])\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "print(\"GLOBAL PARAMS:\", NUMBER_OF_EPOCHS, BATCH_SIZE, optimizer)\n",
        "loss_list = []\n",
        "# Creating the DataLoader for batching purposes\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS,\n",
        "                          collate_fn=custom_batch)\n",
        "\n",
        "if device != \"cpu\":\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    #torch.cuda.set_device(1)\n",
        "t0 = time()\n",
        "for epoch in range(NUMBER_OF_EPOCHS):\n",
        "    print(\"$$$$$----EPOCH {}----$$$$$$\".format(epoch+1))\n",
        "    iteration = 0\n",
        "\n",
        "    for batch_idx, sample in enumerate(train_loader):\n",
        "        iteration +=1\n",
        "        \n",
        "        '''if (epoch+1 == 1 and iteration > 400):\n",
        "          LEARNING_RATE = 9e-3\n",
        "          optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "        elif (epoch+1 == 2 and iteration <=400):\n",
        "          LEARNING_RATE = 6e-3\n",
        "          optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "        elif (epoch+1 == 2 and iteration >400):\n",
        "          LEARNING_RATE = 1e-3\n",
        "          optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "        elif (epoch+1 ==3):\n",
        "          LEARNING_RATE = 8e-4\n",
        "          optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)'''\n",
        "        if iteration%125 == 0:\n",
        "          LEARNING_RATE *= 0.92           \n",
        "          optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "          print(\"OPTIMIZER =\", LEARNING_RATE, optimizer)\n",
        "\n",
        "        net.zero_grad()\n",
        "\n",
        "        image_batch, captions_batch = sample['image'], sample['captions']\n",
        "        \n",
        "        #print(\"image_shape\", image_batch.shape)\n",
        "        #print(\"batch_shape\", captions_batch.shape)\n",
        "        \n",
        "\n",
        "        # If GPU training required\n",
        "        if device != \"cpu\":\n",
        "          #print(\"cuda\")\n",
        "          image_batch, captions_batch = image_batch.to(torch.device(\"cuda:0\")), captions_batch.to(torch.device(\"cuda:0\"))\n",
        "        \n",
        "        output_captions = net((image_batch, captions_batch))\n",
        "        \n",
        "\n",
        "        #print(\"size for loss\", output_captions.shape, captions_batch.shape)\n",
        "        loss = loss_function(output_captions.reshape(-1, output_captions.shape[2]), captions_batch.reshape(-1))\n",
        "        loss_list.append(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if iteration%10 == 0:\n",
        "            create_checkpoint(\"caption_chkpt_clean.pth\", net, optimizer, loss, iteration, epoch+1)\n",
        "        print(\"ITERATION:[{}/{}] | LOSS: {} | EPOCH = [{}/{}] | TIME ELAPSED ={}Mins\".format(iteration, round(29000/BATCH_SIZE)+1,\n",
        "              round(loss.item(), 6), epoch+1, NUMBER_OF_EPOCHS, round((time()-t0)/60,2)))\n",
        "    print(\"\\n$$Loss = {},EPOCH: [{}/{}]\\n\\n\".format(round(loss.item(), 6), epoch+1, NUMBER_OF_EPOCHS))\n",
        "    create_checkpoint(\"epoch{}_chkpt_clean.pth\".format(epoch+1), net, optimizer, loss, iteration, epoch+1)\n",
        "\n",
        "create_checkpoint(\"Final_Model_clean.pth\", net, optimizer, loss, iteration, epoch+1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GLOBAL PARAMS: 3 24 Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.01\n",
            "    weight_decay: 0\n",
            ")\n",
            "$$$$$----EPOCH 1----$$$$$$\n",
            "ITERATION:[1/1209] | LOSS: 9.403143 | EPOCH = [1/3] | TIME ELAPSED =0.41Mins\n",
            "ITERATION:[2/1209] | LOSS: 8.85462 | EPOCH = [1/3] | TIME ELAPSED =0.69Mins\n",
            "ITERATION:[3/1209] | LOSS: 5.947085 | EPOCH = [1/3] | TIME ELAPSED =0.98Mins\n",
            "ITERATION:[4/1209] | LOSS: 6.236547 | EPOCH = [1/3] | TIME ELAPSED =1.26Mins\n",
            "ITERATION:[5/1209] | LOSS: 5.570205 | EPOCH = [1/3] | TIME ELAPSED =1.58Mins\n",
            "ITERATION:[6/1209] | LOSS: 5.608498 | EPOCH = [1/3] | TIME ELAPSED =1.86Mins\n",
            "ITERATION:[7/1209] | LOSS: 5.568336 | EPOCH = [1/3] | TIME ELAPSED =2.16Mins\n",
            "ITERATION:[8/1209] | LOSS: 5.348892 | EPOCH = [1/3] | TIME ELAPSED =2.42Mins\n",
            "ITERATION:[9/1209] | LOSS: 5.223582 | EPOCH = [1/3] | TIME ELAPSED =2.69Mins\n",
            "ITERATION:[10/1209] | LOSS: 5.107593 | EPOCH = [1/3] | TIME ELAPSED =3.21Mins\n",
            "ITERATION:[11/1209] | LOSS: 4.747217 | EPOCH = [1/3] | TIME ELAPSED =3.49Mins\n",
            "ITERATION:[12/1209] | LOSS: 4.802676 | EPOCH = [1/3] | TIME ELAPSED =3.76Mins\n",
            "ITERATION:[13/1209] | LOSS: 4.772618 | EPOCH = [1/3] | TIME ELAPSED =4.04Mins\n",
            "ITERATION:[14/1209] | LOSS: 4.703785 | EPOCH = [1/3] | TIME ELAPSED =4.3Mins\n",
            "ITERATION:[15/1209] | LOSS: 4.603667 | EPOCH = [1/3] | TIME ELAPSED =4.58Mins\n",
            "ITERATION:[16/1209] | LOSS: 4.56796 | EPOCH = [1/3] | TIME ELAPSED =4.86Mins\n",
            "ITERATION:[17/1209] | LOSS: 4.594414 | EPOCH = [1/3] | TIME ELAPSED =5.14Mins\n",
            "ITERATION:[18/1209] | LOSS: 4.515602 | EPOCH = [1/3] | TIME ELAPSED =5.49Mins\n",
            "ITERATION:[19/1209] | LOSS: 4.552646 | EPOCH = [1/3] | TIME ELAPSED =5.76Mins\n",
            "ITERATION:[20/1209] | LOSS: 4.645201 | EPOCH = [1/3] | TIME ELAPSED =6.09Mins\n",
            "ITERATION:[21/1209] | LOSS: 4.592356 | EPOCH = [1/3] | TIME ELAPSED =6.38Mins\n",
            "ITERATION:[22/1209] | LOSS: 4.268668 | EPOCH = [1/3] | TIME ELAPSED =6.66Mins\n",
            "ITERATION:[23/1209] | LOSS: 4.171979 | EPOCH = [1/3] | TIME ELAPSED =6.94Mins\n",
            "ITERATION:[24/1209] | LOSS: 4.265098 | EPOCH = [1/3] | TIME ELAPSED =7.24Mins\n",
            "ITERATION:[25/1209] | LOSS: 4.147902 | EPOCH = [1/3] | TIME ELAPSED =7.52Mins\n",
            "ITERATION:[26/1209] | LOSS: 4.125333 | EPOCH = [1/3] | TIME ELAPSED =7.79Mins\n",
            "ITERATION:[27/1209] | LOSS: 4.257708 | EPOCH = [1/3] | TIME ELAPSED =8.09Mins\n",
            "ITERATION:[28/1209] | LOSS: 4.108725 | EPOCH = [1/3] | TIME ELAPSED =8.37Mins\n",
            "ITERATION:[29/1209] | LOSS: 4.19903 | EPOCH = [1/3] | TIME ELAPSED =8.66Mins\n",
            "ITERATION:[30/1209] | LOSS: 4.035779 | EPOCH = [1/3] | TIME ELAPSED =8.96Mins\n",
            "ITERATION:[31/1209] | LOSS: 4.256548 | EPOCH = [1/3] | TIME ELAPSED =9.26Mins\n",
            "ITERATION:[32/1209] | LOSS: 4.140006 | EPOCH = [1/3] | TIME ELAPSED =9.55Mins\n",
            "ITERATION:[33/1209] | LOSS: 4.007441 | EPOCH = [1/3] | TIME ELAPSED =9.84Mins\n",
            "ITERATION:[34/1209] | LOSS: 3.96876 | EPOCH = [1/3] | TIME ELAPSED =10.12Mins\n",
            "ITERATION:[35/1209] | LOSS: 4.178445 | EPOCH = [1/3] | TIME ELAPSED =10.39Mins\n",
            "ITERATION:[36/1209] | LOSS: 4.04871 | EPOCH = [1/3] | TIME ELAPSED =10.68Mins\n",
            "ITERATION:[37/1209] | LOSS: 3.880186 | EPOCH = [1/3] | TIME ELAPSED =10.95Mins\n",
            "ITERATION:[38/1209] | LOSS: 4.063853 | EPOCH = [1/3] | TIME ELAPSED =11.24Mins\n",
            "ITERATION:[39/1209] | LOSS: 3.785924 | EPOCH = [1/3] | TIME ELAPSED =11.51Mins\n",
            "ITERATION:[40/1209] | LOSS: 4.012656 | EPOCH = [1/3] | TIME ELAPSED =11.84Mins\n",
            "ITERATION:[41/1209] | LOSS: 3.889411 | EPOCH = [1/3] | TIME ELAPSED =12.13Mins\n",
            "ITERATION:[42/1209] | LOSS: 4.089997 | EPOCH = [1/3] | TIME ELAPSED =12.42Mins\n",
            "ITERATION:[43/1209] | LOSS: 4.14544 | EPOCH = [1/3] | TIME ELAPSED =12.71Mins\n",
            "ITERATION:[44/1209] | LOSS: 3.83061 | EPOCH = [1/3] | TIME ELAPSED =12.98Mins\n",
            "ITERATION:[45/1209] | LOSS: 3.802637 | EPOCH = [1/3] | TIME ELAPSED =13.25Mins\n",
            "ITERATION:[46/1209] | LOSS: 3.885689 | EPOCH = [1/3] | TIME ELAPSED =13.54Mins\n",
            "ITERATION:[47/1209] | LOSS: 4.181655 | EPOCH = [1/3] | TIME ELAPSED =13.83Mins\n",
            "ITERATION:[48/1209] | LOSS: 3.801385 | EPOCH = [1/3] | TIME ELAPSED =14.11Mins\n",
            "ITERATION:[49/1209] | LOSS: 3.748961 | EPOCH = [1/3] | TIME ELAPSED =14.4Mins\n",
            "ITERATION:[50/1209] | LOSS: 3.784043 | EPOCH = [1/3] | TIME ELAPSED =14.72Mins\n",
            "ITERATION:[51/1209] | LOSS: 3.846205 | EPOCH = [1/3] | TIME ELAPSED =14.99Mins\n",
            "ITERATION:[52/1209] | LOSS: 3.749296 | EPOCH = [1/3] | TIME ELAPSED =15.28Mins\n",
            "ITERATION:[53/1209] | LOSS: 3.819456 | EPOCH = [1/3] | TIME ELAPSED =15.58Mins\n",
            "ITERATION:[54/1209] | LOSS: 3.73148 | EPOCH = [1/3] | TIME ELAPSED =15.87Mins\n",
            "ITERATION:[55/1209] | LOSS: 3.83662 | EPOCH = [1/3] | TIME ELAPSED =16.18Mins\n",
            "ITERATION:[56/1209] | LOSS: 3.620988 | EPOCH = [1/3] | TIME ELAPSED =16.47Mins\n",
            "ITERATION:[57/1209] | LOSS: 4.000908 | EPOCH = [1/3] | TIME ELAPSED =16.76Mins\n",
            "ITERATION:[58/1209] | LOSS: 3.703074 | EPOCH = [1/3] | TIME ELAPSED =17.04Mins\n",
            "ITERATION:[59/1209] | LOSS: 3.78312 | EPOCH = [1/3] | TIME ELAPSED =17.32Mins\n",
            "ITERATION:[60/1209] | LOSS: 3.950007 | EPOCH = [1/3] | TIME ELAPSED =17.64Mins\n",
            "ITERATION:[61/1209] | LOSS: 3.619287 | EPOCH = [1/3] | TIME ELAPSED =17.91Mins\n",
            "ITERATION:[62/1209] | LOSS: 3.609629 | EPOCH = [1/3] | TIME ELAPSED =18.2Mins\n",
            "ITERATION:[63/1209] | LOSS: 3.808675 | EPOCH = [1/3] | TIME ELAPSED =18.48Mins\n",
            "ITERATION:[64/1209] | LOSS: 3.78932 | EPOCH = [1/3] | TIME ELAPSED =18.76Mins\n",
            "ITERATION:[65/1209] | LOSS: 3.559684 | EPOCH = [1/3] | TIME ELAPSED =19.06Mins\n",
            "ITERATION:[66/1209] | LOSS: 3.785463 | EPOCH = [1/3] | TIME ELAPSED =19.33Mins\n",
            "ITERATION:[67/1209] | LOSS: 3.997679 | EPOCH = [1/3] | TIME ELAPSED =19.61Mins\n",
            "ITERATION:[68/1209] | LOSS: 3.721216 | EPOCH = [1/3] | TIME ELAPSED =19.89Mins\n",
            "ITERATION:[69/1209] | LOSS: 3.745672 | EPOCH = [1/3] | TIME ELAPSED =20.17Mins\n",
            "ITERATION:[70/1209] | LOSS: 3.852317 | EPOCH = [1/3] | TIME ELAPSED =20.51Mins\n",
            "ITERATION:[71/1209] | LOSS: 3.704999 | EPOCH = [1/3] | TIME ELAPSED =20.81Mins\n",
            "ITERATION:[72/1209] | LOSS: 3.778277 | EPOCH = [1/3] | TIME ELAPSED =21.1Mins\n",
            "ITERATION:[73/1209] | LOSS: 3.770977 | EPOCH = [1/3] | TIME ELAPSED =21.38Mins\n",
            "ITERATION:[74/1209] | LOSS: 3.641123 | EPOCH = [1/3] | TIME ELAPSED =21.66Mins\n",
            "ITERATION:[75/1209] | LOSS: 3.649217 | EPOCH = [1/3] | TIME ELAPSED =21.95Mins\n",
            "ITERATION:[76/1209] | LOSS: 3.80533 | EPOCH = [1/3] | TIME ELAPSED =22.22Mins\n",
            "ITERATION:[77/1209] | LOSS: 3.976215 | EPOCH = [1/3] | TIME ELAPSED =22.49Mins\n",
            "ITERATION:[78/1209] | LOSS: 3.727526 | EPOCH = [1/3] | TIME ELAPSED =22.77Mins\n",
            "ITERATION:[79/1209] | LOSS: 3.614523 | EPOCH = [1/3] | TIME ELAPSED =23.08Mins\n",
            "ITERATION:[80/1209] | LOSS: 3.584602 | EPOCH = [1/3] | TIME ELAPSED =23.41Mins\n",
            "ITERATION:[81/1209] | LOSS: 3.756006 | EPOCH = [1/3] | TIME ELAPSED =23.69Mins\n",
            "ITERATION:[82/1209] | LOSS: 3.747638 | EPOCH = [1/3] | TIME ELAPSED =23.96Mins\n",
            "ITERATION:[83/1209] | LOSS: 3.759779 | EPOCH = [1/3] | TIME ELAPSED =24.25Mins\n",
            "ITERATION:[84/1209] | LOSS: 3.909321 | EPOCH = [1/3] | TIME ELAPSED =24.53Mins\n",
            "ITERATION:[85/1209] | LOSS: 3.749533 | EPOCH = [1/3] | TIME ELAPSED =24.82Mins\n",
            "ITERATION:[86/1209] | LOSS: 3.622995 | EPOCH = [1/3] | TIME ELAPSED =25.11Mins\n",
            "ITERATION:[87/1209] | LOSS: 3.484198 | EPOCH = [1/3] | TIME ELAPSED =25.39Mins\n",
            "ITERATION:[88/1209] | LOSS: 3.771223 | EPOCH = [1/3] | TIME ELAPSED =25.66Mins\n",
            "ITERATION:[89/1209] | LOSS: 3.498487 | EPOCH = [1/3] | TIME ELAPSED =25.93Mins\n",
            "ITERATION:[90/1209] | LOSS: 3.494302 | EPOCH = [1/3] | TIME ELAPSED =26.27Mins\n",
            "ITERATION:[91/1209] | LOSS: 3.639076 | EPOCH = [1/3] | TIME ELAPSED =26.55Mins\n",
            "ITERATION:[92/1209] | LOSS: 3.55493 | EPOCH = [1/3] | TIME ELAPSED =26.82Mins\n",
            "ITERATION:[93/1209] | LOSS: 3.618441 | EPOCH = [1/3] | TIME ELAPSED =27.1Mins\n",
            "ITERATION:[94/1209] | LOSS: 3.923682 | EPOCH = [1/3] | TIME ELAPSED =27.37Mins\n",
            "ITERATION:[95/1209] | LOSS: 3.661507 | EPOCH = [1/3] | TIME ELAPSED =27.67Mins\n",
            "ITERATION:[96/1209] | LOSS: 3.669426 | EPOCH = [1/3] | TIME ELAPSED =27.96Mins\n",
            "ITERATION:[97/1209] | LOSS: 3.751741 | EPOCH = [1/3] | TIME ELAPSED =28.24Mins\n",
            "ITERATION:[98/1209] | LOSS: 3.580589 | EPOCH = [1/3] | TIME ELAPSED =28.54Mins\n",
            "ITERATION:[99/1209] | LOSS: 3.683731 | EPOCH = [1/3] | TIME ELAPSED =28.81Mins\n",
            "OPTIMIZER = 0.0092 Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0092\n",
            "    weight_decay: 0\n",
            ")\n",
            "ITERATION:[100/1209] | LOSS: 3.721466 | EPOCH = [1/3] | TIME ELAPSED =29.17Mins\n",
            "ITERATION:[101/1209] | LOSS: 3.623016 | EPOCH = [1/3] | TIME ELAPSED =29.45Mins\n",
            "ITERATION:[102/1209] | LOSS: 3.574623 | EPOCH = [1/3] | TIME ELAPSED =29.72Mins\n",
            "ITERATION:[103/1209] | LOSS: 3.781092 | EPOCH = [1/3] | TIME ELAPSED =30.01Mins\n",
            "ITERATION:[104/1209] | LOSS: 3.885402 | EPOCH = [1/3] | TIME ELAPSED =30.3Mins\n",
            "ITERATION:[105/1209] | LOSS: 3.844776 | EPOCH = [1/3] | TIME ELAPSED =30.56Mins\n",
            "ITERATION:[106/1209] | LOSS: 3.628206 | EPOCH = [1/3] | TIME ELAPSED =30.88Mins\n",
            "ITERATION:[107/1209] | LOSS: 3.790347 | EPOCH = [1/3] | TIME ELAPSED =31.16Mins\n",
            "ITERATION:[108/1209] | LOSS: 3.822409 | EPOCH = [1/3] | TIME ELAPSED =31.44Mins\n",
            "ITERATION:[109/1209] | LOSS: 3.872693 | EPOCH = [1/3] | TIME ELAPSED =31.72Mins\n",
            "ITERATION:[110/1209] | LOSS: 3.806978 | EPOCH = [1/3] | TIME ELAPSED =32.06Mins\n",
            "ITERATION:[111/1209] | LOSS: 3.707827 | EPOCH = [1/3] | TIME ELAPSED =32.35Mins\n",
            "ITERATION:[112/1209] | LOSS: 3.810816 | EPOCH = [1/3] | TIME ELAPSED =32.6Mins\n",
            "ITERATION:[113/1209] | LOSS: 3.508754 | EPOCH = [1/3] | TIME ELAPSED =32.87Mins\n",
            "ITERATION:[114/1209] | LOSS: 3.617997 | EPOCH = [1/3] | TIME ELAPSED =33.14Mins\n",
            "ITERATION:[115/1209] | LOSS: 3.609366 | EPOCH = [1/3] | TIME ELAPSED =33.42Mins\n",
            "ITERATION:[116/1209] | LOSS: 3.704328 | EPOCH = [1/3] | TIME ELAPSED =33.69Mins\n",
            "ITERATION:[117/1209] | LOSS: 3.772556 | EPOCH = [1/3] | TIME ELAPSED =33.96Mins\n",
            "ITERATION:[118/1209] | LOSS: 3.59504 | EPOCH = [1/3] | TIME ELAPSED =34.24Mins\n",
            "ITERATION:[119/1209] | LOSS: 3.627363 | EPOCH = [1/3] | TIME ELAPSED =34.51Mins\n",
            "ITERATION:[120/1209] | LOSS: 3.800401 | EPOCH = [1/3] | TIME ELAPSED =34.86Mins\n",
            "ITERATION:[121/1209] | LOSS: 3.840944 | EPOCH = [1/3] | TIME ELAPSED =35.14Mins\n",
            "ITERATION:[122/1209] | LOSS: 3.548144 | EPOCH = [1/3] | TIME ELAPSED =35.49Mins\n",
            "ITERATION:[123/1209] | LOSS: 3.712115 | EPOCH = [1/3] | TIME ELAPSED =35.79Mins\n",
            "ITERATION:[124/1209] | LOSS: 3.60322 | EPOCH = [1/3] | TIME ELAPSED =36.07Mins\n",
            "ITERATION:[125/1209] | LOSS: 3.650633 | EPOCH = [1/3] | TIME ELAPSED =36.37Mins\n",
            "ITERATION:[126/1209] | LOSS: 3.826343 | EPOCH = [1/3] | TIME ELAPSED =36.65Mins\n",
            "ITERATION:[127/1209] | LOSS: 3.510673 | EPOCH = [1/3] | TIME ELAPSED =36.94Mins\n",
            "ITERATION:[128/1209] | LOSS: 3.894739 | EPOCH = [1/3] | TIME ELAPSED =37.21Mins\n",
            "ITERATION:[129/1209] | LOSS: 3.98382 | EPOCH = [1/3] | TIME ELAPSED =37.5Mins\n",
            "ITERATION:[130/1209] | LOSS: 3.963368 | EPOCH = [1/3] | TIME ELAPSED =37.84Mins\n",
            "ITERATION:[131/1209] | LOSS: 3.912798 | EPOCH = [1/3] | TIME ELAPSED =38.13Mins\n",
            "ITERATION:[132/1209] | LOSS: 3.679546 | EPOCH = [1/3] | TIME ELAPSED =38.4Mins\n",
            "ITERATION:[133/1209] | LOSS: 3.633595 | EPOCH = [1/3] | TIME ELAPSED =38.68Mins\n",
            "ITERATION:[134/1209] | LOSS: 3.696445 | EPOCH = [1/3] | TIME ELAPSED =38.97Mins\n",
            "ITERATION:[135/1209] | LOSS: 3.762318 | EPOCH = [1/3] | TIME ELAPSED =39.25Mins\n",
            "ITERATION:[136/1209] | LOSS: 3.639205 | EPOCH = [1/3] | TIME ELAPSED =39.54Mins\n",
            "ITERATION:[137/1209] | LOSS: 3.628735 | EPOCH = [1/3] | TIME ELAPSED =39.8Mins\n",
            "ITERATION:[138/1209] | LOSS: 3.765232 | EPOCH = [1/3] | TIME ELAPSED =40.09Mins\n",
            "ITERATION:[139/1209] | LOSS: 3.804361 | EPOCH = [1/3] | TIME ELAPSED =40.38Mins\n",
            "ITERATION:[140/1209] | LOSS: 3.692873 | EPOCH = [1/3] | TIME ELAPSED =40.68Mins\n",
            "ITERATION:[141/1209] | LOSS: 3.500025 | EPOCH = [1/3] | TIME ELAPSED =40.99Mins\n",
            "ITERATION:[142/1209] | LOSS: 3.676576 | EPOCH = [1/3] | TIME ELAPSED =41.25Mins\n",
            "ITERATION:[143/1209] | LOSS: 3.55373 | EPOCH = [1/3] | TIME ELAPSED =41.55Mins\n",
            "ITERATION:[144/1209] | LOSS: 3.798818 | EPOCH = [1/3] | TIME ELAPSED =41.83Mins\n",
            "ITERATION:[145/1209] | LOSS: 3.872716 | EPOCH = [1/3] | TIME ELAPSED =42.1Mins\n",
            "ITERATION:[146/1209] | LOSS: 3.606253 | EPOCH = [1/3] | TIME ELAPSED =42.38Mins\n",
            "ITERATION:[147/1209] | LOSS: 3.390096 | EPOCH = [1/3] | TIME ELAPSED =42.65Mins\n",
            "ITERATION:[148/1209] | LOSS: 3.521108 | EPOCH = [1/3] | TIME ELAPSED =42.92Mins\n",
            "ITERATION:[149/1209] | LOSS: 3.562542 | EPOCH = [1/3] | TIME ELAPSED =43.19Mins\n",
            "ITERATION:[150/1209] | LOSS: 3.695789 | EPOCH = [1/3] | TIME ELAPSED =43.52Mins\n",
            "ITERATION:[151/1209] | LOSS: 3.52383 | EPOCH = [1/3] | TIME ELAPSED =43.8Mins\n",
            "ITERATION:[152/1209] | LOSS: 3.760252 | EPOCH = [1/3] | TIME ELAPSED =44.1Mins\n",
            "ITERATION:[153/1209] | LOSS: 3.350236 | EPOCH = [1/3] | TIME ELAPSED =44.38Mins\n",
            "ITERATION:[154/1209] | LOSS: 3.689333 | EPOCH = [1/3] | TIME ELAPSED =44.65Mins\n",
            "ITERATION:[155/1209] | LOSS: 3.632937 | EPOCH = [1/3] | TIME ELAPSED =44.93Mins\n",
            "ITERATION:[156/1209] | LOSS: 3.702683 | EPOCH = [1/3] | TIME ELAPSED =45.22Mins\n",
            "ITERATION:[157/1209] | LOSS: 3.61533 | EPOCH = [1/3] | TIME ELAPSED =45.49Mins\n",
            "ITERATION:[158/1209] | LOSS: 3.609657 | EPOCH = [1/3] | TIME ELAPSED =45.86Mins\n",
            "ITERATION:[159/1209] | LOSS: 3.487849 | EPOCH = [1/3] | TIME ELAPSED =46.15Mins\n",
            "ITERATION:[160/1209] | LOSS: 3.509444 | EPOCH = [1/3] | TIME ELAPSED =46.47Mins\n",
            "ITERATION:[161/1209] | LOSS: 3.562836 | EPOCH = [1/3] | TIME ELAPSED =46.76Mins\n",
            "ITERATION:[162/1209] | LOSS: 3.56321 | EPOCH = [1/3] | TIME ELAPSED =47.03Mins\n",
            "ITERATION:[163/1209] | LOSS: 3.555071 | EPOCH = [1/3] | TIME ELAPSED =47.31Mins\n",
            "ITERATION:[164/1209] | LOSS: 3.673645 | EPOCH = [1/3] | TIME ELAPSED =47.6Mins\n",
            "ITERATION:[165/1209] | LOSS: 3.514312 | EPOCH = [1/3] | TIME ELAPSED =47.86Mins\n",
            "ITERATION:[166/1209] | LOSS: 3.627959 | EPOCH = [1/3] | TIME ELAPSED =48.14Mins\n",
            "ITERATION:[167/1209] | LOSS: 3.535335 | EPOCH = [1/3] | TIME ELAPSED =48.39Mins\n",
            "ITERATION:[168/1209] | LOSS: 3.538011 | EPOCH = [1/3] | TIME ELAPSED =48.68Mins\n",
            "ITERATION:[169/1209] | LOSS: 3.472899 | EPOCH = [1/3] | TIME ELAPSED =48.96Mins\n",
            "ITERATION:[170/1209] | LOSS: 3.419921 | EPOCH = [1/3] | TIME ELAPSED =49.28Mins\n",
            "ITERATION:[171/1209] | LOSS: 3.639908 | EPOCH = [1/3] | TIME ELAPSED =49.56Mins\n",
            "ITERATION:[172/1209] | LOSS: 3.570783 | EPOCH = [1/3] | TIME ELAPSED =49.82Mins\n",
            "ITERATION:[173/1209] | LOSS: 3.484677 | EPOCH = [1/3] | TIME ELAPSED =50.1Mins\n",
            "ITERATION:[174/1209] | LOSS: 3.378747 | EPOCH = [1/3] | TIME ELAPSED =50.38Mins\n",
            "ITERATION:[175/1209] | LOSS: 3.712748 | EPOCH = [1/3] | TIME ELAPSED =50.67Mins\n",
            "ITERATION:[176/1209] | LOSS: 3.816512 | EPOCH = [1/3] | TIME ELAPSED =50.95Mins\n",
            "ITERATION:[177/1209] | LOSS: 3.283521 | EPOCH = [1/3] | TIME ELAPSED =51.24Mins\n",
            "ITERATION:[178/1209] | LOSS: 3.466433 | EPOCH = [1/3] | TIME ELAPSED =51.51Mins\n",
            "ITERATION:[179/1209] | LOSS: 3.42261 | EPOCH = [1/3] | TIME ELAPSED =51.77Mins\n",
            "ITERATION:[180/1209] | LOSS: 3.393778 | EPOCH = [1/3] | TIME ELAPSED =52.1Mins\n",
            "ITERATION:[181/1209] | LOSS: 3.645604 | EPOCH = [1/3] | TIME ELAPSED =52.37Mins\n",
            "ITERATION:[182/1209] | LOSS: 3.347315 | EPOCH = [1/3] | TIME ELAPSED =52.65Mins\n",
            "ITERATION:[183/1209] | LOSS: 3.649825 | EPOCH = [1/3] | TIME ELAPSED =52.92Mins\n",
            "ITERATION:[184/1209] | LOSS: 3.510404 | EPOCH = [1/3] | TIME ELAPSED =53.21Mins\n",
            "ITERATION:[185/1209] | LOSS: 3.366522 | EPOCH = [1/3] | TIME ELAPSED =53.48Mins\n",
            "ITERATION:[186/1209] | LOSS: 3.69029 | EPOCH = [1/3] | TIME ELAPSED =53.74Mins\n",
            "ITERATION:[187/1209] | LOSS: 3.630371 | EPOCH = [1/3] | TIME ELAPSED =54.03Mins\n",
            "ITERATION:[188/1209] | LOSS: 3.576119 | EPOCH = [1/3] | TIME ELAPSED =54.31Mins\n",
            "ITERATION:[189/1209] | LOSS: 3.342289 | EPOCH = [1/3] | TIME ELAPSED =54.59Mins\n",
            "ITERATION:[190/1209] | LOSS: 3.468538 | EPOCH = [1/3] | TIME ELAPSED =54.9Mins\n",
            "ITERATION:[191/1209] | LOSS: 3.424091 | EPOCH = [1/3] | TIME ELAPSED =55.18Mins\n",
            "ITERATION:[192/1209] | LOSS: 3.408921 | EPOCH = [1/3] | TIME ELAPSED =55.46Mins\n",
            "ITERATION:[193/1209] | LOSS: 3.642409 | EPOCH = [1/3] | TIME ELAPSED =55.75Mins\n",
            "ITERATION:[194/1209] | LOSS: 3.399957 | EPOCH = [1/3] | TIME ELAPSED =56.02Mins\n",
            "ITERATION:[195/1209] | LOSS: 3.55841 | EPOCH = [1/3] | TIME ELAPSED =56.3Mins\n",
            "ITERATION:[196/1209] | LOSS: 3.685171 | EPOCH = [1/3] | TIME ELAPSED =56.59Mins\n",
            "ITERATION:[197/1209] | LOSS: 3.746063 | EPOCH = [1/3] | TIME ELAPSED =56.88Mins\n",
            "ITERATION:[198/1209] | LOSS: 3.279025 | EPOCH = [1/3] | TIME ELAPSED =57.19Mins\n",
            "ITERATION:[199/1209] | LOSS: 3.564009 | EPOCH = [1/3] | TIME ELAPSED =57.47Mins\n",
            "OPTIMIZER = 0.008464000000000001 Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.008464000000000001\n",
            "    weight_decay: 0\n",
            ")\n",
            "ITERATION:[200/1209] | LOSS: 3.218277 | EPOCH = [1/3] | TIME ELAPSED =57.8Mins\n",
            "ITERATION:[201/1209] | LOSS: 3.527338 | EPOCH = [1/3] | TIME ELAPSED =58.1Mins\n",
            "ITERATION:[202/1209] | LOSS: 3.599125 | EPOCH = [1/3] | TIME ELAPSED =58.38Mins\n",
            "ITERATION:[203/1209] | LOSS: 3.91187 | EPOCH = [1/3] | TIME ELAPSED =58.7Mins\n",
            "ITERATION:[204/1209] | LOSS: 3.614278 | EPOCH = [1/3] | TIME ELAPSED =58.98Mins\n",
            "ITERATION:[205/1209] | LOSS: 3.492373 | EPOCH = [1/3] | TIME ELAPSED =59.25Mins\n",
            "ITERATION:[206/1209] | LOSS: 3.587532 | EPOCH = [1/3] | TIME ELAPSED =59.54Mins\n",
            "ITERATION:[207/1209] | LOSS: 3.509071 | EPOCH = [1/3] | TIME ELAPSED =59.83Mins\n",
            "ITERATION:[208/1209] | LOSS: 3.531218 | EPOCH = [1/3] | TIME ELAPSED =60.11Mins\n",
            "ITERATION:[209/1209] | LOSS: 3.507085 | EPOCH = [1/3] | TIME ELAPSED =60.37Mins\n",
            "ITERATION:[210/1209] | LOSS: 3.76733 | EPOCH = [1/3] | TIME ELAPSED =60.71Mins\n",
            "ITERATION:[211/1209] | LOSS: 3.437072 | EPOCH = [1/3] | TIME ELAPSED =60.99Mins\n",
            "ITERATION:[212/1209] | LOSS: 3.375377 | EPOCH = [1/3] | TIME ELAPSED =61.26Mins\n",
            "ITERATION:[213/1209] | LOSS: 3.895697 | EPOCH = [1/3] | TIME ELAPSED =61.53Mins\n",
            "ITERATION:[214/1209] | LOSS: 3.71733 | EPOCH = [1/3] | TIME ELAPSED =61.8Mins\n",
            "ITERATION:[215/1209] | LOSS: 3.590225 | EPOCH = [1/3] | TIME ELAPSED =62.06Mins\n",
            "ITERATION:[216/1209] | LOSS: 3.695415 | EPOCH = [1/3] | TIME ELAPSED =62.33Mins\n",
            "ITERATION:[217/1209] | LOSS: 3.576283 | EPOCH = [1/3] | TIME ELAPSED =62.59Mins\n",
            "ITERATION:[218/1209] | LOSS: 3.731444 | EPOCH = [1/3] | TIME ELAPSED =62.87Mins\n",
            "ITERATION:[219/1209] | LOSS: 3.62227 | EPOCH = [1/3] | TIME ELAPSED =63.14Mins\n",
            "ITERATION:[220/1209] | LOSS: 3.37289 | EPOCH = [1/3] | TIME ELAPSED =63.45Mins\n",
            "ITERATION:[221/1209] | LOSS: 3.489208 | EPOCH = [1/3] | TIME ELAPSED =63.73Mins\n",
            "ITERATION:[222/1209] | LOSS: 3.490372 | EPOCH = [1/3] | TIME ELAPSED =64.03Mins\n",
            "ITERATION:[223/1209] | LOSS: 3.485716 | EPOCH = [1/3] | TIME ELAPSED =64.31Mins\n",
            "ITERATION:[224/1209] | LOSS: 3.6996 | EPOCH = [1/3] | TIME ELAPSED =64.6Mins\n",
            "ITERATION:[225/1209] | LOSS: 3.637253 | EPOCH = [1/3] | TIME ELAPSED =64.88Mins\n",
            "ITERATION:[226/1209] | LOSS: 3.555862 | EPOCH = [1/3] | TIME ELAPSED =65.15Mins\n",
            "ITERATION:[227/1209] | LOSS: 3.435525 | EPOCH = [1/3] | TIME ELAPSED =65.43Mins\n",
            "ITERATION:[228/1209] | LOSS: 3.653993 | EPOCH = [1/3] | TIME ELAPSED =65.71Mins\n",
            "ITERATION:[229/1209] | LOSS: 3.462909 | EPOCH = [1/3] | TIME ELAPSED =65.99Mins\n",
            "ITERATION:[230/1209] | LOSS: 3.493271 | EPOCH = [1/3] | TIME ELAPSED =66.29Mins\n",
            "ITERATION:[231/1209] | LOSS: 3.389886 | EPOCH = [1/3] | TIME ELAPSED =66.57Mins\n",
            "ITERATION:[232/1209] | LOSS: 3.838266 | EPOCH = [1/3] | TIME ELAPSED =66.85Mins\n",
            "ITERATION:[233/1209] | LOSS: 3.70487 | EPOCH = [1/3] | TIME ELAPSED =67.12Mins\n",
            "ITERATION:[234/1209] | LOSS: 3.453773 | EPOCH = [1/3] | TIME ELAPSED =67.39Mins\n",
            "ITERATION:[235/1209] | LOSS: 3.434512 | EPOCH = [1/3] | TIME ELAPSED =67.67Mins\n",
            "ITERATION:[236/1209] | LOSS: 3.596404 | EPOCH = [1/3] | TIME ELAPSED =67.95Mins\n",
            "ITERATION:[237/1209] | LOSS: 3.651669 | EPOCH = [1/3] | TIME ELAPSED =68.22Mins\n",
            "ITERATION:[238/1209] | LOSS: 3.485453 | EPOCH = [1/3] | TIME ELAPSED =68.5Mins\n",
            "ITERATION:[239/1209] | LOSS: 3.393874 | EPOCH = [1/3] | TIME ELAPSED =68.78Mins\n",
            "ITERATION:[240/1209] | LOSS: 3.497647 | EPOCH = [1/3] | TIME ELAPSED =69.11Mins\n",
            "ITERATION:[241/1209] | LOSS: 3.508075 | EPOCH = [1/3] | TIME ELAPSED =69.39Mins\n",
            "ITERATION:[242/1209] | LOSS: 3.356732 | EPOCH = [1/3] | TIME ELAPSED =69.68Mins\n",
            "ITERATION:[243/1209] | LOSS: 3.556253 | EPOCH = [1/3] | TIME ELAPSED =69.94Mins\n",
            "ITERATION:[244/1209] | LOSS: 3.763162 | EPOCH = [1/3] | TIME ELAPSED =70.21Mins\n",
            "ITERATION:[245/1209] | LOSS: 3.655666 | EPOCH = [1/3] | TIME ELAPSED =70.5Mins\n",
            "ITERATION:[246/1209] | LOSS: 3.673338 | EPOCH = [1/3] | TIME ELAPSED =70.77Mins\n",
            "ITERATION:[247/1209] | LOSS: 3.553628 | EPOCH = [1/3] | TIME ELAPSED =71.05Mins\n",
            "ITERATION:[248/1209] | LOSS: 3.384714 | EPOCH = [1/3] | TIME ELAPSED =71.31Mins\n",
            "ITERATION:[249/1209] | LOSS: 3.608857 | EPOCH = [1/3] | TIME ELAPSED =71.6Mins\n",
            "ITERATION:[250/1209] | LOSS: 3.489642 | EPOCH = [1/3] | TIME ELAPSED =71.92Mins\n",
            "ITERATION:[251/1209] | LOSS: 3.477528 | EPOCH = [1/3] | TIME ELAPSED =72.2Mins\n",
            "ITERATION:[252/1209] | LOSS: 3.420177 | EPOCH = [1/3] | TIME ELAPSED =72.48Mins\n",
            "ITERATION:[253/1209] | LOSS: 3.504946 | EPOCH = [1/3] | TIME ELAPSED =72.76Mins\n",
            "ITERATION:[254/1209] | LOSS: 3.477672 | EPOCH = [1/3] | TIME ELAPSED =73.02Mins\n",
            "ITERATION:[255/1209] | LOSS: 3.446677 | EPOCH = [1/3] | TIME ELAPSED =73.29Mins\n",
            "ITERATION:[256/1209] | LOSS: 3.555377 | EPOCH = [1/3] | TIME ELAPSED =73.57Mins\n",
            "ITERATION:[257/1209] | LOSS: 3.543577 | EPOCH = [1/3] | TIME ELAPSED =73.87Mins\n",
            "ITERATION:[258/1209] | LOSS: 3.34874 | EPOCH = [1/3] | TIME ELAPSED =74.14Mins\n",
            "ITERATION:[259/1209] | LOSS: 3.328849 | EPOCH = [1/3] | TIME ELAPSED =74.43Mins\n",
            "ITERATION:[260/1209] | LOSS: 3.44856 | EPOCH = [1/3] | TIME ELAPSED =74.75Mins\n",
            "ITERATION:[261/1209] | LOSS: 3.527235 | EPOCH = [1/3] | TIME ELAPSED =75.06Mins\n",
            "ITERATION:[262/1209] | LOSS: 3.65841 | EPOCH = [1/3] | TIME ELAPSED =75.38Mins\n",
            "ITERATION:[263/1209] | LOSS: 3.179258 | EPOCH = [1/3] | TIME ELAPSED =75.66Mins\n",
            "ITERATION:[264/1209] | LOSS: 3.658505 | EPOCH = [1/3] | TIME ELAPSED =75.95Mins\n",
            "ITERATION:[265/1209] | LOSS: 3.55386 | EPOCH = [1/3] | TIME ELAPSED =76.22Mins\n",
            "ITERATION:[266/1209] | LOSS: 3.565704 | EPOCH = [1/3] | TIME ELAPSED =76.49Mins\n",
            "ITERATION:[267/1209] | LOSS: 3.750718 | EPOCH = [1/3] | TIME ELAPSED =76.76Mins\n",
            "ITERATION:[268/1209] | LOSS: 3.558173 | EPOCH = [1/3] | TIME ELAPSED =77.03Mins\n",
            "ITERATION:[269/1209] | LOSS: 3.39209 | EPOCH = [1/3] | TIME ELAPSED =77.31Mins\n",
            "ITERATION:[270/1209] | LOSS: 3.384455 | EPOCH = [1/3] | TIME ELAPSED =77.65Mins\n",
            "ITERATION:[271/1209] | LOSS: 3.520309 | EPOCH = [1/3] | TIME ELAPSED =77.93Mins\n",
            "ITERATION:[272/1209] | LOSS: 3.438742 | EPOCH = [1/3] | TIME ELAPSED =78.19Mins\n",
            "ITERATION:[273/1209] | LOSS: 3.384834 | EPOCH = [1/3] | TIME ELAPSED =78.49Mins\n",
            "ITERATION:[274/1209] | LOSS: 3.51476 | EPOCH = [1/3] | TIME ELAPSED =78.77Mins\n",
            "ITERATION:[275/1209] | LOSS: 3.382864 | EPOCH = [1/3] | TIME ELAPSED =79.05Mins\n",
            "ITERATION:[276/1209] | LOSS: 3.431954 | EPOCH = [1/3] | TIME ELAPSED =79.32Mins\n",
            "ITERATION:[277/1209] | LOSS: 3.460373 | EPOCH = [1/3] | TIME ELAPSED =79.6Mins\n",
            "ITERATION:[278/1209] | LOSS: 3.620292 | EPOCH = [1/3] | TIME ELAPSED =79.92Mins\n",
            "ITERATION:[279/1209] | LOSS: 3.472695 | EPOCH = [1/3] | TIME ELAPSED =80.19Mins\n",
            "ITERATION:[280/1209] | LOSS: 3.616319 | EPOCH = [1/3] | TIME ELAPSED =80.52Mins\n",
            "ITERATION:[281/1209] | LOSS: 3.484692 | EPOCH = [1/3] | TIME ELAPSED =80.79Mins\n",
            "ITERATION:[282/1209] | LOSS: 3.54175 | EPOCH = [1/3] | TIME ELAPSED =81.07Mins\n",
            "ITERATION:[283/1209] | LOSS: 3.209419 | EPOCH = [1/3] | TIME ELAPSED =81.37Mins\n",
            "ITERATION:[284/1209] | LOSS: 3.342832 | EPOCH = [1/3] | TIME ELAPSED =81.65Mins\n",
            "ITERATION:[285/1209] | LOSS: 3.44519 | EPOCH = [1/3] | TIME ELAPSED =81.93Mins\n",
            "ITERATION:[286/1209] | LOSS: 3.525569 | EPOCH = [1/3] | TIME ELAPSED =82.2Mins\n",
            "ITERATION:[287/1209] | LOSS: 3.174219 | EPOCH = [1/3] | TIME ELAPSED =82.48Mins\n",
            "ITERATION:[288/1209] | LOSS: 3.27473 | EPOCH = [1/3] | TIME ELAPSED =82.77Mins\n",
            "ITERATION:[289/1209] | LOSS: 3.424028 | EPOCH = [1/3] | TIME ELAPSED =83.06Mins\n",
            "ITERATION:[290/1209] | LOSS: 3.529463 | EPOCH = [1/3] | TIME ELAPSED =83.39Mins\n",
            "ITERATION:[291/1209] | LOSS: 3.464256 | EPOCH = [1/3] | TIME ELAPSED =83.67Mins\n",
            "ITERATION:[292/1209] | LOSS: 3.321758 | EPOCH = [1/3] | TIME ELAPSED =83.94Mins\n",
            "ITERATION:[293/1209] | LOSS: 3.342805 | EPOCH = [1/3] | TIME ELAPSED =84.22Mins\n",
            "ITERATION:[294/1209] | LOSS: 3.545942 | EPOCH = [1/3] | TIME ELAPSED =84.5Mins\n",
            "ITERATION:[295/1209] | LOSS: 3.475382 | EPOCH = [1/3] | TIME ELAPSED =84.77Mins\n",
            "ITERATION:[296/1209] | LOSS: 3.390909 | EPOCH = [1/3] | TIME ELAPSED =85.05Mins\n",
            "ITERATION:[297/1209] | LOSS: 3.543298 | EPOCH = [1/3] | TIME ELAPSED =85.34Mins\n",
            "ITERATION:[298/1209] | LOSS: 3.253955 | EPOCH = [1/3] | TIME ELAPSED =85.59Mins\n",
            "ITERATION:[299/1209] | LOSS: 3.025484 | EPOCH = [1/3] | TIME ELAPSED =85.87Mins\n",
            "OPTIMIZER = 0.007786880000000001 Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.007786880000000001\n",
            "    weight_decay: 0\n",
            ")\n",
            "ITERATION:[300/1209] | LOSS: 3.760256 | EPOCH = [1/3] | TIME ELAPSED =86.22Mins\n",
            "ITERATION:[301/1209] | LOSS: 3.526984 | EPOCH = [1/3] | TIME ELAPSED =86.5Mins\n",
            "ITERATION:[302/1209] | LOSS: 3.50084 | EPOCH = [1/3] | TIME ELAPSED =86.79Mins\n",
            "ITERATION:[303/1209] | LOSS: 3.608457 | EPOCH = [1/3] | TIME ELAPSED =87.08Mins\n",
            "ITERATION:[304/1209] | LOSS: 3.662476 | EPOCH = [1/3] | TIME ELAPSED =87.39Mins\n",
            "ITERATION:[305/1209] | LOSS: 3.429985 | EPOCH = [1/3] | TIME ELAPSED =87.66Mins\n",
            "ITERATION:[306/1209] | LOSS: 3.355566 | EPOCH = [1/3] | TIME ELAPSED =87.93Mins\n",
            "ITERATION:[307/1209] | LOSS: 3.463712 | EPOCH = [1/3] | TIME ELAPSED =88.2Mins\n",
            "ITERATION:[308/1209] | LOSS: 3.527542 | EPOCH = [1/3] | TIME ELAPSED =88.48Mins\n",
            "ITERATION:[309/1209] | LOSS: 3.378635 | EPOCH = [1/3] | TIME ELAPSED =88.8Mins\n",
            "ITERATION:[310/1209] | LOSS: 3.449951 | EPOCH = [1/3] | TIME ELAPSED =89.12Mins\n",
            "ITERATION:[311/1209] | LOSS: 3.589549 | EPOCH = [1/3] | TIME ELAPSED =89.39Mins\n",
            "ITERATION:[312/1209] | LOSS: 3.447478 | EPOCH = [1/3] | TIME ELAPSED =89.68Mins\n",
            "ITERATION:[313/1209] | LOSS: 3.375318 | EPOCH = [1/3] | TIME ELAPSED =89.97Mins\n",
            "ITERATION:[314/1209] | LOSS: 3.35982 | EPOCH = [1/3] | TIME ELAPSED =90.25Mins\n",
            "ITERATION:[315/1209] | LOSS: 3.747768 | EPOCH = [1/3] | TIME ELAPSED =90.51Mins\n",
            "ITERATION:[316/1209] | LOSS: 3.28321 | EPOCH = [1/3] | TIME ELAPSED =90.82Mins\n",
            "ITERATION:[317/1209] | LOSS: 3.52694 | EPOCH = [1/3] | TIME ELAPSED =91.1Mins\n",
            "ITERATION:[318/1209] | LOSS: 3.5135 | EPOCH = [1/3] | TIME ELAPSED =91.37Mins\n",
            "ITERATION:[319/1209] | LOSS: 3.367429 | EPOCH = [1/3] | TIME ELAPSED =91.65Mins\n",
            "ITERATION:[320/1209] | LOSS: 3.322956 | EPOCH = [1/3] | TIME ELAPSED =91.96Mins\n",
            "ITERATION:[321/1209] | LOSS: 3.366433 | EPOCH = [1/3] | TIME ELAPSED =92.24Mins\n",
            "ITERATION:[322/1209] | LOSS: 3.677289 | EPOCH = [1/3] | TIME ELAPSED =92.54Mins\n",
            "ITERATION:[323/1209] | LOSS: 3.643566 | EPOCH = [1/3] | TIME ELAPSED =92.83Mins\n",
            "ITERATION:[324/1209] | LOSS: 3.565216 | EPOCH = [1/3] | TIME ELAPSED =93.11Mins\n",
            "ITERATION:[325/1209] | LOSS: 3.573358 | EPOCH = [1/3] | TIME ELAPSED =93.38Mins\n",
            "ITERATION:[326/1209] | LOSS: 3.370728 | EPOCH = [1/3] | TIME ELAPSED =93.67Mins\n",
            "ITERATION:[327/1209] | LOSS: 3.49046 | EPOCH = [1/3] | TIME ELAPSED =93.95Mins\n",
            "ITERATION:[328/1209] | LOSS: 3.45462 | EPOCH = [1/3] | TIME ELAPSED =94.22Mins\n",
            "ITERATION:[329/1209] | LOSS: 3.56427 | EPOCH = [1/3] | TIME ELAPSED =94.49Mins\n",
            "ITERATION:[330/1209] | LOSS: 3.460914 | EPOCH = [1/3] | TIME ELAPSED =94.81Mins\n",
            "ITERATION:[331/1209] | LOSS: 3.46162 | EPOCH = [1/3] | TIME ELAPSED =95.09Mins\n",
            "ITERATION:[332/1209] | LOSS: 3.510881 | EPOCH = [1/3] | TIME ELAPSED =95.36Mins\n",
            "ITERATION:[333/1209] | LOSS: 3.39117 | EPOCH = [1/3] | TIME ELAPSED =95.63Mins\n",
            "ITERATION:[334/1209] | LOSS: 3.413222 | EPOCH = [1/3] | TIME ELAPSED =95.91Mins\n",
            "ITERATION:[335/1209] | LOSS: 3.634449 | EPOCH = [1/3] | TIME ELAPSED =96.2Mins\n",
            "ITERATION:[336/1209] | LOSS: 3.262939 | EPOCH = [1/3] | TIME ELAPSED =96.5Mins\n",
            "ITERATION:[337/1209] | LOSS: 3.403647 | EPOCH = [1/3] | TIME ELAPSED =96.78Mins\n",
            "ITERATION:[338/1209] | LOSS: 3.420757 | EPOCH = [1/3] | TIME ELAPSED =97.06Mins\n",
            "ITERATION:[339/1209] | LOSS: 3.72042 | EPOCH = [1/3] | TIME ELAPSED =97.35Mins\n",
            "ITERATION:[340/1209] | LOSS: 3.337677 | EPOCH = [1/3] | TIME ELAPSED =97.68Mins\n",
            "ITERATION:[341/1209] | LOSS: 3.360468 | EPOCH = [1/3] | TIME ELAPSED =98.04Mins\n",
            "ITERATION:[342/1209] | LOSS: 3.632401 | EPOCH = [1/3] | TIME ELAPSED =98.32Mins\n",
            "ITERATION:[343/1209] | LOSS: 3.469935 | EPOCH = [1/3] | TIME ELAPSED =98.65Mins\n",
            "ITERATION:[344/1209] | LOSS: 3.91985 | EPOCH = [1/3] | TIME ELAPSED =98.93Mins\n",
            "ITERATION:[345/1209] | LOSS: 3.476622 | EPOCH = [1/3] | TIME ELAPSED =99.2Mins\n",
            "ITERATION:[346/1209] | LOSS: 3.36433 | EPOCH = [1/3] | TIME ELAPSED =99.48Mins\n",
            "ITERATION:[347/1209] | LOSS: 3.850542 | EPOCH = [1/3] | TIME ELAPSED =99.78Mins\n",
            "ITERATION:[348/1209] | LOSS: 3.359385 | EPOCH = [1/3] | TIME ELAPSED =100.06Mins\n",
            "ITERATION:[349/1209] | LOSS: 3.366891 | EPOCH = [1/3] | TIME ELAPSED =100.34Mins\n",
            "ITERATION:[350/1209] | LOSS: 3.262189 | EPOCH = [1/3] | TIME ELAPSED =100.66Mins\n",
            "ITERATION:[351/1209] | LOSS: 3.598339 | EPOCH = [1/3] | TIME ELAPSED =100.94Mins\n",
            "ITERATION:[352/1209] | LOSS: 3.453394 | EPOCH = [1/3] | TIME ELAPSED =101.22Mins\n",
            "ITERATION:[353/1209] | LOSS: 3.515903 | EPOCH = [1/3] | TIME ELAPSED =101.5Mins\n",
            "ITERATION:[354/1209] | LOSS: 3.283988 | EPOCH = [1/3] | TIME ELAPSED =101.76Mins\n",
            "ITERATION:[355/1209] | LOSS: 3.327086 | EPOCH = [1/3] | TIME ELAPSED =102.14Mins\n",
            "ITERATION:[356/1209] | LOSS: 3.545189 | EPOCH = [1/3] | TIME ELAPSED =102.43Mins\n",
            "ITERATION:[357/1209] | LOSS: 3.460269 | EPOCH = [1/3] | TIME ELAPSED =102.75Mins\n",
            "ITERATION:[358/1209] | LOSS: 3.548371 | EPOCH = [1/3] | TIME ELAPSED =103.02Mins\n",
            "ITERATION:[359/1209] | LOSS: 3.56722 | EPOCH = [1/3] | TIME ELAPSED =103.31Mins\n",
            "ITERATION:[360/1209] | LOSS: 3.637637 | EPOCH = [1/3] | TIME ELAPSED =103.63Mins\n",
            "ITERATION:[361/1209] | LOSS: 3.453258 | EPOCH = [1/3] | TIME ELAPSED =103.94Mins\n",
            "ITERATION:[362/1209] | LOSS: 3.367045 | EPOCH = [1/3] | TIME ELAPSED =104.21Mins\n",
            "ITERATION:[363/1209] | LOSS: 3.299175 | EPOCH = [1/3] | TIME ELAPSED =104.48Mins\n",
            "ITERATION:[364/1209] | LOSS: 3.394133 | EPOCH = [1/3] | TIME ELAPSED =104.75Mins\n",
            "ITERATION:[365/1209] | LOSS: 3.432527 | EPOCH = [1/3] | TIME ELAPSED =105.03Mins\n",
            "ITERATION:[366/1209] | LOSS: 3.577022 | EPOCH = [1/3] | TIME ELAPSED =105.3Mins\n",
            "ITERATION:[367/1209] | LOSS: 3.296945 | EPOCH = [1/3] | TIME ELAPSED =105.59Mins\n",
            "ITERATION:[368/1209] | LOSS: 3.346794 | EPOCH = [1/3] | TIME ELAPSED =105.88Mins\n",
            "ITERATION:[369/1209] | LOSS: 3.367437 | EPOCH = [1/3] | TIME ELAPSED =106.17Mins\n",
            "ITERATION:[370/1209] | LOSS: 3.453681 | EPOCH = [1/3] | TIME ELAPSED =106.47Mins\n",
            "ITERATION:[371/1209] | LOSS: 3.488271 | EPOCH = [1/3] | TIME ELAPSED =106.76Mins\n",
            "ITERATION:[372/1209] | LOSS: 3.410947 | EPOCH = [1/3] | TIME ELAPSED =107.04Mins\n",
            "ITERATION:[373/1209] | LOSS: 3.24992 | EPOCH = [1/3] | TIME ELAPSED =107.32Mins\n",
            "ITERATION:[374/1209] | LOSS: 3.496331 | EPOCH = [1/3] | TIME ELAPSED =107.59Mins\n",
            "ITERATION:[375/1209] | LOSS: 3.590176 | EPOCH = [1/3] | TIME ELAPSED =107.88Mins\n",
            "ITERATION:[376/1209] | LOSS: 3.157946 | EPOCH = [1/3] | TIME ELAPSED =108.17Mins\n",
            "ITERATION:[377/1209] | LOSS: 3.222159 | EPOCH = [1/3] | TIME ELAPSED =108.5Mins\n",
            "ITERATION:[378/1209] | LOSS: 3.422548 | EPOCH = [1/3] | TIME ELAPSED =108.81Mins\n",
            "ITERATION:[379/1209] | LOSS: 3.433113 | EPOCH = [1/3] | TIME ELAPSED =109.12Mins\n",
            "ITERATION:[380/1209] | LOSS: 3.329736 | EPOCH = [1/3] | TIME ELAPSED =109.43Mins\n",
            "ITERATION:[381/1209] | LOSS: 3.350405 | EPOCH = [1/3] | TIME ELAPSED =109.7Mins\n",
            "ITERATION:[382/1209] | LOSS: 3.685023 | EPOCH = [1/3] | TIME ELAPSED =109.98Mins\n",
            "ITERATION:[383/1209] | LOSS: 3.368688 | EPOCH = [1/3] | TIME ELAPSED =110.26Mins\n",
            "ITERATION:[384/1209] | LOSS: 3.336239 | EPOCH = [1/3] | TIME ELAPSED =110.58Mins\n",
            "ITERATION:[385/1209] | LOSS: 3.386127 | EPOCH = [1/3] | TIME ELAPSED =110.86Mins\n",
            "ITERATION:[386/1209] | LOSS: 3.484621 | EPOCH = [1/3] | TIME ELAPSED =111.14Mins\n",
            "ITERATION:[387/1209] | LOSS: 3.429895 | EPOCH = [1/3] | TIME ELAPSED =111.42Mins\n",
            "ITERATION:[388/1209] | LOSS: 3.555953 | EPOCH = [1/3] | TIME ELAPSED =111.71Mins\n",
            "ITERATION:[389/1209] | LOSS: 3.522468 | EPOCH = [1/3] | TIME ELAPSED =112.0Mins\n",
            "ITERATION:[390/1209] | LOSS: 3.359965 | EPOCH = [1/3] | TIME ELAPSED =112.33Mins\n",
            "ITERATION:[391/1209] | LOSS: 3.397115 | EPOCH = [1/3] | TIME ELAPSED =112.61Mins\n",
            "ITERATION:[392/1209] | LOSS: 3.592928 | EPOCH = [1/3] | TIME ELAPSED =112.9Mins\n",
            "ITERATION:[393/1209] | LOSS: 3.13912 | EPOCH = [1/3] | TIME ELAPSED =113.18Mins\n",
            "ITERATION:[394/1209] | LOSS: 3.224951 | EPOCH = [1/3] | TIME ELAPSED =113.45Mins\n",
            "ITERATION:[395/1209] | LOSS: 3.387568 | EPOCH = [1/3] | TIME ELAPSED =113.75Mins\n",
            "ITERATION:[396/1209] | LOSS: 3.338719 | EPOCH = [1/3] | TIME ELAPSED =114.01Mins\n",
            "ITERATION:[397/1209] | LOSS: 3.116908 | EPOCH = [1/3] | TIME ELAPSED =114.36Mins\n",
            "ITERATION:[398/1209] | LOSS: 3.586548 | EPOCH = [1/3] | TIME ELAPSED =114.66Mins\n",
            "ITERATION:[399/1209] | LOSS: 3.275533 | EPOCH = [1/3] | TIME ELAPSED =114.97Mins\n",
            "OPTIMIZER = 0.007163929600000001 Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.007163929600000001\n",
            "    weight_decay: 0\n",
            ")\n",
            "ITERATION:[400/1209] | LOSS: 3.648816 | EPOCH = [1/3] | TIME ELAPSED =115.31Mins\n",
            "ITERATION:[401/1209] | LOSS: 3.484909 | EPOCH = [1/3] | TIME ELAPSED =115.6Mins\n",
            "ITERATION:[402/1209] | LOSS: 3.299165 | EPOCH = [1/3] | TIME ELAPSED =115.88Mins\n",
            "ITERATION:[403/1209] | LOSS: 3.41308 | EPOCH = [1/3] | TIME ELAPSED =116.17Mins\n",
            "ITERATION:[404/1209] | LOSS: 3.604834 | EPOCH = [1/3] | TIME ELAPSED =116.45Mins\n",
            "ITERATION:[405/1209] | LOSS: 3.569456 | EPOCH = [1/3] | TIME ELAPSED =116.74Mins\n",
            "ITERATION:[406/1209] | LOSS: 3.60678 | EPOCH = [1/3] | TIME ELAPSED =117.05Mins\n",
            "ITERATION:[407/1209] | LOSS: 3.240893 | EPOCH = [1/3] | TIME ELAPSED =117.38Mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8KQRfKHHblR",
        "colab_type": "text"
      },
      "source": [
        "### TEST MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEU_HGwJHblS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if phase == \"Test\":\n",
        "    with open('../dict/VOCAB.pkl', 'rb') as handle:\n",
        "        VOCAB = pickle.load(handle)\n",
        "    with open('../dict/WORD2IDX.pkl', 'rb') as handle:\n",
        "        WORD2IDX = pickle.load(handle)\n",
        "    with open('../dict/IDX2WORD.pkl', 'rb') as handle:\n",
        "        IDX2WORD = pickle.load(handle)\n",
        "    print(\"Dictionary Loaded Successfully\")\n",
        "\n",
        "        \n",
        "if platform == \"colab\":\n",
        "    IMAGE_DIR = '/content/drive/My Drive/public_test_images/'\n",
        "else:\n",
        "    IMAGE_DIR = 'D:/Padhai/IIT Delhi MS(R)/2019-20 Sem II/COL774 Machine Learning/Assignment/Assignment4/train_images/'\n",
        "if restore == True:\n",
        "    net = ImageCaptionsNet()\n",
        "    net = net.double()\n",
        "    #net = net.to(torch.device(\"cuda:0\"))\n",
        "    #net = nn.DataParallel(net)\n",
        "    state_dict = collections.OrderedDict()\n",
        "    state_dict = restore_checkpoint(\"Final_Model_multi_withAttn.pth\")\n",
        "    \n",
        "    net.load_state_dict(state_dict)\n",
        "    print(\"State Dictionary Loaded Successfully.\")\n",
        "\n",
        "    # load params\n",
        "    if device != 'cpu':\n",
        "        net = nn.DataParallel(net)\n",
        "        net = net.to(torch.device(\"cuda:0\"))\n",
        "\n",
        "\n",
        "# Creating the Dataset\n",
        "test_dataset = ImageCaptionsDataset(\n",
        "    IMAGE_DIR, captions_preprocessing_obj.captions_dict, img_transform=img_transform,\n",
        "    captions_transform=captions_preprocessing_obj.captions_transform)\n",
        "\n",
        "\n",
        "\n",
        "def beam_search(img_feature, max_words=15, beam_k=3):\n",
        "    \n",
        "    #init with start token \n",
        "    init_caption = []\n",
        "    init_caption = [[[WORD2IDX[\"<start>\"]], float(0)]]\n",
        "    \n",
        "    \n",
        "    #print(img_feature.shape)\n",
        "    #img_feature = img_feature.unsqueeze(dim=1)\n",
        "    while len(init_caption[0][0]) < max_words:\n",
        "        temp_cap = []\n",
        "        for c in init_caption:  \n",
        "            #print(c[0])\n",
        "            cap_pad = c[0] +  [0] * int(max_words - len(c[0]))\n",
        "            cap_pad = torch.LongTensor(cap_pad).unsqueeze(dim=0)\n",
        "            lstm_op = net.Decoder(img_feature, cap_pad)        \n",
        "            lstm_op = lstm_op.reshape(max_words, lstm_op.shape[2])\n",
        "        \n",
        "            #TOP k prob\n",
        "            #print(lstm_op.shape)\n",
        "            #print(torch.argmax(lstm_op[0], dim=0).tolist())\n",
        "            top_pred = torch.argmax(lstm_op, dim=1)\n",
        "            #top_pred = torch.argsort(top_pred)[-beam_k:]\n",
        "            print(top_pred)\n",
        "            for i in range(beam_k): \n",
        "                word_idx = top_pred[i]\n",
        "                prob = c[1] + lstm_op[0][word_idx]\n",
        "                cap = c[0][:] + [word_idx]\n",
        "                \n",
        "                temp_cap.append([cap, prob])\n",
        "                \n",
        "        init_caption = temp_cap\n",
        "        init_caption = sorted(init_caption, reverse=False, key=lambda x: x[1])[-beam_k:]\n",
        "    #print(type(init_caption[-1][0]))\n",
        "    temp_caption = list(map(lambda x: IDX2WORD[x], init_caption[-1][0]))\n",
        "    \n",
        "    pred_caption = list()\n",
        "    for w in temp_caption:\n",
        "        if w != '<end>':\n",
        "            pred_caption.append(w)\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    return pred_caption\n",
        "def argmax_search(img_feature, max_words=15):\n",
        "    start_word = [\"<start>\"]\n",
        "    while True:\n",
        "        par_caps = [WORD2IDX[i] for i in start_word]\n",
        "        par_caps = cap_pad = par_caps +  [0] * int(max_words - len(par_caps))\n",
        "        #print(par_caps)\n",
        "        cap_pad = torch.LongTensor(par_caps).unsqueeze(dim=0)\n",
        "        lstm_op = net.Decoder(img_feature, cap_pad) \n",
        "        #print(\"before\", lstm_op.shape)\n",
        "        lstm_op = lstm_op.reshape(max_words, lstm_op.shape[2])\n",
        "        #print(\"after\",lstm_op.shape)\n",
        "        max_pred = torch.argmax(lstm_op, dim=1).tolist()\n",
        "        max_pred = torch.max(lstm_op, dim=1).tolist()\n",
        "        print(max_pred)\n",
        "        word_pred = IDX2WORD[max_pred]\n",
        "        start_word.append(word_pred)\n",
        "        \n",
        "        if word_pred == \"<end>\" or len(start_word) > max_words:\n",
        "            break\n",
        "            \n",
        "    return ' '.join(start_word[1:-1])\n",
        "\n",
        "def caption_image(image_feature, max_words=20):\n",
        "        result_caption = []\n",
        "        cap_temp = torch.LongTensor([0]*max_words).unsqueeze(0)\n",
        "        x = image_feature\n",
        "        #print(cap_temp.shape)\n",
        "        with torch.no_grad():\n",
        "            for i in range(max_words):\n",
        "                #print(\"img, cap\",image_feature.shape,x.shape, cap_temp.shape)\n",
        "                    \n",
        "                output = net.Decoder(x, cap_temp)                    \n",
        "                \n",
        "                #print(\"output shape\", output.shape)\n",
        "                predicted = output.argmax(2)\n",
        "                image_feature = net.Decoder.embed(predicted)\n",
        "                image_feature = image_feature.squeeze(0)\n",
        "                predicted = predicted.tolist()\n",
        "                #print(\"predicted\", predicted)\n",
        "                result_caption = predicted[0]\n",
        "                cap_temp = result_caption + [0] * int(max_words - len(result_caption))\n",
        "                #print(cap_temp)\n",
        "                cap_temp = torch.LongTensor(cap_temp).unsqueeze(0)\n",
        "\n",
        "                if predicted == 3:\n",
        "                    break\n",
        "        caption = [IDX2WORD[i] for i in  result_caption]\n",
        "        return ' '.join(caption)\n",
        "        \n",
        "\n",
        "    \n",
        "\n",
        "# Define your hyperparameters\n",
        "NUMBER_OF_EPOCHS = 1\n",
        "LEARNING_RATE = 1e-1\n",
        "BATCH_SIZE = 2\n",
        "NUM_WORKERS = 0 # Parallel threads for dataloading\n",
        "MAX_WORDS = 30\n",
        "# Creating the DataLoader for batching purposes\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_wrapper)\n",
        "import os\n",
        "if device != \"cpu\":\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "t0 = time()\n",
        "pred_caps = {}\n",
        "for batch_idx, sample in enumerate(test_loader):\n",
        "        print(\"Image_idx\", batch_idx)\n",
        "        image_batch, captions_batch = sample['image'], sample['captions']\n",
        "        \n",
        "        print(\"Image_idx\", captions_batch)\n",
        "        img_features = net.Encoder(image_batch)\n",
        "        #print(x.shape)\n",
        "        #pred_cap = beam_search(img_features)\n",
        "        pred_cap = caption_image(img_features)\n",
        "        pred_caps[batch_idx] = pred_cap\n",
        "        print(batch_idx, pred_cap)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahdu7rc7CDYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}