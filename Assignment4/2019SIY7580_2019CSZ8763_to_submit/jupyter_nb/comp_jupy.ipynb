{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "B83XJ_ttBEFZ",
    "outputId": "593ec291-f6fd-471b-8889-7dc1dd72faa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "val9_dFDA5BC"
   },
   "outputs": [],
   "source": [
    "'''Import modules'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from collections import Counter\n",
    "from skimage import io, transform\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np\n",
    "from time import time\n",
    "import collections\n",
    "import pickle\n",
    "import os\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "DreNgskw-kTF",
    "outputId": "83132a89-fef4-4c02-edd7-58c0f97450b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "x6qEbzQNBMM-",
    "outputId": "3ac75912-6b77-432f-fda1-5b21be14c822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda\n",
      "Using 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device =\", device)\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#parallel = False #enable nn.DataParallel for GPU\n",
    "platform = \"colab\" #colab/local\n",
    "restore = False #Restore Checkpoint\n",
    "phase = \"Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Zf92eqfBN34"
   },
   "outputs": [],
   "source": [
    "VOCAB = {}\n",
    "WORD2IDX = {}\n",
    "IDX2WORD = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "oOKS9DIUfkor",
    "outputId": "3e98d3e0-471e-4e24-b274-81a47be486d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found 0\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "keys_found = 0\n",
    "not_found = []\n",
    "vocab_dump = VOCAB.copy()\n",
    "for k in VOCAB.keys():\n",
    "    if k in fasttext_model.vocab:\n",
    "        keys_found += 1\n",
    "        vocab_dump[k] = torch.FloatTensor(fasttext_model.wv.get_vector(k))\n",
    "    else:\n",
    "        vocab_dump[k] = torch.randn(300)\n",
    "        not_found.append(k)\n",
    "\n",
    "print(\"not found\", len(not_found))\n",
    "\n",
    "#with open('/content/drive/My Drive/A4/embeddings/trained_embed.pkl', 'wb') as handle:\n",
    "#  pickle.dump(vocab_dump, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLOoOXXGBO1x"
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        #print(\"TA RESCALE INPUT\", image.shape)\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        #print(\"TA RESCALE OUTPUT\", image.shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        #print(\"TA TRANSPOSE IP\", image.shape)\n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        #print(\"TA TRANSPOSE OP\", image.shape)\n",
    "        return image\n",
    "\n",
    "\n",
    "IMAGE_RESIZE = (256, 256)\n",
    "# Sequentially compose the transforms\n",
    "img_transform = transforms.Compose([Rescale(IMAGE_RESIZE), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "F3T42fc3BQpv",
    "outputId": "1f276bdf-cf4e-4579-8b89-641f7385c85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE = 8680\n"
     ]
    }
   ],
   "source": [
    "class CaptionsPreprocessing:\n",
    "    \"\"\"Preprocess the captions, generate vocabulary and convert words to tensor tokens\n",
    "    Args:\n",
    "        captions_file_path (string): captions tsv file path\n",
    "    \"\"\"\n",
    "    def __init__(self, captions_file_path):\n",
    "        self.captions_file_path = captions_file_path\n",
    "\n",
    "        # Read raw captions\n",
    "        self.raw_captions_dict = self.read_raw_captions()\n",
    "\n",
    "        # Preprocess captions\n",
    "        self.captions_dict = self.process_captions()\n",
    "\n",
    "        # Create vocabulary\n",
    "        self.start = \"<start>\"\n",
    "        self.end = \"<end>\"\n",
    "        self.oov = \"<unk>\"\n",
    "        self.pad = \"<pad>\"\n",
    "        self.vocab = self.generate_vocabulary()\n",
    "        self.word2index = self.convert_word2index()        \n",
    "        self.index2word = self.convert_index2word()\n",
    "        \n",
    "\n",
    "    def read_raw_captions(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            Dictionary with raw captions list keyed by image ids (integers)\n",
    "        \"\"\"\n",
    "        captions_dict = {}\n",
    "        with open(self.captions_file_path, 'r', encoding='utf-8') as f:\n",
    "            for img_caption_line in f.readlines():\n",
    "                img_captions = img_caption_line.strip().split('\\t')\n",
    "                captions_dict[int(img_captions[0])] = img_captions[1:]\n",
    "\n",
    "        return captions_dict \n",
    "\n",
    "    def process_captions(self):\n",
    "        \"\"\"\n",
    "        Use this function to generate dictionary and other preprocessing on captions\n",
    "        \"\"\"\n",
    "\n",
    "        raw_captions_dict = self.raw_captions_dict \n",
    "        \n",
    "        # Do the preprocessing here                \n",
    "        captions_dict = raw_captions_dict\n",
    "\n",
    "        return captions_dict\n",
    "\n",
    " \n",
    "\n",
    "    def generate_vocabulary(self):\n",
    "        \"\"\"\n",
    "        Use this function to generate dictionary and other preprocessing on captions\n",
    "        \"\"\"\n",
    "        captions_dict = self.captions_dict\n",
    "\n",
    "        # Generate the vocabulary\n",
    "        \n",
    "        all_captions = \"\"        \n",
    "        for cap_lists in captions_dict.values():\n",
    "            all_captions += \" \".join(cap_lists)\n",
    "        all_captions = nltk.tokenize.word_tokenize(all_captions.lower())\n",
    "        \n",
    "        vocab = {self.pad :1, self.oov :1, self.start :1, self.end :1}\n",
    "        vocab_update = Counter(all_captions) \n",
    "        vocab_update = {k:v for k,v in vocab_update.items() if v >= freq_threshold}\n",
    "        vocab.update(vocab_update)        \n",
    "        vocab_size = len(vocab)\n",
    "        \n",
    "        if phase == \"Train\":\n",
    "            VOCAB.clear()\n",
    "            VOCAB.update(vocab)\n",
    "            if platform == \"colab\":\n",
    "                fname = '/content/drive/My Drive/A4/dict/VOCAB_comp.pkl'\n",
    "            else:\n",
    "                fname = '../dict/VOCAB_comp.pkl'\n",
    "            #if not os.path.isfile(fname):\n",
    "            with open(fname, 'wb') as handle:\n",
    "                pickle.dump(vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        print(\"VOCAB SIZE =\", vocab_size)\n",
    "        return vocab\n",
    "    \n",
    "    def convert_word2index(self):\n",
    "        \"\"\"\n",
    "        word to index converter\n",
    "        \"\"\"\n",
    "        word2index = {}\n",
    "        vocab = self.vocab\n",
    "        idx = 0\n",
    "        words = vocab.keys()\n",
    "        for w in words:\n",
    "            word2index[w] = idx\n",
    "            idx +=1\n",
    "        if phase == \"Train\":\n",
    "            WORD2IDX.clear()\n",
    "            WORD2IDX.update(word2index)\n",
    "            if platform == \"colab\":\n",
    "                fname = '/content/drive/My Drive/A4/dict/WORD2IDX_comp.pkl'\n",
    "            else:\n",
    "                fname = '../dict/WORD2IDX_comp.pkl'\n",
    "            #if not os.path.isfile(fname):\n",
    "            with open(fname, 'wb') as handle:\n",
    "                pickle.dump(word2index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        return word2index\n",
    "    \n",
    "    def convert_index2word(self):\n",
    "        \"\"\"\n",
    "        index to word converter\n",
    "        \"\"\"\n",
    "        index2word = {}\n",
    "        w2i = self.word2index\n",
    "        idx = 0\n",
    "        \n",
    "        for k, v in w2i.items():\n",
    "            index2word[v] = k\n",
    "            \n",
    "        if phase == \"Train\":\n",
    "            IDX2WORD.clear()\n",
    "            IDX2WORD.update(index2word)\n",
    "            if platform == \"colab\":\n",
    "                fname = '/content/drive/My Drive/A4/dict/IDX2WORD_comp.pkl'\n",
    "            else:\n",
    "                fname = '../dict/IDX2WORD_comp.pkl'\n",
    "            #if not os.path.isfile(fname):\n",
    "            with open(fname, 'wb') as handle:\n",
    "                pickle.dump(index2word, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        return index2word\n",
    "\n",
    "    def captions_transform(self, img_caption_list):\n",
    "        \"\"\"\n",
    "        Use this function to generate tensor tokens for the text captions\n",
    "        Args:\n",
    "            img_caption_list: List of captions for a particular image\n",
    "        \"\"\"\n",
    "        if phase == \"Test\":\n",
    "            word2index = WORD2IDX\n",
    "            vocab = VOCAB\n",
    "        else:\n",
    "            word2index = self.word2index\n",
    "            vocab = self.vocab\n",
    "            \n",
    "        start = self.start\n",
    "        end = self.end\n",
    "        oov = self.oov\n",
    "        \n",
    "        processed_list = list(map(lambda x: nltk.tokenize.word_tokenize(x.lower()), img_caption_list))\n",
    "        \n",
    "        \n",
    "        #print(processed_list)\n",
    "        processed_list = list(map(lambda x: list(map(lambda y: WORD2IDX[y] if y in vocab else WORD2IDX[oov],x)),\n",
    "                                  processed_list))\n",
    "        processed_list = list(map(lambda x: [WORD2IDX['<start>']] + x + [WORD2IDX['<end>']], processed_list))\n",
    "        #print(processed_list)\n",
    "        return processed_list\n",
    "\n",
    "\n",
    "if platform == \"colab\":\n",
    "    CAPTIONS_FILE_PATH = '/content/drive/My Drive/A4/train_captions.tsv'\n",
    "else:\n",
    "    CAPTIONS_FILE_PATH = \"D:/Padhai/IIT Delhi MS(R)/2019-20 Sem II/COL774 Machine Learning/Assignment/Assignment4/train_captions.tsv\"\n",
    "    \n",
    "embedding_dim = 200\n",
    "freq_threshold = 5\n",
    "captions_preprocessing_obj = CaptionsPreprocessing(CAPTIONS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ddnzTeRBUFd"
   },
   "outputs": [],
   "source": [
    "class ImageCaptionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, captions_dict, img_transform=None, captions_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Directory with all the images.\n",
    "            captions_dict: Dictionary with captions list keyed by image ids (integers)\n",
    "            img_transform (callable, optional): Optional transform to be applied\n",
    "                on the image sample.\n",
    "\n",
    "            captions_transform: (callable, optional): Optional transform to be applied\n",
    "                on the caption sample (list).\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.captions_dict = captions_dict\n",
    "        self.img_transform = img_transform\n",
    "        self.captions_transform = captions_transform\n",
    "\n",
    "        self.image_ids = list(captions_dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, 'image_{}.jpg'.format(self.image_ids[idx]))\n",
    "        image = io.imread(img_name)\n",
    "        #print(\"RAW IMG\", image.shape)\n",
    "        captions = self.captions_dict[self.image_ids[idx]]\n",
    "        if self.img_transform:\n",
    "            image = self.img_transform(image)\n",
    "            #print(\"AFTER img_transform\", image.shape)\n",
    "            image = image.transpose((2, 0, 1))\n",
    "            \n",
    "\n",
    "        if self.captions_transform:            \n",
    "            captions = self.captions_transform(captions)\n",
    "            \n",
    "        sample = {'image': image, 'captions': captions}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "def custom_batch(batch):\n",
    "    batch_size = len(batch)\n",
    "    captions = []\n",
    "    normalize_img = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    x = list(map(lambda b: captions.extend(b['captions']),batch))    \n",
    "    x = list(map(lambda b: b['image'],batch)) \n",
    "    x = list(map(lambda i: normalize_img(torch.from_numpy(i)).unsqueeze(0),x))\n",
    "    #print(\"my after norm shape\", x[0].shape)\n",
    "    captions = list(map(lambda c: torch.LongTensor(c),captions))\n",
    "    lengths = list(map(lambda c: len(c),captions))\n",
    "    captions = pad_sequence(captions, batch_first=True)\n",
    "    images = torch.cat(x)\n",
    "    \n",
    "    sample = {'image': images, 'captions': captions, \"lengths\": lengths}    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cP-sf163BZEX"
   },
   "outputs": [],
   "source": [
    "#ENCODER\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        resnet50 = models.resnet50(pretrained=True, progress=True)        \n",
    "        self.resnet50 = resnet50\n",
    "        for param in self.resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"EMBED DIM\", embed_dim)\n",
    "        self.fc = nn.Linear(in_features=self.resnet50.fc.in_features, out_features=embed_dim, bias = True)\n",
    "        layers = list(resnet50.children())[:-1]\n",
    "        self.resnet50 = nn.Sequential(*layers)\n",
    "        '''for layer in list(self.resnet50.children())[2:]:\n",
    "            for params in layer.parameters():\n",
    "                params.requires_grad = True'''\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        print(\"resnet50 Loaded Successfully..!\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet50(x)\n",
    "        #print(\"Resnet module op\", x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        #print(\"Resnet module op reshape\", x.shape)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        #print(\"Resnet FC op\", x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, lstm_hidden_size,lstm_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.vocab_size = len(VOCAB)\n",
    "        print(\"VOCAB SIZE = \", self.vocab_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = lstm_hidden_size,\n",
    "                            num_layers = lstm_layers, batch_first = True)\n",
    "        #self.attention = AttentionBlock(embed_dim, lstm_hidden_size, self.vocab_size)\n",
    "        self.linear = nn.Linear(lstm_hidden_size, self.vocab_size)        \n",
    "        #self.embed = nn.Embedding.from_pretrained(init_weights)\n",
    "        self.embed = nn.Embedding(self.vocab_size, embed_dim)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, image_features, image_captions, lengths):\n",
    "        #print(\"DECODER INPUT\", image_features)\n",
    "        if phase == \"Train\":\n",
    "            #print(image)\n",
    "            image_features = torch.Tensor.repeat_interleave(image_features, repeats=5 , dim=0)\n",
    "        image_features = image_features.unsqueeze(1)\n",
    "        \n",
    "        \n",
    "        #Img (B,256,256) #(B*5, max len, embed dim)\n",
    "        embedded_captions = self.embed(image_captions)\n",
    "        print(\"EMBED SHAPE\", embedded_captions.shape)\n",
    "        print(\"SHAPES BEFORE CONCAT\",context.unsqueeze(dim=1).shape, embedded_captions[:,:-1].shape)\n",
    "        input_lstm = torch.cat((image_features, embedded_captions[:,:-1]), dim = 1)\n",
    "        #input_lstm = pack_padded_sequence(input_lstm, lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_outputs, _ = self.lstm(input_lstm)        \n",
    "        #lstm_outputs = self.linear(lstm_outputs[0]) \n",
    "        print(\"lstm_outputs.shape\", lstm_outputs.shape)\n",
    "        lstm_outputs = self.linear(lstm_outputs) \n",
    "        \n",
    "        return lstm_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "5atlpQpiBa_n",
    "outputId": "086bbe08-dac1-466b-ed31-32e8032dfe81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBED DIM 200\n",
      "resnet50 Loaded Successfully..!\n",
      "VOCAB SIZE =  8680\n",
      "Device to CUDA\n"
     ]
    }
   ],
   "source": [
    "class ImageCaptionsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageCaptionsNet, self).__init__()        \n",
    "        ##CNN ENCODER RESNET-50        \n",
    "        self.Encoder = Encoder(embed_dim = embedding_dim)\n",
    "        ## RNN DECODER\n",
    "        self.Decoder = Decoder(embedding_dim, units, 1)    \n",
    "        \n",
    "\n",
    "    def forward(self, img_batch, cap_batch, lengths):\n",
    "        #print(\"IMG INPUT\",x)\n",
    "        x = self.Encoder(img_batch)\n",
    "        #print(\"IMG FEATURE\",x)\n",
    "        x = self.Decoder(x, cap_batch, lengths)\n",
    "        #print(\"IMG FEATURE\",x)\n",
    "        return x\n",
    "    \n",
    "units = 512\n",
    "if restore == False:\n",
    "    net = ImageCaptionsNet()\n",
    "    net = net.double()\n",
    "    \n",
    "'''    if parallel == True and device != \"cpu\":\n",
    "        print(\"Parallel Processing enabled\")\n",
    "        net = nn.DataParallel(net)'''\n",
    "\n",
    "if device == \"cpu\":\n",
    "    print(\"Device to CPU\")\n",
    "else:\n",
    "    print(\"Device to CUDA\")\n",
    "    net = net.to(torch.device(\"cuda:0\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "za24CpL-Bc2_"
   },
   "outputs": [],
   "source": [
    "'''Save and Restore Checkpoints'''\n",
    "def create_checkpoint(path,model, optim_obj, loss_obj,iteration, epoch):\n",
    "    checkpoint = {'epoch': epoch,\n",
    "                  'iteration': iteration,\n",
    "                  'model_state_dict': model.state_dict()}\n",
    "\n",
    "    if platform == \"colab\":\n",
    "        directory = '/content/drive/My Drive/A4/bkp_final_try/'\n",
    "    else:\n",
    "        directory = '../bkp_final_try/'\n",
    "\n",
    "    torch.save(checkpoint, directory + path)\n",
    "    \n",
    "def restore_checkpoint(path):\n",
    "    new_state_dict = collections.OrderedDict()\n",
    "    if platform == \"colab\":\n",
    "        directory = '/content/drive/My Drive/A4/bkp_final_try/'\n",
    "        checkpoint = torch.load(directory + path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        directory = '../bkp_final_try/'\n",
    "        checkpoint = torch.load(directory + path, map_location=torch.device('cpu'))    \n",
    "    \n",
    "    epoch = checkpoint['epoch']\n",
    "    new_state_dict = checkpoint['model_state_dict']\n",
    "    iteration = checkpoint['iteration']\n",
    "    #optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
    "    #loss_obj = checkpoint['loss']\n",
    "    print(\"Iterations = {}, Epoch = {}\".format(iteration, epoch))\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkfskWPHhtAi"
   },
   "source": [
    "### TRAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RA1o2PSgBfKF",
    "outputId": "12d256f4-bf2e-4c50-877d-78aec1244292",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL PARAMS: 31568944, TOTAL TRAINABLE PARAMS NET: 8060912, TOTAL ADAM PARAMS: 8060912\n",
      "TOTAL EPOCHS: 3, BATCH SIZE: 64, OPTIMIZER: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "$$$$$----EPOCH 1----$$$$$$\n",
      "ITERATION:[1/454] | LOSS: 9.070918 | EPOCH = [1/3] | TIME ELAPSED =0.47Mins\n",
      "ITERATION:[2/454] | LOSS: 9.066564 | EPOCH = [1/3] | TIME ELAPSED =0.84Mins\n",
      "ITERATION:[3/454] | LOSS: 9.062153 | EPOCH = [1/3] | TIME ELAPSED =1.27Mins\n",
      "ITERATION:[4/454] | LOSS: 9.057034 | EPOCH = [1/3] | TIME ELAPSED =1.67Mins\n",
      "ITERATION:[5/454] | LOSS: 9.05347 | EPOCH = [1/3] | TIME ELAPSED =2.06Mins\n",
      "ITERATION:[6/454] | LOSS: 9.046896 | EPOCH = [1/3] | TIME ELAPSED =2.48Mins\n",
      "ITERATION:[7/454] | LOSS: 9.042988 | EPOCH = [1/3] | TIME ELAPSED =2.95Mins\n",
      "ITERATION:[8/454] | LOSS: 9.036194 | EPOCH = [1/3] | TIME ELAPSED =3.37Mins\n",
      "ITERATION:[9/454] | LOSS: 9.032488 | EPOCH = [1/3] | TIME ELAPSED =3.77Mins\n",
      "ITERATION:[10/454] | LOSS: 9.028835 | EPOCH = [1/3] | TIME ELAPSED =4.23Mins\n",
      "ITERATION:[11/454] | LOSS: 9.024654 | EPOCH = [1/3] | TIME ELAPSED =4.61Mins\n",
      "ITERATION:[12/454] | LOSS: 9.01845 | EPOCH = [1/3] | TIME ELAPSED =4.94Mins\n",
      "ITERATION:[13/454] | LOSS: 9.01264 | EPOCH = [1/3] | TIME ELAPSED =5.27Mins\n",
      "ITERATION:[14/454] | LOSS: 9.007517 | EPOCH = [1/3] | TIME ELAPSED =5.67Mins\n",
      "ITERATION:[15/454] | LOSS: 9.002521 | EPOCH = [1/3] | TIME ELAPSED =6.1Mins\n",
      "ITERATION:[16/454] | LOSS: 8.995541 | EPOCH = [1/3] | TIME ELAPSED =6.53Mins\n",
      "ITERATION:[17/454] | LOSS: 8.98887 | EPOCH = [1/3] | TIME ELAPSED =7.02Mins\n",
      "ITERATION:[18/454] | LOSS: 8.986955 | EPOCH = [1/3] | TIME ELAPSED =7.35Mins\n",
      "ITERATION:[19/454] | LOSS: 8.980686 | EPOCH = [1/3] | TIME ELAPSED =7.71Mins\n",
      "ITERATION:[20/454] | LOSS: 8.975789 | EPOCH = [1/3] | TIME ELAPSED =8.15Mins\n",
      "ITERATION:[21/454] | LOSS: 8.972016 | EPOCH = [1/3] | TIME ELAPSED =8.52Mins\n",
      "ITERATION:[22/454] | LOSS: 8.963856 | EPOCH = [1/3] | TIME ELAPSED =8.94Mins\n",
      "ITERATION:[23/454] | LOSS: 8.954611 | EPOCH = [1/3] | TIME ELAPSED =9.34Mins\n",
      "ITERATION:[24/454] | LOSS: 8.95419 | EPOCH = [1/3] | TIME ELAPSED =9.77Mins\n",
      "\n",
      "LEARNING RATE = 9.4e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 9.4e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[25/454] | LOSS: 8.942619 | EPOCH = [1/3] | TIME ELAPSED =10.24Mins\n",
      "ITERATION:[26/454] | LOSS: 8.934547 | EPOCH = [1/3] | TIME ELAPSED =10.63Mins\n",
      "ITERATION:[27/454] | LOSS: 8.923732 | EPOCH = [1/3] | TIME ELAPSED =11.08Mins\n",
      "ITERATION:[28/454] | LOSS: 8.923707 | EPOCH = [1/3] | TIME ELAPSED =11.43Mins\n",
      "ITERATION:[29/454] | LOSS: 8.913623 | EPOCH = [1/3] | TIME ELAPSED =11.79Mins\n",
      "ITERATION:[30/454] | LOSS: 8.902476 | EPOCH = [1/3] | TIME ELAPSED =12.18Mins\n",
      "ITERATION:[31/454] | LOSS: 8.904427 | EPOCH = [1/3] | TIME ELAPSED =12.62Mins\n",
      "ITERATION:[32/454] | LOSS: 8.887545 | EPOCH = [1/3] | TIME ELAPSED =13.01Mins\n",
      "ITERATION:[33/454] | LOSS: 8.889669 | EPOCH = [1/3] | TIME ELAPSED =13.41Mins\n",
      "ITERATION:[34/454] | LOSS: 8.879949 | EPOCH = [1/3] | TIME ELAPSED =13.79Mins\n",
      "ITERATION:[35/454] | LOSS: 8.867713 | EPOCH = [1/3] | TIME ELAPSED =14.17Mins\n",
      "ITERATION:[36/454] | LOSS: 8.861874 | EPOCH = [1/3] | TIME ELAPSED =14.63Mins\n",
      "ITERATION:[37/454] | LOSS: 8.836115 | EPOCH = [1/3] | TIME ELAPSED =15.13Mins\n",
      "ITERATION:[38/454] | LOSS: 8.834302 | EPOCH = [1/3] | TIME ELAPSED =15.53Mins\n",
      "ITERATION:[39/454] | LOSS: 8.839113 | EPOCH = [1/3] | TIME ELAPSED =15.93Mins\n",
      "ITERATION:[40/454] | LOSS: 8.831347 | EPOCH = [1/3] | TIME ELAPSED =16.32Mins\n",
      "ITERATION:[41/454] | LOSS: 8.816397 | EPOCH = [1/3] | TIME ELAPSED =16.76Mins\n",
      "ITERATION:[42/454] | LOSS: 8.792886 | EPOCH = [1/3] | TIME ELAPSED =17.11Mins\n",
      "ITERATION:[43/454] | LOSS: 8.785048 | EPOCH = [1/3] | TIME ELAPSED =17.5Mins\n",
      "ITERATION:[44/454] | LOSS: 8.765643 | EPOCH = [1/3] | TIME ELAPSED =17.94Mins\n",
      "ITERATION:[45/454] | LOSS: 8.762918 | EPOCH = [1/3] | TIME ELAPSED =18.32Mins\n",
      "ITERATION:[46/454] | LOSS: 8.762964 | EPOCH = [1/3] | TIME ELAPSED =18.72Mins\n",
      "ITERATION:[47/454] | LOSS: 8.726407 | EPOCH = [1/3] | TIME ELAPSED =19.09Mins\n",
      "ITERATION:[48/454] | LOSS: 8.71966 | EPOCH = [1/3] | TIME ELAPSED =19.44Mins\n",
      "ITERATION:[49/454] | LOSS: 8.723749 | EPOCH = [1/3] | TIME ELAPSED =19.9Mins\n",
      "\n",
      "LEARNING RATE = 8.835999999999999e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 8.835999999999999e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[50/454] | LOSS: 8.708793 | EPOCH = [1/3] | TIME ELAPSED =20.34Mins\n",
      "ITERATION:[51/454] | LOSS: 8.674289 | EPOCH = [1/3] | TIME ELAPSED =20.79Mins\n",
      "ITERATION:[52/454] | LOSS: 8.672861 | EPOCH = [1/3] | TIME ELAPSED =21.23Mins\n",
      "ITERATION:[53/454] | LOSS: 8.650103 | EPOCH = [1/3] | TIME ELAPSED =21.58Mins\n",
      "ITERATION:[54/454] | LOSS: 8.661431 | EPOCH = [1/3] | TIME ELAPSED =22.05Mins\n",
      "ITERATION:[55/454] | LOSS: 8.621571 | EPOCH = [1/3] | TIME ELAPSED =22.41Mins\n",
      "ITERATION:[56/454] | LOSS: 8.618396 | EPOCH = [1/3] | TIME ELAPSED =22.84Mins\n",
      "ITERATION:[57/454] | LOSS: 8.585242 | EPOCH = [1/3] | TIME ELAPSED =23.38Mins\n",
      "ITERATION:[58/454] | LOSS: 8.570382 | EPOCH = [1/3] | TIME ELAPSED =23.81Mins\n",
      "ITERATION:[59/454] | LOSS: 8.556058 | EPOCH = [1/3] | TIME ELAPSED =24.19Mins\n",
      "ITERATION:[60/454] | LOSS: 8.543781 | EPOCH = [1/3] | TIME ELAPSED =24.54Mins\n",
      "ITERATION:[61/454] | LOSS: 8.535792 | EPOCH = [1/3] | TIME ELAPSED =24.91Mins\n",
      "ITERATION:[62/454] | LOSS: 8.521656 | EPOCH = [1/3] | TIME ELAPSED =25.36Mins\n",
      "ITERATION:[63/454] | LOSS: 8.486713 | EPOCH = [1/3] | TIME ELAPSED =25.73Mins\n",
      "ITERATION:[64/454] | LOSS: 8.449385 | EPOCH = [1/3] | TIME ELAPSED =26.11Mins\n",
      "ITERATION:[65/454] | LOSS: 8.442181 | EPOCH = [1/3] | TIME ELAPSED =26.51Mins\n",
      "ITERATION:[66/454] | LOSS: 8.411937 | EPOCH = [1/3] | TIME ELAPSED =26.93Mins\n",
      "ITERATION:[67/454] | LOSS: 8.409612 | EPOCH = [1/3] | TIME ELAPSED =27.33Mins\n",
      "ITERATION:[68/454] | LOSS: 8.360837 | EPOCH = [1/3] | TIME ELAPSED =27.77Mins\n",
      "ITERATION:[69/454] | LOSS: 8.338739 | EPOCH = [1/3] | TIME ELAPSED =28.15Mins\n",
      "ITERATION:[70/454] | LOSS: 8.341262 | EPOCH = [1/3] | TIME ELAPSED =28.63Mins\n",
      "ITERATION:[71/454] | LOSS: 8.288389 | EPOCH = [1/3] | TIME ELAPSED =29.1Mins\n",
      "ITERATION:[72/454] | LOSS: 8.259397 | EPOCH = [1/3] | TIME ELAPSED =29.52Mins\n",
      "ITERATION:[73/454] | LOSS: 8.2473 | EPOCH = [1/3] | TIME ELAPSED =29.85Mins\n",
      "ITERATION:[74/454] | LOSS: 8.249135 | EPOCH = [1/3] | TIME ELAPSED =30.3Mins\n",
      "\n",
      "LEARNING RATE = 8.305839999999998e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 8.305839999999998e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[75/454] | LOSS: 8.173081 | EPOCH = [1/3] | TIME ELAPSED =30.72Mins\n",
      "ITERATION:[76/454] | LOSS: 8.172885 | EPOCH = [1/3] | TIME ELAPSED =31.16Mins\n",
      "ITERATION:[77/454] | LOSS: 8.140323 | EPOCH = [1/3] | TIME ELAPSED =31.71Mins\n",
      "ITERATION:[78/454] | LOSS: 8.086218 | EPOCH = [1/3] | TIME ELAPSED =32.12Mins\n",
      "ITERATION:[79/454] | LOSS: 8.040587 | EPOCH = [1/3] | TIME ELAPSED =32.59Mins\n",
      "ITERATION:[80/454] | LOSS: 8.10691 | EPOCH = [1/3] | TIME ELAPSED =32.99Mins\n",
      "ITERATION:[81/454] | LOSS: 8.021591 | EPOCH = [1/3] | TIME ELAPSED =33.43Mins\n",
      "ITERATION:[82/454] | LOSS: 7.985823 | EPOCH = [1/3] | TIME ELAPSED =33.87Mins\n",
      "ITERATION:[83/454] | LOSS: 7.922248 | EPOCH = [1/3] | TIME ELAPSED =34.27Mins\n",
      "ITERATION:[84/454] | LOSS: 7.891312 | EPOCH = [1/3] | TIME ELAPSED =34.66Mins\n",
      "ITERATION:[85/454] | LOSS: 7.849299 | EPOCH = [1/3] | TIME ELAPSED =35.05Mins\n",
      "ITERATION:[86/454] | LOSS: 7.79735 | EPOCH = [1/3] | TIME ELAPSED =35.52Mins\n",
      "ITERATION:[87/454] | LOSS: 7.776783 | EPOCH = [1/3] | TIME ELAPSED =35.95Mins\n",
      "ITERATION:[88/454] | LOSS: 7.692383 | EPOCH = [1/3] | TIME ELAPSED =36.4Mins\n",
      "ITERATION:[89/454] | LOSS: 7.5966 | EPOCH = [1/3] | TIME ELAPSED =36.81Mins\n",
      "ITERATION:[90/454] | LOSS: 7.614521 | EPOCH = [1/3] | TIME ELAPSED =37.22Mins\n",
      "ITERATION:[91/454] | LOSS: 7.553596 | EPOCH = [1/3] | TIME ELAPSED =37.68Mins\n",
      "ITERATION:[92/454] | LOSS: 7.517315 | EPOCH = [1/3] | TIME ELAPSED =38.13Mins\n",
      "ITERATION:[93/454] | LOSS: 7.401481 | EPOCH = [1/3] | TIME ELAPSED =38.57Mins\n",
      "ITERATION:[94/454] | LOSS: 7.298606 | EPOCH = [1/3] | TIME ELAPSED =38.96Mins\n",
      "ITERATION:[95/454] | LOSS: 7.231254 | EPOCH = [1/3] | TIME ELAPSED =39.35Mins\n",
      "ITERATION:[96/454] | LOSS: 7.137963 | EPOCH = [1/3] | TIME ELAPSED =39.8Mins\n",
      "ITERATION:[97/454] | LOSS: 7.04999 | EPOCH = [1/3] | TIME ELAPSED =40.19Mins\n",
      "ITERATION:[98/454] | LOSS: 6.96335 | EPOCH = [1/3] | TIME ELAPSED =40.64Mins\n",
      "ITERATION:[99/454] | LOSS: 6.879691 | EPOCH = [1/3] | TIME ELAPSED =41.12Mins\n",
      "\n",
      "LEARNING RATE = 7.807489599999997e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 7.807489599999997e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[100/454] | LOSS: 6.758801 | EPOCH = [1/3] | TIME ELAPSED =41.59Mins\n",
      "ITERATION:[101/454] | LOSS: 6.705804 | EPOCH = [1/3] | TIME ELAPSED =41.96Mins\n",
      "ITERATION:[102/454] | LOSS: 6.571394 | EPOCH = [1/3] | TIME ELAPSED =42.38Mins\n",
      "ITERATION:[103/454] | LOSS: 6.589167 | EPOCH = [1/3] | TIME ELAPSED =42.74Mins\n",
      "ITERATION:[104/454] | LOSS: 6.473104 | EPOCH = [1/3] | TIME ELAPSED =43.12Mins\n",
      "ITERATION:[105/454] | LOSS: 6.39084 | EPOCH = [1/3] | TIME ELAPSED =43.6Mins\n",
      "ITERATION:[106/454] | LOSS: 6.353726 | EPOCH = [1/3] | TIME ELAPSED =43.99Mins\n",
      "ITERATION:[107/454] | LOSS: 6.21824 | EPOCH = [1/3] | TIME ELAPSED =44.41Mins\n",
      "ITERATION:[108/454] | LOSS: 6.188954 | EPOCH = [1/3] | TIME ELAPSED =44.82Mins\n",
      "ITERATION:[109/454] | LOSS: 6.058789 | EPOCH = [1/3] | TIME ELAPSED =45.17Mins\n",
      "ITERATION:[110/454] | LOSS: 6.061044 | EPOCH = [1/3] | TIME ELAPSED =45.6Mins\n",
      "ITERATION:[111/454] | LOSS: 5.973739 | EPOCH = [1/3] | TIME ELAPSED =45.95Mins\n",
      "ITERATION:[112/454] | LOSS: 5.957478 | EPOCH = [1/3] | TIME ELAPSED =46.41Mins\n",
      "ITERATION:[113/454] | LOSS: 5.903878 | EPOCH = [1/3] | TIME ELAPSED =46.85Mins\n",
      "ITERATION:[114/454] | LOSS: 5.752005 | EPOCH = [1/3] | TIME ELAPSED =47.3Mins\n",
      "ITERATION:[115/454] | LOSS: 5.734272 | EPOCH = [1/3] | TIME ELAPSED =47.77Mins\n",
      "ITERATION:[116/454] | LOSS: 5.68579 | EPOCH = [1/3] | TIME ELAPSED =48.27Mins\n",
      "ITERATION:[117/454] | LOSS: 5.672664 | EPOCH = [1/3] | TIME ELAPSED =48.61Mins\n",
      "ITERATION:[118/454] | LOSS: 5.661923 | EPOCH = [1/3] | TIME ELAPSED =49.03Mins\n",
      "ITERATION:[119/454] | LOSS: 5.484602 | EPOCH = [1/3] | TIME ELAPSED =49.42Mins\n",
      "ITERATION:[120/454] | LOSS: 5.587102 | EPOCH = [1/3] | TIME ELAPSED =49.82Mins\n",
      "ITERATION:[121/454] | LOSS: 5.466506 | EPOCH = [1/3] | TIME ELAPSED =50.26Mins\n",
      "ITERATION:[122/454] | LOSS: 5.520208 | EPOCH = [1/3] | TIME ELAPSED =50.67Mins\n",
      "ITERATION:[123/454] | LOSS: 5.451246 | EPOCH = [1/3] | TIME ELAPSED =51.04Mins\n",
      "ITERATION:[124/454] | LOSS: 5.492687 | EPOCH = [1/3] | TIME ELAPSED =51.45Mins\n",
      "\n",
      "LEARNING RATE = 7.339040223999996e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 7.339040223999996e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[125/454] | LOSS: 5.42401 | EPOCH = [1/3] | TIME ELAPSED =51.93Mins\n",
      "ITERATION:[126/454] | LOSS: 5.380072 | EPOCH = [1/3] | TIME ELAPSED =52.29Mins\n",
      "ITERATION:[127/454] | LOSS: 5.412041 | EPOCH = [1/3] | TIME ELAPSED =52.66Mins\n",
      "ITERATION:[128/454] | LOSS: 5.333444 | EPOCH = [1/3] | TIME ELAPSED =53.19Mins\n",
      "ITERATION:[129/454] | LOSS: 5.33527 | EPOCH = [1/3] | TIME ELAPSED =53.62Mins\n",
      "ITERATION:[130/454] | LOSS: 5.295085 | EPOCH = [1/3] | TIME ELAPSED =54.07Mins\n",
      "ITERATION:[131/454] | LOSS: 5.287811 | EPOCH = [1/3] | TIME ELAPSED =54.57Mins\n",
      "ITERATION:[132/454] | LOSS: 5.331889 | EPOCH = [1/3] | TIME ELAPSED =54.96Mins\n",
      "ITERATION:[133/454] | LOSS: 5.264043 | EPOCH = [1/3] | TIME ELAPSED =55.46Mins\n",
      "ITERATION:[134/454] | LOSS: 5.165145 | EPOCH = [1/3] | TIME ELAPSED =55.94Mins\n",
      "ITERATION:[135/454] | LOSS: 5.194457 | EPOCH = [1/3] | TIME ELAPSED =56.43Mins\n",
      "ITERATION:[136/454] | LOSS: 5.251472 | EPOCH = [1/3] | TIME ELAPSED =56.85Mins\n",
      "ITERATION:[137/454] | LOSS: 5.268611 | EPOCH = [1/3] | TIME ELAPSED =57.32Mins\n",
      "ITERATION:[138/454] | LOSS: 5.235715 | EPOCH = [1/3] | TIME ELAPSED =57.7Mins\n",
      "ITERATION:[139/454] | LOSS: 5.237593 | EPOCH = [1/3] | TIME ELAPSED =58.09Mins\n",
      "ITERATION:[140/454] | LOSS: 5.250823 | EPOCH = [1/3] | TIME ELAPSED =58.53Mins\n",
      "ITERATION:[141/454] | LOSS: 5.241436 | EPOCH = [1/3] | TIME ELAPSED =58.96Mins\n",
      "ITERATION:[142/454] | LOSS: 5.153469 | EPOCH = [1/3] | TIME ELAPSED =59.35Mins\n",
      "ITERATION:[143/454] | LOSS: 5.206765 | EPOCH = [1/3] | TIME ELAPSED =59.81Mins\n",
      "ITERATION:[144/454] | LOSS: 5.12564 | EPOCH = [1/3] | TIME ELAPSED =60.2Mins\n",
      "ITERATION:[145/454] | LOSS: 5.070012 | EPOCH = [1/3] | TIME ELAPSED =60.54Mins\n",
      "ITERATION:[146/454] | LOSS: 5.146037 | EPOCH = [1/3] | TIME ELAPSED =60.96Mins\n",
      "ITERATION:[147/454] | LOSS: 5.154257 | EPOCH = [1/3] | TIME ELAPSED =61.28Mins\n",
      "ITERATION:[148/454] | LOSS: 5.094704 | EPOCH = [1/3] | TIME ELAPSED =61.75Mins\n",
      "ITERATION:[149/454] | LOSS: 5.129973 | EPOCH = [1/3] | TIME ELAPSED =62.16Mins\n",
      "\n",
      "LEARNING RATE = 6.898697810559997e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 6.898697810559997e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[150/454] | LOSS: 5.183911 | EPOCH = [1/3] | TIME ELAPSED =62.57Mins\n",
      "ITERATION:[151/454] | LOSS: 5.201358 | EPOCH = [1/3] | TIME ELAPSED =63.08Mins\n",
      "ITERATION:[152/454] | LOSS: 5.15178 | EPOCH = [1/3] | TIME ELAPSED =63.47Mins\n",
      "ITERATION:[153/454] | LOSS: 5.108215 | EPOCH = [1/3] | TIME ELAPSED =63.92Mins\n",
      "ITERATION:[154/454] | LOSS: 5.087034 | EPOCH = [1/3] | TIME ELAPSED =64.32Mins\n",
      "ITERATION:[155/454] | LOSS: 5.140641 | EPOCH = [1/3] | TIME ELAPSED =64.77Mins\n",
      "ITERATION:[156/454] | LOSS: 5.143205 | EPOCH = [1/3] | TIME ELAPSED =65.2Mins\n",
      "ITERATION:[157/454] | LOSS: 5.080887 | EPOCH = [1/3] | TIME ELAPSED =65.66Mins\n",
      "ITERATION:[158/454] | LOSS: 5.096907 | EPOCH = [1/3] | TIME ELAPSED =66.01Mins\n",
      "ITERATION:[159/454] | LOSS: 5.081142 | EPOCH = [1/3] | TIME ELAPSED =66.47Mins\n",
      "ITERATION:[160/454] | LOSS: 5.065867 | EPOCH = [1/3] | TIME ELAPSED =66.88Mins\n",
      "ITERATION:[161/454] | LOSS: 5.031308 | EPOCH = [1/3] | TIME ELAPSED =67.26Mins\n",
      "ITERATION:[162/454] | LOSS: 5.072926 | EPOCH = [1/3] | TIME ELAPSED =67.64Mins\n",
      "ITERATION:[163/454] | LOSS: 5.078482 | EPOCH = [1/3] | TIME ELAPSED =68.08Mins\n",
      "ITERATION:[164/454] | LOSS: 5.103035 | EPOCH = [1/3] | TIME ELAPSED =68.48Mins\n",
      "ITERATION:[165/454] | LOSS: 5.063303 | EPOCH = [1/3] | TIME ELAPSED =68.93Mins\n",
      "ITERATION:[166/454] | LOSS: 5.0553 | EPOCH = [1/3] | TIME ELAPSED =69.34Mins\n",
      "ITERATION:[167/454] | LOSS: 5.068513 | EPOCH = [1/3] | TIME ELAPSED =69.82Mins\n",
      "ITERATION:[168/454] | LOSS: 4.94269 | EPOCH = [1/3] | TIME ELAPSED =70.23Mins\n",
      "ITERATION:[169/454] | LOSS: 5.028475 | EPOCH = [1/3] | TIME ELAPSED =70.72Mins\n",
      "ITERATION:[170/454] | LOSS: 5.041194 | EPOCH = [1/3] | TIME ELAPSED =71.2Mins\n",
      "ITERATION:[171/454] | LOSS: 5.046376 | EPOCH = [1/3] | TIME ELAPSED =71.58Mins\n",
      "ITERATION:[172/454] | LOSS: 5.072287 | EPOCH = [1/3] | TIME ELAPSED =72.04Mins\n",
      "ITERATION:[173/454] | LOSS: 5.043504 | EPOCH = [1/3] | TIME ELAPSED =72.47Mins\n",
      "ITERATION:[174/454] | LOSS: 4.975967 | EPOCH = [1/3] | TIME ELAPSED =72.87Mins\n",
      "\n",
      "LEARNING RATE = 6.484775941926396e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 6.484775941926396e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[175/454] | LOSS: 5.118126 | EPOCH = [1/3] | TIME ELAPSED =73.36Mins\n",
      "ITERATION:[176/454] | LOSS: 5.089136 | EPOCH = [1/3] | TIME ELAPSED =73.74Mins\n",
      "ITERATION:[177/454] | LOSS: 5.029836 | EPOCH = [1/3] | TIME ELAPSED =74.07Mins\n",
      "ITERATION:[178/454] | LOSS: 5.058697 | EPOCH = [1/3] | TIME ELAPSED =74.53Mins\n",
      "ITERATION:[179/454] | LOSS: 5.023395 | EPOCH = [1/3] | TIME ELAPSED =75.0Mins\n",
      "ITERATION:[180/454] | LOSS: 4.998573 | EPOCH = [1/3] | TIME ELAPSED =75.44Mins\n",
      "ITERATION:[181/454] | LOSS: 5.053717 | EPOCH = [1/3] | TIME ELAPSED =75.85Mins\n",
      "ITERATION:[182/454] | LOSS: 5.018232 | EPOCH = [1/3] | TIME ELAPSED =76.23Mins\n",
      "ITERATION:[183/454] | LOSS: 5.027849 | EPOCH = [1/3] | TIME ELAPSED =76.68Mins\n",
      "ITERATION:[184/454] | LOSS: 5.065478 | EPOCH = [1/3] | TIME ELAPSED =77.04Mins\n",
      "ITERATION:[185/454] | LOSS: 5.090775 | EPOCH = [1/3] | TIME ELAPSED =77.46Mins\n",
      "ITERATION:[186/454] | LOSS: 5.051947 | EPOCH = [1/3] | TIME ELAPSED =77.94Mins\n",
      "ITERATION:[187/454] | LOSS: 5.083564 | EPOCH = [1/3] | TIME ELAPSED =78.3Mins\n",
      "ITERATION:[188/454] | LOSS: 5.043392 | EPOCH = [1/3] | TIME ELAPSED =78.82Mins\n",
      "ITERATION:[189/454] | LOSS: 5.03728 | EPOCH = [1/3] | TIME ELAPSED =79.23Mins\n",
      "ITERATION:[190/454] | LOSS: 4.992495 | EPOCH = [1/3] | TIME ELAPSED =79.66Mins\n",
      "ITERATION:[191/454] | LOSS: 5.030191 | EPOCH = [1/3] | TIME ELAPSED =80.08Mins\n",
      "ITERATION:[192/454] | LOSS: 5.023718 | EPOCH = [1/3] | TIME ELAPSED =80.47Mins\n",
      "ITERATION:[193/454] | LOSS: 5.036122 | EPOCH = [1/3] | TIME ELAPSED =80.88Mins\n",
      "ITERATION:[194/454] | LOSS: 5.005346 | EPOCH = [1/3] | TIME ELAPSED =81.18Mins\n",
      "ITERATION:[195/454] | LOSS: 5.062335 | EPOCH = [1/3] | TIME ELAPSED =81.66Mins\n",
      "ITERATION:[196/454] | LOSS: 5.046474 | EPOCH = [1/3] | TIME ELAPSED =82.04Mins\n",
      "ITERATION:[197/454] | LOSS: 5.06488 | EPOCH = [1/3] | TIME ELAPSED =82.49Mins\n",
      "ITERATION:[198/454] | LOSS: 4.992948 | EPOCH = [1/3] | TIME ELAPSED =82.93Mins\n",
      "ITERATION:[199/454] | LOSS: 5.07699 | EPOCH = [1/3] | TIME ELAPSED =83.42Mins\n",
      "\n",
      "LEARNING RATE = 6.095689385410812e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 6.095689385410812e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[200/454] | LOSS: 4.97973 | EPOCH = [1/3] | TIME ELAPSED =83.79Mins\n",
      "ITERATION:[201/454] | LOSS: 5.018397 | EPOCH = [1/3] | TIME ELAPSED =84.23Mins\n",
      "ITERATION:[202/454] | LOSS: 5.025811 | EPOCH = [1/3] | TIME ELAPSED =84.71Mins\n",
      "ITERATION:[203/454] | LOSS: 4.966508 | EPOCH = [1/3] | TIME ELAPSED =85.19Mins\n",
      "ITERATION:[204/454] | LOSS: 4.993187 | EPOCH = [1/3] | TIME ELAPSED =85.56Mins\n",
      "ITERATION:[205/454] | LOSS: 4.942742 | EPOCH = [1/3] | TIME ELAPSED =85.97Mins\n",
      "ITERATION:[206/454] | LOSS: 4.990044 | EPOCH = [1/3] | TIME ELAPSED =86.5Mins\n",
      "ITERATION:[207/454] | LOSS: 5.021503 | EPOCH = [1/3] | TIME ELAPSED =86.91Mins\n",
      "ITERATION:[208/454] | LOSS: 4.952386 | EPOCH = [1/3] | TIME ELAPSED =87.35Mins\n",
      "ITERATION:[209/454] | LOSS: 4.967807 | EPOCH = [1/3] | TIME ELAPSED =87.78Mins\n",
      "ITERATION:[210/454] | LOSS: 5.040906 | EPOCH = [1/3] | TIME ELAPSED =88.26Mins\n",
      "ITERATION:[211/454] | LOSS: 4.939335 | EPOCH = [1/3] | TIME ELAPSED =88.69Mins\n",
      "ITERATION:[212/454] | LOSS: 5.032474 | EPOCH = [1/3] | TIME ELAPSED =89.04Mins\n",
      "ITERATION:[213/454] | LOSS: 4.943182 | EPOCH = [1/3] | TIME ELAPSED =89.44Mins\n",
      "ITERATION:[214/454] | LOSS: 4.961707 | EPOCH = [1/3] | TIME ELAPSED =89.87Mins\n",
      "ITERATION:[215/454] | LOSS: 4.941964 | EPOCH = [1/3] | TIME ELAPSED =90.33Mins\n",
      "ITERATION:[216/454] | LOSS: 4.972642 | EPOCH = [1/3] | TIME ELAPSED =90.77Mins\n",
      "ITERATION:[217/454] | LOSS: 5.067889 | EPOCH = [1/3] | TIME ELAPSED =91.17Mins\n",
      "ITERATION:[218/454] | LOSS: 4.958429 | EPOCH = [1/3] | TIME ELAPSED =91.58Mins\n",
      "ITERATION:[219/454] | LOSS: 4.962908 | EPOCH = [1/3] | TIME ELAPSED =92.03Mins\n",
      "ITERATION:[220/454] | LOSS: 4.980486 | EPOCH = [1/3] | TIME ELAPSED =92.46Mins\n",
      "ITERATION:[221/454] | LOSS: 5.046702 | EPOCH = [1/3] | TIME ELAPSED =92.86Mins\n",
      "ITERATION:[222/454] | LOSS: 4.932034 | EPOCH = [1/3] | TIME ELAPSED =93.31Mins\n",
      "ITERATION:[223/454] | LOSS: 4.981487 | EPOCH = [1/3] | TIME ELAPSED =93.72Mins\n",
      "ITERATION:[224/454] | LOSS: 5.060845 | EPOCH = [1/3] | TIME ELAPSED =94.23Mins\n",
      "\n",
      "LEARNING RATE = 5.729948022286163e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5.729948022286163e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[225/454] | LOSS: 4.857182 | EPOCH = [1/3] | TIME ELAPSED =94.8Mins\n",
      "ITERATION:[226/454] | LOSS: 4.955587 | EPOCH = [1/3] | TIME ELAPSED =95.22Mins\n",
      "ITERATION:[227/454] | LOSS: 4.935356 | EPOCH = [1/3] | TIME ELAPSED =95.59Mins\n",
      "ITERATION:[228/454] | LOSS: 4.904737 | EPOCH = [1/3] | TIME ELAPSED =95.98Mins\n",
      "ITERATION:[229/454] | LOSS: 4.965498 | EPOCH = [1/3] | TIME ELAPSED =96.38Mins\n",
      "ITERATION:[230/454] | LOSS: 4.917371 | EPOCH = [1/3] | TIME ELAPSED =96.83Mins\n",
      "ITERATION:[231/454] | LOSS: 4.928544 | EPOCH = [1/3] | TIME ELAPSED =97.24Mins\n",
      "ITERATION:[232/454] | LOSS: 4.97413 | EPOCH = [1/3] | TIME ELAPSED =97.59Mins\n",
      "ITERATION:[233/454] | LOSS: 4.973771 | EPOCH = [1/3] | TIME ELAPSED =97.99Mins\n",
      "ITERATION:[234/454] | LOSS: 4.975802 | EPOCH = [1/3] | TIME ELAPSED =98.4Mins\n",
      "ITERATION:[235/454] | LOSS: 4.967944 | EPOCH = [1/3] | TIME ELAPSED =98.83Mins\n",
      "ITERATION:[236/454] | LOSS: 5.016002 | EPOCH = [1/3] | TIME ELAPSED =99.17Mins\n",
      "ITERATION:[237/454] | LOSS: 4.903908 | EPOCH = [1/3] | TIME ELAPSED =99.6Mins\n",
      "ITERATION:[238/454] | LOSS: 4.888429 | EPOCH = [1/3] | TIME ELAPSED =99.97Mins\n",
      "ITERATION:[239/454] | LOSS: 4.828507 | EPOCH = [1/3] | TIME ELAPSED =100.44Mins\n",
      "ITERATION:[240/454] | LOSS: 4.901763 | EPOCH = [1/3] | TIME ELAPSED =100.89Mins\n",
      "ITERATION:[241/454] | LOSS: 4.918412 | EPOCH = [1/3] | TIME ELAPSED =101.3Mins\n",
      "ITERATION:[242/454] | LOSS: 4.966012 | EPOCH = [1/3] | TIME ELAPSED =101.71Mins\n",
      "ITERATION:[243/454] | LOSS: 4.896274 | EPOCH = [1/3] | TIME ELAPSED =102.16Mins\n",
      "ITERATION:[244/454] | LOSS: 4.881766 | EPOCH = [1/3] | TIME ELAPSED =102.55Mins\n",
      "ITERATION:[245/454] | LOSS: 4.916661 | EPOCH = [1/3] | TIME ELAPSED =103.02Mins\n",
      "ITERATION:[246/454] | LOSS: 4.9546 | EPOCH = [1/3] | TIME ELAPSED =103.37Mins\n",
      "ITERATION:[247/454] | LOSS: 4.955876 | EPOCH = [1/3] | TIME ELAPSED =103.83Mins\n",
      "ITERATION:[248/454] | LOSS: 4.933015 | EPOCH = [1/3] | TIME ELAPSED =104.21Mins\n",
      "ITERATION:[249/454] | LOSS: 4.92497 | EPOCH = [1/3] | TIME ELAPSED =104.57Mins\n",
      "\n",
      "LEARNING RATE = 5.386151140948993e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5.386151140948993e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[250/454] | LOSS: 4.949852 | EPOCH = [1/3] | TIME ELAPSED =104.98Mins\n",
      "ITERATION:[251/454] | LOSS: 4.989328 | EPOCH = [1/3] | TIME ELAPSED =105.39Mins\n",
      "ITERATION:[252/454] | LOSS: 4.991253 | EPOCH = [1/3] | TIME ELAPSED =105.78Mins\n",
      "ITERATION:[253/454] | LOSS: 4.901967 | EPOCH = [1/3] | TIME ELAPSED =106.24Mins\n",
      "ITERATION:[254/454] | LOSS: 4.946052 | EPOCH = [1/3] | TIME ELAPSED =106.71Mins\n",
      "ITERATION:[255/454] | LOSS: 4.949363 | EPOCH = [1/3] | TIME ELAPSED =107.16Mins\n",
      "ITERATION:[256/454] | LOSS: 4.935875 | EPOCH = [1/3] | TIME ELAPSED =107.59Mins\n",
      "ITERATION:[257/454] | LOSS: 4.955309 | EPOCH = [1/3] | TIME ELAPSED =107.94Mins\n",
      "ITERATION:[258/454] | LOSS: 4.967052 | EPOCH = [1/3] | TIME ELAPSED =108.43Mins\n",
      "ITERATION:[259/454] | LOSS: 4.951007 | EPOCH = [1/3] | TIME ELAPSED =108.92Mins\n",
      "ITERATION:[260/454] | LOSS: 4.923326 | EPOCH = [1/3] | TIME ELAPSED =109.29Mins\n",
      "ITERATION:[261/454] | LOSS: 4.996926 | EPOCH = [1/3] | TIME ELAPSED =109.75Mins\n",
      "ITERATION:[262/454] | LOSS: 4.935747 | EPOCH = [1/3] | TIME ELAPSED =110.19Mins\n",
      "ITERATION:[263/454] | LOSS: 5.008998 | EPOCH = [1/3] | TIME ELAPSED =110.63Mins\n",
      "ITERATION:[264/454] | LOSS: 4.935543 | EPOCH = [1/3] | TIME ELAPSED =111.06Mins\n",
      "ITERATION:[265/454] | LOSS: 4.923161 | EPOCH = [1/3] | TIME ELAPSED =111.45Mins\n",
      "ITERATION:[266/454] | LOSS: 4.954204 | EPOCH = [1/3] | TIME ELAPSED =111.81Mins\n",
      "ITERATION:[267/454] | LOSS: 4.920864 | EPOCH = [1/3] | TIME ELAPSED =112.23Mins\n",
      "ITERATION:[268/454] | LOSS: 4.918724 | EPOCH = [1/3] | TIME ELAPSED =112.6Mins\n",
      "ITERATION:[269/454] | LOSS: 4.897834 | EPOCH = [1/3] | TIME ELAPSED =113.05Mins\n",
      "ITERATION:[270/454] | LOSS: 4.852015 | EPOCH = [1/3] | TIME ELAPSED =113.49Mins\n",
      "ITERATION:[271/454] | LOSS: 4.920471 | EPOCH = [1/3] | TIME ELAPSED =113.96Mins\n",
      "ITERATION:[272/454] | LOSS: 4.871669 | EPOCH = [1/3] | TIME ELAPSED =114.42Mins\n",
      "ITERATION:[273/454] | LOSS: 4.906988 | EPOCH = [1/3] | TIME ELAPSED =114.81Mins\n",
      "ITERATION:[274/454] | LOSS: 4.88104 | EPOCH = [1/3] | TIME ELAPSED =115.23Mins\n",
      "\n",
      "LEARNING RATE = 5.062982072492053e-05 Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5.062982072492053e-05\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "ITERATION:[275/454] | LOSS: 4.916848 | EPOCH = [1/3] | TIME ELAPSED =115.66Mins\n",
      "ITERATION:[276/454] | LOSS: 4.902818 | EPOCH = [1/3] | TIME ELAPSED =116.06Mins\n",
      "ITERATION:[277/454] | LOSS: 4.951821 | EPOCH = [1/3] | TIME ELAPSED =116.47Mins\n",
      "ITERATION:[278/454] | LOSS: 4.891502 | EPOCH = [1/3] | TIME ELAPSED =116.95Mins\n",
      "ITERATION:[279/454] | LOSS: 4.918816 | EPOCH = [1/3] | TIME ELAPSED =117.33Mins\n"
     ]
    }
   ],
   "source": [
    "if platform == \"colab\":\n",
    "    IMAGE_DIR = '/content/drive/My Drive/train_images/'\n",
    "else:\n",
    "    IMAGE_DIR = 'D:/Padhai/IIT Delhi MS(R)/2019-20 Sem II/COL774 Machine Learning/Assignment/Assignment4/train_images/'\n",
    "\n",
    "if restore == True:\n",
    "    net = ImageCaptionsNet()\n",
    "    net = net.double()\n",
    "    new_state_dict = collections.OrderedDict()\n",
    "    new_state_dict = restore_checkpoint(\"caption_chkpt_multi.pth\")    \n",
    "    \n",
    "    print(\"State Dictionary Loaded Successfully.\")\n",
    "    #net = nn.DataParallel(net)\n",
    "    net = net.to(torch.device(\"cuda:0\"))\n",
    "\n",
    "# Creating the Dataset\n",
    "train_dataset = ImageCaptionsDataset(\n",
    "    IMAGE_DIR, captions_preprocessing_obj.captions_dict, img_transform=img_transform,\n",
    "    captions_transform=captions_preprocessing_obj.captions_transform\n",
    ")\n",
    "\n",
    "# Define your hyperparameters\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0 # Parallel threads for dataloading\n",
    "\n",
    "'''cw = torch.ones(len(VOCAB), dtype=torch.double)\n",
    "cw[WORD2IDX[\"<pad>\"]] = 0\n",
    "cw = cw.to(torch.device(\"cuda:0\"))'''\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=WORD2IDX[\"<pad>\"])\n",
    "\n",
    "paramaters = list(net.Decoder.parameters()) + list(net.Encoder.fc.parameters())\n",
    "\n",
    "optimizer = optim.Adam(paramaters, lr=LEARNING_RATE,weight_decay=0.01)\n",
    "\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "params_for_adam = sum(p.numel() for p in paramaters)\n",
    "print(\"TOTAL PARAMS: {}, TOTAL TRAINABLE PARAMS NET: {}, TOTAL ADAM PARAMS: {}\".format(total_params,trainable_params,params_for_adam))\n",
    "print(\"TOTAL EPOCHS: {}, BATCH SIZE: {}, OPTIMIZER: {}\".format(NUMBER_OF_EPOCHS, BATCH_SIZE, optimizer))\n",
    "loss_list = []\n",
    "# Creating the DataLoader for batching purposes\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                          collate_fn=custom_batch)\n",
    "\n",
    "if device != \"cpu\":\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #torch.cuda.set_device(1)\n",
    "t0 = time()\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    print(\"$$$$$----EPOCH {}----$$$$$$\".format(epoch+1))\n",
    "    iteration = 0\n",
    "    \n",
    "    '''if epoch == 1:\n",
    "        LEARNING_RATE = 8e-4\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = LEARNING_RATE\n",
    "        print(\"\\nLEARNING RATE =\", LEARNING_RATE, optimizer)\n",
    "    elif epoch == 2:\n",
    "        LEARNING_RATE = 5e-4\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = LEARNING_RATE\n",
    "        print(\"\\nLEARNING RATE =\", LEARNING_RATE, optimizer)'''\n",
    "    \n",
    "\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        iteration +=1\n",
    "        if iteration%25 == 0:\n",
    "            LEARNING_RATE *= 0.94\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = LEARNING_RATE\n",
    "            print(\"\\nLEARNING RATE =\", LEARNING_RATE, optimizer)\n",
    "\n",
    "        #net.zero_grad()\n",
    "        \n",
    "        net.Encoder.zero_grad()\n",
    "        net.Decoder.zero_grad()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        image_batch, captions_batch, lengths = sample['image'], sample['captions'], sample['lengths']\n",
    "        #print(lengths)\n",
    "        #print(\"image_shape\", image_batch.shape)\n",
    "        #print(\"batch_shape\", captions_batch.shape)\n",
    "        \n",
    "        #print(\"MY CAP\", captions_batch)\n",
    "\n",
    "        # If GPU training required\n",
    "        if device != \"cpu\":\n",
    "          #print(\"cuda\")\n",
    "          image_batch, captions_batch = image_batch.to(torch.device(\"cuda:0\")), captions_batch.to(torch.device(\"cuda:0\"))\n",
    "        \n",
    "        output_captions = net(image_batch, captions_batch, lengths)\n",
    "        #ground_truth = pack_padded_sequence(captions_batch, lengths, batch_first=True, enforce_sorted=False)\n",
    "        #ground_truth = ground_truth[0]\n",
    "        #print(\"GT\", captions_batch.reshape(-1))\n",
    "        #print(\"size for loss\", output_captions.shape, captions_batch.shape)\n",
    "        #torch.Size([10, 26, 9934]) torch.Size([10, 26])\n",
    "        #print(\"BEFORE LOSS\", output_captions.shape, ground_truth.shape)\n",
    "        #loss = loss_function(output_captions, ground_truth)\n",
    "        loss = loss_function(output_captions.reshape(-1, output_captions.shape[2]), captions_batch.reshape(-1))\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if iteration%25 == 0:\n",
    "            create_checkpoint(\"chkpt_finaltry_TOKEN.pth\", net, optimizer, loss, iteration, epoch+1)\n",
    "        print(\"ITERATION:[{}/{}] | LOSS: {} | EPOCH = [{}/{}] | TIME ELAPSED ={}Mins\".format(iteration, round(29000/BATCH_SIZE)+1,\n",
    "              round(loss.item(), 6), epoch+1, NUMBER_OF_EPOCHS, round((time()-t0)/60,2)))\n",
    "    print(\"\\n$$Loss = {},EPOCH: [{}/{}]\\n\\n\".format(round(loss.item(), 6), epoch+1, NUMBER_OF_EPOCHS))\n",
    "    create_checkpoint(\"Epoch_finaltry_TOKEN.pth\", net, optimizer, loss, iteration, epoch+1)\n",
    "\n",
    "create_checkpoint(\"Full_finaltry_TOKEN.pth\", net, optimizer, loss, iteration, epoch+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MAUvo16FgQdy"
   },
   "outputs": [],
   "source": [
    "WORD2IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fPazV1R1H1ES",
    "outputId": "f0b0a494-e062-4a7d-b707-06bdfe8b50d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ImageCaptionsNet(\n",
       "    (Encoder): Encoder(\n",
       "      (resnet50): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      )\n",
       "      (fc): Linear(in_features=2048, out_features=200, bias=True)\n",
       "    )\n",
       "    (Decoder): Decoder(\n",
       "      (lstm): LSTM(200, 512, batch_first=True)\n",
       "      (linear): Linear(in_features=512, out_features=8680, bias=True)\n",
       "      (embed): Embedding(8680, 200)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I14wCbvEMWdg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j980Ey5B-kUv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TOKEN_comp_final_try.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
